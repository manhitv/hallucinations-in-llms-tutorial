{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Notebook: Memory for Surprise-driven Exploration (Classic Control Ver.)</center>**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:**\n",
    "1. Burda, Y., Edwards, H., Storkey, A., & Klimov, O. (2018). Exploration by random network distillation. arXiv preprint arXiv:1810.12894.\n",
    "2. Pathak, D., Agrawal, P., Efros, A. A., & Darrell, T. (2017, July). Curiosity-driven exploration by self-supervised prediction. In International conference on machine learning (pp. 2778-2787). PMLR.\n",
    "3. Huang, S., Dossa, R. F. J., Ye, C., Braga, J., Chakraborty, D., Mehta, K., & AraÃƒÅ¡jo, J. G. (2022). Cleanrl: High-quality single-file implementations of deep reinforcement learning algorithms. Journal of Machine Learning Research, 23(274), 1-18.\n",
    "4. Brockman, G., Cheung, V., Pettersson, L., Schneider, J., Schulman, J., Tang, J., & Zaremba, W. (2016). Openai gym. arXiv preprint arXiv:1606.01540.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Setting up the libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these commands from the terminal to install related libraries and set up the working environment\n",
    "# pip install gym # Install the gym library with RL environments\n",
    "# pip install envpool\n",
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import envpool\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gym.wrappers.normalize import RunningMeanStd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. CartPole Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this notebook we will use the simple CartPole-v1 environment (https://www.gymlibrary.dev/environments/classic_control/cart_pole/) for demonstration. ðŸŽ® \n",
    "- The goal in this environment is to balance the pole on top of a cart by applying left or right action.\n",
    "- The observation space is (4,), including cart position, cart velocity, pole angle and pole angular velocity. And, action space is Discrete(2) including action to move left or right. ðŸ”„\n",
    "- This notebook can also be used for other classic control environments as well. ðŸ˜Š All you need to do is change the env_id and the state and action space. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://www.gymlibrary.dev/_images/cart_pole.gif\" width=\"300\" height=\"200\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Simple PPO** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you only want to run the surprise motivation, please run until section 3.2.2 to initialize the parameters and PPO.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'env_id': 'CartPole-v1',                              # env_id can be changed here\n",
    "          'exp_name': \"RND\",\n",
    "          'torch_deterministic': True,\n",
    "          'cuda': True,\n",
    "          'seed': 1,\n",
    "          'num_envs': 8,                                        # number of multi-environments\n",
    "          'num_steps': 128,                                     # number of steps running in each environments per rollout\n",
    "          'num_minibatches': 4,                                 # number of minibatches\n",
    "          'total_timesteps': 100000,                            # total training timesteps\n",
    "          'learning_rate': 2.5e-4,                              # learning_rate\n",
    "          'anneal_lr': True,                                    # reducing learning rate during learning\n",
    "          'num_iterations_obs_norm_init': 50,\n",
    "          'gamma': 0.99,\n",
    "          'int_gamma': 0.99,\n",
    "          'gae_lambda': 0.95,\n",
    "          'int_coef': 1.0,\n",
    "          'ext_coef': 2.0,\n",
    "          'update_epochs': 4,\n",
    "          'update_proportion': 0.25,\n",
    "          'clip_coef': 0.2,\n",
    "          'norm_adv': True,\n",
    "          'clip_vloss': True,\n",
    "          'ent_coef': 0.00,\n",
    "          'vf_coef': 0.5,\n",
    "          'max_grad_norm': 0.5,\n",
    "          'target_kl': None}\n",
    "\n",
    "\n",
    "state_space = 4                                                    # state space of env\n",
    "action_space = 2                                                   # action space of env\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and params[\"cuda\"] else \"cpu\")\n",
    "\n",
    "# Set seed.\n",
    "random.seed(params[\"seed\"])                                                 \n",
    "np.random.seed(params[\"seed\"])\n",
    "torch.manual_seed(params[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = params[\"torch_deterministic\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.1 Utils**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordEpisodeStatistics(gym.Wrapper):\n",
    "    def __init__(self, env, deque_size=100):\n",
    "        super().__init__(env)\n",
    "        self.num_envs = getattr(env, \"num_envs\", 1)\n",
    "        self.episode_returns = None\n",
    "        self.episode_lengths = None\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        observations = super().reset(**kwargs)\n",
    "        self.episode_returns = np.zeros(self.num_envs, dtype=np.float32)\n",
    "        self.episode_lengths = np.zeros(self.num_envs, dtype=np.int32)\n",
    "        self.lives = np.zeros(self.num_envs, dtype=np.int32)\n",
    "        self.returned_episode_returns = np.zeros(self.num_envs, dtype=np.float32)\n",
    "        self.returned_episode_lengths = np.zeros(self.num_envs, dtype=np.int32)\n",
    "        return observations\n",
    "\n",
    "    def step(self, action):\n",
    "        observations, rewards, dones, _, infos = super().step(action)\n",
    "        self.episode_returns += infos[\"reward\"]\n",
    "        self.episode_lengths += 1\n",
    "        self.returned_episode_returns[:] = self.episode_returns\n",
    "        self.returned_episode_lengths[:] = self.episode_lengths\n",
    "        self.episode_returns *= 1 - infos[\"terminated\"]\n",
    "        self.episode_lengths *= 1 - infos[\"terminated\"]\n",
    "        infos[\"r\"] = self.returned_episode_returns\n",
    "        infos[\"l\"] = self.returned_episode_lengths\n",
    "        return (observations, rewards, dones, infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)                # Initialize layer weights according to orthogonal method.\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)             # Set the bias of the layer.\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_id):\n",
    "    def thunk():\n",
    "        env = gym.make(env_id)\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        return env\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env_id, agent, use_int_rews):\n",
    "    env = gym.make(env_id)\n",
    "    sum_result = 0\n",
    "    for _ in range(50):\n",
    "        ob, _ = env.reset()\n",
    "        while True:\n",
    "            if use_int_rews:\n",
    "                action, _, _, _, _ = agent.get_action_and_value(torch.Tensor(ob).to(device))\n",
    "            else:\n",
    "                action, _, _, _ = agent.get_action_and_value(torch.Tensor(ob).to(device))\n",
    "            next_ob, reward, terminated, truncated, info = env.step(action.cpu().numpy())\n",
    "            sum_result += reward\n",
    "            done = np.logical_or(terminated, truncated)\n",
    "            if done:\n",
    "                break\n",
    "            ob = next_ob\n",
    "    return sum_result/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.2 PPO Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOAgent(nn.Module):\n",
    "    def __init__(self, envs, use_int_rews=False):\n",
    "        super().__init__()\n",
    "        self.use_int_rews = use_int_rews\n",
    "        # print(envs.single_observation_space.shape)\n",
    "\n",
    "        self.critic_ext = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "\n",
    "        self.critic_int = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, action_space), std=0.01),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.actor(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        if self.use_int_rews:                                                                                       # If intrinsic reward is used\n",
    "            return (action, probs.log_prob(action), probs.entropy(), self.critic_ext(x), self.critic_int(x),)\n",
    "        else:                                                                                                       # If intrinsic reward is not used\n",
    "            return (action, probs.log_prob(action), probs.entropy(), self.critic_ext(x),)\n",
    "\n",
    "    def get_value(self, x):\n",
    "        if self.use_int_rews:                                                                                       # If intrinsic reward is used\n",
    "            return self.critic_ext(x), self.critic_int(x)\n",
    "        else:                                                                                                       # If intrinsic reward is not used\n",
    "            return self.critic_ext(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.2.3 Main Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = params[\"env_id\"]\n",
    "exp_name = params[\"exp_name\"]\n",
    "seed = params[\"seed\"]\n",
    "run_name = f\"{env_id}__{exp_name}__{seed}__{int(time.time())}\"\n",
    "\n",
    "\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(env_id) for i in range(params[\"num_envs\"])],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up agent and model\n",
    "Agent = PPOAgent(envs, use_int_rews=False).to(device)\n",
    "optimizer = optim.Adam(\n",
    "    Agent.parameters(),\n",
    "    lr=params[\"learning_rate\"],\n",
    "    eps=1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.zeros((params[\"num_steps\"], params[\"num_envs\"]) + envs.single_observation_space.shape).to(device)  \n",
    "actions = torch.zeros((params[\"num_steps\"], params[\"num_envs\"]) + envs.single_action_space.shape).to(device)   \n",
    "logprobs = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "rewards = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "dones = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "values = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "avg_returns = deque(maxlen=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=88, episodic_return=11.0\n",
      "global_step=96, episodic_return=12.0\n",
      "global_step=120, episodic_return=15.0\n",
      "global_step=136, episodic_return=17.0\n",
      "global_step=136, episodic_return=17.0\n",
      "global_step=160, episodic_return=20.0\n",
      "global_step=176, episodic_return=22.0\n",
      "global_step=224, episodic_return=11.0\n",
      "global_step=240, episodic_return=15.0\n",
      "global_step=256, episodic_return=10.0\n",
      "global_step=264, episodic_return=22.0\n",
      "global_step=264, episodic_return=13.0\n",
      "global_step=328, episodic_return=11.0\n",
      "global_step=328, episodic_return=29.0\n",
      "global_step=336, episodic_return=42.0\n",
      "global_step=368, episodic_return=18.0\n",
      "global_step=408, episodic_return=34.0\n",
      "global_step=416, episodic_return=10.0\n",
      "global_step=416, episodic_return=20.0\n",
      "global_step=448, episodic_return=23.0\n",
      "global_step=456, episodic_return=24.0\n",
      "global_step=472, episodic_return=13.0\n",
      "global_step=472, episodic_return=18.0\n",
      "global_step=504, episodic_return=22.0\n",
      "global_step=536, episodic_return=11.0\n",
      "global_step=544, episodic_return=16.0\n",
      "global_step=552, episodic_return=12.0\n",
      "global_step=576, episodic_return=13.0\n",
      "global_step=600, episodic_return=24.0\n",
      "global_step=608, episodic_return=17.0\n",
      "global_step=632, episodic_return=16.0\n",
      "global_step=640, episodic_return=12.0\n",
      "global_step=656, episodic_return=30.0\n",
      "global_step=656, episodic_return=10.0\n",
      "global_step=728, episodic_return=12.0\n",
      "global_step=744, episodic_return=26.0\n",
      "global_step=744, episodic_return=18.0\n",
      "global_step=744, episodic_return=11.0\n",
      "global_step=768, episodic_return=20.0\n",
      "global_step=776, episodic_return=17.0\n",
      "global_step=784, episodic_return=29.0\n",
      "global_step=824, episodic_return=10.0\n",
      "global_step=832, episodic_return=11.0\n",
      "global_step=840, episodic_return=23.0\n",
      "global_step=864, episodic_return=12.0\n",
      "global_step=872, episodic_return=18.0\n",
      "global_step=928, episodic_return=13.0\n",
      "global_step=936, episodic_return=9.0\n",
      "global_step=944, episodic_return=14.0\n",
      "global_step=960, episodic_return=22.0\n",
      "global_step=1024, episodic_return=12.0\n",
      "SPS: 200\n",
      "global_step=1088, episodic_return=43.0\n",
      "global_step=1096, episodic_return=17.0\n",
      "global_step=1104, episodic_return=20.0\n",
      "global_step=1128, episodic_return=24.0\n",
      "global_step=1136, episodic_return=14.0\n",
      "global_step=1208, episodic_return=42.0\n",
      "global_step=1240, episodic_return=18.0\n",
      "global_step=1248, episodic_return=14.0\n",
      "global_step=1256, episodic_return=16.0\n",
      "global_step=1264, episodic_return=22.0\n",
      "global_step=1272, episodic_return=54.0\n",
      "global_step=1360, episodic_return=73.0\n",
      "global_step=1368, episodic_return=20.0\n",
      "global_step=1376, episodic_return=17.0\n",
      "global_step=1400, episodic_return=19.0\n",
      "global_step=1456, episodic_return=10.0\n",
      "global_step=1464, episodic_return=25.0\n",
      "global_step=1496, episodic_return=16.0\n",
      "global_step=1512, episodic_return=51.0\n",
      "global_step=1512, episodic_return=32.0\n",
      "global_step=1528, episodic_return=21.0\n",
      "global_step=1560, episodic_return=36.0\n",
      "global_step=1568, episodic_return=21.0\n",
      "global_step=1632, episodic_return=21.0\n",
      "global_step=1656, episodic_return=20.0\n",
      "global_step=1664, episodic_return=26.0\n",
      "global_step=1664, episodic_return=13.0\n",
      "global_step=1672, episodic_return=20.0\n",
      "global_step=1688, episodic_return=22.0\n",
      "global_step=1760, episodic_return=16.0\n",
      "global_step=1768, episodic_return=10.0\n",
      "global_step=1792, episodic_return=16.0\n",
      "global_step=1848, episodic_return=23.0\n",
      "global_step=1880, episodic_return=28.0\n",
      "global_step=1896, episodic_return=13.0\n",
      "global_step=1944, episodic_return=34.0\n",
      "global_step=1968, episodic_return=26.0\n",
      "global_step=2016, episodic_return=61.0\n",
      "global_step=2024, episodic_return=57.0\n",
      "SPS: 97\n",
      "global_step=2064, episodic_return=23.0\n",
      "global_step=2080, episodic_return=29.0\n",
      "global_step=2080, episodic_return=17.0\n",
      "global_step=2088, episodic_return=15.0\n",
      "global_step=2104, episodic_return=42.0\n",
      "global_step=2120, episodic_return=28.0\n",
      "global_step=2152, episodic_return=17.0\n",
      "global_step=2192, episodic_return=16.0\n",
      "global_step=2216, episodic_return=14.0\n",
      "global_step=2216, episodic_return=16.0\n",
      "global_step=2264, episodic_return=23.0\n",
      "global_step=2304, episodic_return=23.0\n",
      "global_step=2304, episodic_return=35.0\n",
      "global_step=2304, episodic_return=11.0\n",
      "global_step=2304, episodic_return=28.0\n",
      "global_step=2336, episodic_return=23.0\n",
      "global_step=2344, episodic_return=10.0\n",
      "global_step=2408, episodic_return=13.0\n",
      "global_step=2424, episodic_return=10.0\n",
      "global_step=2432, episodic_return=16.0\n",
      "global_step=2432, episodic_return=12.0\n",
      "global_step=2440, episodic_return=17.0\n",
      "global_step=2464, episodic_return=34.0\n",
      "global_step=2528, episodic_return=39.0\n",
      "global_step=2584, episodic_return=19.0\n",
      "global_step=2600, episodic_return=37.0\n",
      "global_step=2608, episodic_return=22.0\n",
      "global_step=2608, episodic_return=23.0\n",
      "global_step=2616, episodic_return=26.0\n",
      "global_step=2664, episodic_return=17.0\n",
      "global_step=2720, episodic_return=17.0\n",
      "global_step=2736, episodic_return=17.0\n",
      "global_step=2752, episodic_return=18.0\n",
      "global_step=2752, episodic_return=11.0\n",
      "global_step=2792, episodic_return=41.0\n",
      "global_step=2808, episodic_return=24.0\n",
      "global_step=2824, episodic_return=27.0\n",
      "global_step=2872, episodic_return=15.0\n",
      "global_step=2904, episodic_return=14.0\n",
      "global_step=2944, episodic_return=15.0\n",
      "global_step=2944, episodic_return=26.0\n",
      "global_step=2968, episodic_return=31.0\n",
      "global_step=3040, episodic_return=75.0\n",
      "global_step=3056, episodic_return=19.0\n",
      "global_step=3072, episodic_return=16.0\n",
      "SPS: 136\n",
      "global_step=3096, episodic_return=43.0\n",
      "global_step=3136, episodic_return=12.0\n",
      "global_step=3152, episodic_return=43.0\n",
      "global_step=3184, episodic_return=16.0\n",
      "global_step=3184, episodic_return=39.0\n",
      "global_step=3200, episodic_return=32.0\n",
      "global_step=3208, episodic_return=14.0\n",
      "global_step=3248, episodic_return=35.0\n",
      "global_step=3272, episodic_return=9.0\n",
      "global_step=3272, episodic_return=11.0\n",
      "global_step=3288, episodic_return=19.0\n",
      "global_step=3304, episodic_return=29.0\n",
      "global_step=3320, episodic_return=17.0\n",
      "global_step=3328, episodic_return=10.0\n",
      "global_step=3328, episodic_return=22.0\n",
      "global_step=3352, episodic_return=18.0\n",
      "global_step=3392, episodic_return=15.0\n",
      "global_step=3416, episodic_return=14.0\n",
      "global_step=3472, episodic_return=15.0\n",
      "global_step=3496, episodic_return=28.0\n",
      "global_step=3520, episodic_return=16.0\n",
      "global_step=3536, episodic_return=31.0\n",
      "global_step=3552, episodic_return=10.0\n",
      "global_step=3592, episodic_return=12.0\n",
      "global_step=3608, episodic_return=35.0\n",
      "global_step=3648, episodic_return=29.0\n",
      "global_step=3680, episodic_return=44.0\n",
      "global_step=3696, episodic_return=18.0\n",
      "global_step=3704, episodic_return=48.0\n",
      "global_step=3728, episodic_return=26.0\n",
      "global_step=3752, episodic_return=18.0\n",
      "global_step=3752, episodic_return=13.0\n",
      "global_step=3800, episodic_return=15.0\n",
      "global_step=3800, episodic_return=13.0\n",
      "global_step=3848, episodic_return=32.0\n",
      "global_step=3864, episodic_return=41.0\n",
      "global_step=3888, episodic_return=20.0\n",
      "global_step=3896, episodic_return=12.0\n",
      "global_step=3912, episodic_return=14.0\n",
      "global_step=3920, episodic_return=21.0\n",
      "global_step=3928, episodic_return=28.0\n",
      "global_step=3936, episodic_return=23.0\n",
      "global_step=3984, episodic_return=17.0\n",
      "global_step=3984, episodic_return=11.0\n",
      "global_step=4072, episodic_return=17.0\n",
      "global_step=4088, episodic_return=20.0\n",
      "global_step=4088, episodic_return=22.0\n",
      "SPS: 137\n",
      "global_step=4104, episodic_return=15.0\n",
      "global_step=4128, episodic_return=30.0\n",
      "global_step=4176, episodic_return=32.0\n",
      "global_step=4200, episodic_return=14.0\n",
      "global_step=4208, episodic_return=17.0\n",
      "global_step=4224, episodic_return=45.0\n",
      "global_step=4288, episodic_return=38.0\n",
      "global_step=4288, episodic_return=20.0\n",
      "global_step=4344, episodic_return=32.0\n",
      "global_step=4384, episodic_return=26.0\n",
      "global_step=4408, episodic_return=26.0\n",
      "global_step=4440, episodic_return=42.0\n",
      "global_step=4440, episodic_return=27.0\n",
      "global_step=4456, episodic_return=21.0\n",
      "global_step=4504, episodic_return=20.0\n",
      "global_step=4520, episodic_return=29.0\n",
      "global_step=4528, episodic_return=11.0\n",
      "global_step=4552, episodic_return=43.0\n",
      "global_step=4560, episodic_return=13.0\n",
      "global_step=4576, episodic_return=24.0\n",
      "global_step=4608, episodic_return=10.0\n",
      "global_step=4608, episodic_return=25.0\n",
      "global_step=4624, episodic_return=23.0\n",
      "global_step=4656, episodic_return=13.0\n",
      "global_step=4688, episodic_return=23.0\n",
      "global_step=4696, episodic_return=22.0\n",
      "global_step=4712, episodic_return=13.0\n",
      "global_step=4736, episodic_return=16.0\n",
      "global_step=4752, episodic_return=12.0\n",
      "global_step=4792, episodic_return=21.0\n",
      "global_step=4792, episodic_return=29.0\n",
      "global_step=4840, episodic_return=13.0\n",
      "global_step=4856, episodic_return=20.0\n",
      "global_step=4872, episodic_return=15.0\n",
      "global_step=4888, episodic_return=25.0\n",
      "global_step=4952, episodic_return=14.0\n",
      "global_step=4952, episodic_return=10.0\n",
      "global_step=4992, episodic_return=52.0\n",
      "global_step=5000, episodic_return=18.0\n",
      "global_step=5024, episodic_return=17.0\n",
      "global_step=5104, episodic_return=19.0\n",
      "global_step=5120, episodic_return=41.0\n",
      "SPS: 165\n",
      "global_step=5160, episodic_return=46.0\n",
      "global_step=5184, episodic_return=24.0\n",
      "global_step=5224, episodic_return=15.0\n",
      "global_step=5224, episodic_return=64.0\n",
      "global_step=5232, episodic_return=29.0\n",
      "global_step=5240, episodic_return=15.0\n",
      "global_step=5288, episodic_return=42.0\n",
      "global_step=5304, episodic_return=15.0\n",
      "global_step=5328, episodic_return=21.0\n",
      "global_step=5328, episodic_return=13.0\n",
      "global_step=5376, episodic_return=44.0\n",
      "global_step=5376, episodic_return=18.0\n",
      "global_step=5384, episodic_return=10.0\n",
      "global_step=5392, episodic_return=13.0\n",
      "global_step=5408, episodic_return=23.0\n",
      "global_step=5440, episodic_return=25.0\n",
      "global_step=5448, episodic_return=15.0\n",
      "global_step=5520, episodic_return=24.0\n",
      "global_step=5544, episodic_return=17.0\n",
      "global_step=5544, episodic_return=20.0\n",
      "global_step=5592, episodic_return=18.0\n",
      "global_step=5640, episodic_return=33.0\n",
      "global_step=5648, episodic_return=32.0\n",
      "global_step=5656, episodic_return=17.0\n",
      "global_step=5664, episodic_return=15.0\n",
      "global_step=5680, episodic_return=17.0\n",
      "global_step=5736, episodic_return=37.0\n",
      "global_step=5760, episodic_return=21.0\n",
      "global_step=5784, episodic_return=17.0\n",
      "global_step=5792, episodic_return=52.0\n",
      "global_step=5824, episodic_return=20.0\n",
      "global_step=5824, episodic_return=23.0\n",
      "global_step=5880, episodic_return=18.0\n",
      "global_step=5920, episodic_return=20.0\n",
      "global_step=5920, episodic_return=12.0\n",
      "global_step=5928, episodic_return=34.0\n",
      "global_step=5944, episodic_return=19.0\n",
      "global_step=5992, episodic_return=21.0\n",
      "global_step=6048, episodic_return=21.0\n",
      "global_step=6064, episodic_return=17.0\n",
      "global_step=6088, episodic_return=21.0\n",
      "global_step=6112, episodic_return=41.0\n",
      "global_step=6112, episodic_return=15.0\n",
      "SPS: 152\n",
      "global_step=6184, episodic_return=30.0\n",
      "global_step=6200, episodic_return=35.0\n",
      "global_step=6240, episodic_return=22.0\n",
      "global_step=6240, episodic_return=19.0\n",
      "global_step=6304, episodic_return=78.0\n",
      "global_step=6312, episodic_return=25.0\n",
      "global_step=6344, episodic_return=13.0\n",
      "global_step=6400, episodic_return=25.0\n",
      "global_step=6424, episodic_return=15.0\n",
      "global_step=6432, episodic_return=31.0\n",
      "global_step=6448, episodic_return=17.0\n",
      "global_step=6456, episodic_return=51.0\n",
      "global_step=6456, episodic_return=14.0\n",
      "global_step=6480, episodic_return=46.0\n",
      "global_step=6520, episodic_return=35.0\n",
      "global_step=6536, episodic_return=14.0\n",
      "global_step=6552, episodic_return=15.0\n",
      "global_step=6568, episodic_return=14.0\n",
      "global_step=6616, episodic_return=27.0\n",
      "global_step=6632, episodic_return=19.0\n",
      "global_step=6632, episodic_return=22.0\n",
      "global_step=6640, episodic_return=13.0\n",
      "global_step=6656, episodic_return=11.0\n",
      "global_step=6744, episodic_return=14.0\n",
      "global_step=6752, episodic_return=29.0\n",
      "global_step=6760, episodic_return=26.0\n",
      "global_step=6768, episodic_return=17.0\n",
      "global_step=6880, episodic_return=33.0\n",
      "global_step=6904, episodic_return=17.0\n",
      "global_step=6944, episodic_return=36.0\n",
      "global_step=6952, episodic_return=25.0\n",
      "global_step=6984, episodic_return=28.0\n",
      "global_step=6992, episodic_return=44.0\n",
      "global_step=6992, episodic_return=14.0\n",
      "global_step=7016, episodic_return=71.0\n",
      "global_step=7120, episodic_return=27.0\n",
      "global_step=7136, episodic_return=49.0\n",
      "global_step=7136, episodic_return=24.0\n",
      "global_step=7144, episodic_return=20.0\n",
      "SPS: 168\n",
      "global_step=7208, episodic_return=27.0\n",
      "global_step=7208, episodic_return=32.0\n",
      "global_step=7232, episodic_return=27.0\n",
      "global_step=7240, episodic_return=31.0\n",
      "global_step=7256, episodic_return=15.0\n",
      "global_step=7296, episodic_return=11.0\n",
      "global_step=7312, episodic_return=22.0\n",
      "global_step=7384, episodic_return=18.0\n",
      "global_step=7392, episodic_return=23.0\n",
      "global_step=7448, episodic_return=17.0\n",
      "global_step=7456, episodic_return=39.0\n",
      "global_step=7488, episodic_return=24.0\n",
      "global_step=7504, episodic_return=31.0\n",
      "global_step=7528, episodic_return=17.0\n",
      "global_step=7536, episodic_return=11.0\n",
      "global_step=7536, episodic_return=38.0\n",
      "global_step=7608, episodic_return=19.0\n",
      "global_step=7624, episodic_return=15.0\n",
      "global_step=7696, episodic_return=20.0\n",
      "global_step=7696, episodic_return=11.0\n",
      "global_step=7784, episodic_return=50.0\n",
      "global_step=7800, episodic_return=13.0\n",
      "global_step=7832, episodic_return=89.0\n",
      "global_step=7840, episodic_return=27.0\n",
      "global_step=7856, episodic_return=46.0\n",
      "global_step=7912, episodic_return=14.0\n",
      "global_step=7944, episodic_return=51.0\n",
      "global_step=7968, episodic_return=16.0\n",
      "global_step=8000, episodic_return=59.0\n",
      "global_step=8024, episodic_return=10.0\n",
      "global_step=8040, episodic_return=32.0\n",
      "global_step=8056, episodic_return=28.0\n",
      "global_step=8104, episodic_return=13.0\n",
      "global_step=8120, episodic_return=33.0\n",
      "global_step=8128, episodic_return=11.0\n",
      "global_step=8184, episodic_return=61.0\n",
      "global_step=8184, episodic_return=16.0\n",
      "global_step=8184, episodic_return=34.0\n",
      "SPS: 151\n",
      "global_step=8216, episodic_return=12.0\n",
      "global_step=8240, episodic_return=34.0\n",
      "global_step=8272, episodic_return=31.0\n",
      "global_step=8280, episodic_return=22.0\n",
      "global_step=8280, episodic_return=12.0\n",
      "global_step=8312, episodic_return=23.0\n",
      "global_step=8360, episodic_return=22.0\n",
      "global_step=8368, episodic_return=16.0\n",
      "global_step=8376, episodic_return=12.0\n",
      "global_step=8400, episodic_return=27.0\n",
      "global_step=8480, episodic_return=25.0\n",
      "global_step=8480, episodic_return=33.0\n",
      "global_step=8520, episodic_return=31.0\n",
      "global_step=8520, episodic_return=26.0\n",
      "global_step=8544, episodic_return=23.0\n",
      "global_step=8568, episodic_return=21.0\n",
      "global_step=8608, episodic_return=29.0\n",
      "global_step=8624, episodic_return=32.0\n",
      "global_step=8688, episodic_return=21.0\n",
      "global_step=8688, episodic_return=18.0\n",
      "global_step=8736, episodic_return=14.0\n",
      "global_step=8736, episodic_return=32.0\n",
      "global_step=8808, episodic_return=41.0\n",
      "global_step=8864, episodic_return=32.0\n",
      "global_step=8888, episodic_return=40.0\n",
      "global_step=8920, episodic_return=23.0\n",
      "global_step=8936, episodic_return=52.0\n",
      "global_step=8960, episodic_return=34.0\n",
      "global_step=8984, episodic_return=37.0\n",
      "global_step=9008, episodic_return=18.0\n",
      "global_step=9016, episodic_return=35.0\n",
      "global_step=9072, episodic_return=23.0\n",
      "global_step=9080, episodic_return=20.0\n",
      "global_step=9120, episodic_return=39.0\n",
      "global_step=9160, episodic_return=10.0\n",
      "global_step=9168, episodic_return=26.0\n",
      "global_step=9216, episodic_return=18.0\n",
      "SPS: 165\n",
      "global_step=9232, episodic_return=37.0\n",
      "global_step=9232, episodic_return=31.0\n",
      "global_step=9264, episodic_return=18.0\n",
      "global_step=9264, episodic_return=32.0\n",
      "global_step=9336, episodic_return=21.0\n",
      "global_step=9336, episodic_return=40.0\n",
      "global_step=9368, episodic_return=26.0\n",
      "global_step=9392, episodic_return=16.0\n",
      "global_step=9424, episodic_return=26.0\n",
      "global_step=9424, episodic_return=11.0\n",
      "global_step=9432, episodic_return=25.0\n",
      "global_step=9472, episodic_return=26.0\n",
      "global_step=9512, episodic_return=22.0\n",
      "global_step=9536, episodic_return=38.0\n",
      "global_step=9600, episodic_return=16.0\n",
      "global_step=9616, episodic_return=31.0\n",
      "global_step=9624, episodic_return=29.0\n",
      "global_step=9632, episodic_return=15.0\n",
      "global_step=9704, episodic_return=35.0\n",
      "global_step=9720, episodic_return=13.0\n",
      "global_step=9744, episodic_return=40.0\n",
      "global_step=9760, episodic_return=17.0\n",
      "global_step=9776, episodic_return=43.0\n",
      "global_step=9784, episodic_return=19.0\n",
      "global_step=9808, episodic_return=26.0\n",
      "global_step=9848, episodic_return=13.0\n",
      "global_step=9856, episodic_return=12.0\n",
      "global_step=9896, episodic_return=14.0\n",
      "global_step=9952, episodic_return=13.0\n",
      "global_step=9968, episodic_return=31.0\n",
      "global_step=10008, episodic_return=19.0\n",
      "global_step=10016, episodic_return=30.0\n",
      "global_step=10096, episodic_return=36.0\n",
      "global_step=10112, episodic_return=18.0\n",
      "global_step=10120, episodic_return=28.0\n",
      "global_step=10144, episodic_return=16.0\n",
      "global_step=10200, episodic_return=24.0\n",
      "global_step=10240, episodic_return=16.0\n",
      "SPS: 159\n",
      "global_step=10280, episodic_return=93.0\n",
      "global_step=10296, episodic_return=74.0\n",
      "global_step=10312, episodic_return=45.0\n",
      "global_step=10320, episodic_return=22.0\n",
      "global_step=10456, episodic_return=20.0\n",
      "global_step=10464, episodic_return=18.0\n",
      "global_step=10480, episodic_return=35.0\n",
      "global_step=10496, episodic_return=27.0\n",
      "global_step=10504, episodic_return=51.0\n",
      "global_step=10576, episodic_return=12.0\n",
      "global_step=10584, episodic_return=34.0\n",
      "global_step=10608, episodic_return=14.0\n",
      "global_step=10616, episodic_return=14.0\n",
      "global_step=10688, episodic_return=29.0\n",
      "global_step=10704, episodic_return=30.0\n",
      "global_step=10720, episodic_return=18.0\n",
      "global_step=10720, episodic_return=60.0\n",
      "global_step=10744, episodic_return=78.0\n",
      "global_step=10800, episodic_return=27.0\n",
      "global_step=10896, episodic_return=12.0\n",
      "global_step=10920, episodic_return=29.0\n",
      "global_step=10920, episodic_return=38.0\n",
      "global_step=10928, episodic_return=26.0\n",
      "global_step=10944, episodic_return=28.0\n",
      "global_step=10968, episodic_return=28.0\n",
      "global_step=10984, episodic_return=11.0\n",
      "global_step=11000, episodic_return=49.0\n",
      "global_step=11032, episodic_return=14.0\n",
      "global_step=11048, episodic_return=10.0\n",
      "global_step=11056, episodic_return=16.0\n",
      "global_step=11064, episodic_return=45.0\n",
      "global_step=11120, episodic_return=25.0\n",
      "global_step=11184, episodic_return=17.0\n",
      "global_step=11192, episodic_return=24.0\n",
      "global_step=11208, episodic_return=28.0\n",
      "global_step=11216, episodic_return=34.0\n",
      "SPS: 171\n",
      "global_step=11272, episodic_return=19.0\n",
      "global_step=11296, episodic_return=29.0\n",
      "global_step=11312, episodic_return=12.0\n",
      "global_step=11352, episodic_return=18.0\n",
      "global_step=11368, episodic_return=42.0\n",
      "global_step=11376, episodic_return=23.0\n",
      "global_step=11384, episodic_return=41.0\n",
      "global_step=11464, episodic_return=35.0\n",
      "global_step=11488, episodic_return=24.0\n",
      "global_step=11520, episodic_return=19.0\n",
      "global_step=11536, episodic_return=20.0\n",
      "global_step=11560, episodic_return=26.0\n",
      "global_step=11592, episodic_return=40.0\n",
      "global_step=11592, episodic_return=16.0\n",
      "global_step=11616, episodic_return=29.0\n",
      "global_step=11640, episodic_return=41.0\n",
      "global_step=11672, episodic_return=19.0\n",
      "global_step=11704, episodic_return=14.0\n",
      "global_step=11712, episodic_return=12.0\n",
      "global_step=11752, episodic_return=33.0\n",
      "global_step=11816, episodic_return=13.0\n",
      "global_step=11816, episodic_return=35.0\n",
      "global_step=11864, episodic_return=34.0\n",
      "global_step=11864, episodic_return=24.0\n",
      "global_step=11920, episodic_return=35.0\n",
      "global_step=11952, episodic_return=31.0\n",
      "global_step=11992, episodic_return=16.0\n",
      "global_step=12024, episodic_return=20.0\n",
      "global_step=12040, episodic_return=28.0\n",
      "global_step=12096, episodic_return=18.0\n",
      "global_step=12104, episodic_return=14.0\n",
      "global_step=12120, episodic_return=12.0\n",
      "global_step=12176, episodic_return=45.0\n",
      "global_step=12200, episodic_return=35.0\n",
      "global_step=12232, episodic_return=14.0\n",
      "global_step=12232, episodic_return=17.0\n",
      "global_step=12232, episodic_return=60.0\n",
      "global_step=12240, episodic_return=85.0\n",
      "SPS: 167\n",
      "global_step=12344, episodic_return=14.0\n",
      "global_step=12376, episodic_return=25.0\n",
      "global_step=12384, episodic_return=43.0\n",
      "global_step=12392, episodic_return=20.0\n",
      "global_step=12456, episodic_return=27.0\n",
      "global_step=12480, episodic_return=12.0\n",
      "global_step=12496, episodic_return=15.0\n",
      "global_step=12512, episodic_return=39.0\n",
      "global_step=12528, episodic_return=53.0\n",
      "global_step=12528, episodic_return=23.0\n",
      "global_step=12624, episodic_return=16.0\n",
      "global_step=12632, episodic_return=13.0\n",
      "global_step=12632, episodic_return=19.0\n",
      "global_step=12656, episodic_return=18.0\n",
      "global_step=12720, episodic_return=61.0\n",
      "global_step=12760, episodic_return=17.0\n",
      "global_step=12800, episodic_return=21.0\n",
      "global_step=12832, episodic_return=55.0\n",
      "global_step=12832, episodic_return=47.0\n",
      "global_step=12984, episodic_return=28.0\n",
      "global_step=13040, episodic_return=26.0\n",
      "global_step=13048, episodic_return=41.0\n",
      "global_step=13120, episodic_return=10.0\n",
      "global_step=13128, episodic_return=62.0\n",
      "global_step=13160, episodic_return=22.0\n",
      "global_step=13176, episodic_return=47.0\n",
      "global_step=13184, episodic_return=66.0\n",
      "global_step=13208, episodic_return=20.0\n",
      "global_step=13240, episodic_return=14.0\n",
      "SPS: 179\n",
      "global_step=13376, episodic_return=27.0\n",
      "global_step=13384, episodic_return=18.0\n",
      "global_step=13400, episodic_return=24.0\n",
      "global_step=13400, episodic_return=28.0\n",
      "global_step=13408, episodic_return=110.0\n",
      "global_step=13472, episodic_return=80.0\n",
      "global_step=13544, episodic_return=20.0\n",
      "global_step=13544, episodic_return=18.0\n",
      "global_step=13560, episodic_return=47.0\n",
      "global_step=13576, episodic_return=25.0\n",
      "global_step=13576, episodic_return=21.0\n",
      "global_step=13672, episodic_return=12.0\n",
      "global_step=13680, episodic_return=26.0\n",
      "global_step=13704, episodic_return=20.0\n",
      "global_step=13728, episodic_return=41.0\n",
      "global_step=13784, episodic_return=10.0\n",
      "global_step=13848, episodic_return=21.0\n",
      "global_step=13856, episodic_return=37.0\n",
      "global_step=13904, episodic_return=98.0\n",
      "global_step=13920, episodic_return=47.0\n",
      "global_step=13968, episodic_return=15.0\n",
      "global_step=13968, episodic_return=37.0\n",
      "global_step=13976, episodic_return=15.0\n",
      "global_step=14040, episodic_return=32.0\n",
      "global_step=14072, episodic_return=12.0\n",
      "global_step=14080, episodic_return=20.0\n",
      "global_step=14136, episodic_return=29.0\n",
      "global_step=14176, episodic_return=13.0\n",
      "global_step=14224, episodic_return=81.0\n",
      "global_step=14232, episodic_return=12.0\n",
      "global_step=14256, episodic_return=27.0\n",
      "global_step=14304, episodic_return=16.0\n",
      "global_step=14304, episodic_return=10.0\n",
      "global_step=14336, episodic_return=32.0\n",
      "SPS: 176\n",
      "global_step=14344, episodic_return=47.0\n",
      "global_step=14376, episodic_return=18.0\n",
      "global_step=14432, episodic_return=88.0\n",
      "global_step=14464, episodic_return=62.0\n",
      "global_step=14592, episodic_return=20.0\n",
      "global_step=14640, episodic_return=42.0\n",
      "global_step=14640, episodic_return=42.0\n",
      "global_step=14696, episodic_return=45.0\n",
      "global_step=14712, episodic_return=42.0\n",
      "global_step=14728, episodic_return=48.0\n",
      "global_step=14752, episodic_return=14.0\n",
      "global_step=14760, episodic_return=15.0\n",
      "global_step=14760, episodic_return=21.0\n",
      "global_step=14880, episodic_return=52.0\n",
      "global_step=14904, episodic_return=19.0\n",
      "global_step=14904, episodic_return=22.0\n",
      "global_step=14912, episodic_return=82.0\n",
      "global_step=15008, episodic_return=16.0\n",
      "global_step=15016, episodic_return=38.0\n",
      "global_step=15048, episodic_return=44.0\n",
      "global_step=15064, episodic_return=20.0\n",
      "global_step=15088, episodic_return=22.0\n",
      "global_step=15104, episodic_return=25.0\n",
      "global_step=15176, episodic_return=52.0\n",
      "global_step=15184, episodic_return=17.0\n",
      "global_step=15304, episodic_return=25.0\n",
      "global_step=15320, episodic_return=17.0\n",
      "global_step=15344, episodic_return=73.0\n",
      "global_step=15352, episodic_return=42.0\n",
      "SPS: 186\n",
      "global_step=15376, episodic_return=46.0\n",
      "global_step=15392, episodic_return=41.0\n",
      "global_step=15416, episodic_return=30.0\n",
      "global_step=15496, episodic_return=15.0\n",
      "global_step=15504, episodic_return=11.0\n",
      "global_step=15536, episodic_return=29.0\n",
      "global_step=15568, episodic_return=22.0\n",
      "global_step=15584, episodic_return=33.0\n",
      "global_step=15584, episodic_return=30.0\n",
      "global_step=15592, episodic_return=12.0\n",
      "global_step=15648, episodic_return=37.0\n",
      "global_step=15696, episodic_return=14.0\n",
      "global_step=15744, episodic_return=82.0\n",
      "global_step=15768, episodic_return=25.0\n",
      "global_step=15784, episodic_return=24.0\n",
      "global_step=15800, episodic_return=37.0\n",
      "global_step=15800, episodic_return=13.0\n",
      "global_step=15912, episodic_return=41.0\n",
      "global_step=15920, episodic_return=48.0\n",
      "global_step=15976, episodic_return=26.0\n",
      "global_step=16056, episodic_return=39.0\n",
      "global_step=16080, episodic_return=35.0\n",
      "global_step=16128, episodic_return=41.0\n",
      "global_step=16144, episodic_return=28.0\n",
      "global_step=16304, episodic_return=22.0\n",
      "global_step=16360, episodic_return=89.0\n",
      "global_step=16360, episodic_return=38.0\n",
      "SPS: 181\n",
      "global_step=16512, episodic_return=91.0\n",
      "global_step=16584, episodic_return=63.0\n",
      "global_step=16616, episodic_return=80.0\n",
      "global_step=16648, episodic_return=17.0\n",
      "global_step=16664, episodic_return=65.0\n",
      "global_step=16688, episodic_return=97.0\n",
      "global_step=16720, episodic_return=45.0\n",
      "global_step=16768, episodic_return=58.0\n",
      "global_step=16784, episodic_return=21.0\n",
      "global_step=16808, episodic_return=11.0\n",
      "global_step=16840, episodic_return=19.0\n",
      "global_step=16864, episodic_return=27.0\n",
      "global_step=16936, episodic_return=72.0\n",
      "global_step=16960, episodic_return=22.0\n",
      "global_step=17016, episodic_return=44.0\n",
      "global_step=17072, episodic_return=33.0\n",
      "global_step=17088, episodic_return=63.0\n",
      "global_step=17112, episodic_return=31.0\n",
      "global_step=17136, episodic_return=25.0\n",
      "global_step=17152, episodic_return=17.0\n",
      "global_step=17240, episodic_return=35.0\n",
      "global_step=17240, episodic_return=50.0\n",
      "global_step=17304, episodic_return=27.0\n",
      "global_step=17376, episodic_return=30.0\n",
      "global_step=17392, episodic_return=19.0\n",
      "global_step=17392, episodic_return=40.0\n",
      "SPS: 191\n",
      "global_step=17424, episodic_return=39.0\n",
      "global_step=17496, episodic_return=15.0\n",
      "global_step=17584, episodic_return=54.0\n",
      "global_step=17600, episodic_return=26.0\n",
      "global_step=17632, episodic_return=41.0\n",
      "global_step=17656, episodic_return=20.0\n",
      "global_step=17664, episodic_return=30.0\n",
      "global_step=17720, episodic_return=119.0\n",
      "global_step=17752, episodic_return=64.0\n",
      "global_step=17784, episodic_return=49.0\n",
      "global_step=17872, episodic_return=34.0\n",
      "global_step=17888, episodic_return=28.0\n",
      "global_step=17912, episodic_return=32.0\n",
      "global_step=17920, episodic_return=36.0\n",
      "global_step=18072, episodic_return=61.0\n",
      "global_step=18088, episodic_return=21.0\n",
      "global_step=18104, episodic_return=24.0\n",
      "global_step=18120, episodic_return=50.0\n",
      "global_step=18248, episodic_return=62.0\n",
      "global_step=18280, episodic_return=24.0\n",
      "global_step=18288, episodic_return=21.0\n",
      "global_step=18288, episodic_return=27.0\n",
      "global_step=18312, episodic_return=53.0\n",
      "global_step=18344, episodic_return=70.0\n",
      "global_step=18368, episodic_return=33.0\n",
      "global_step=18400, episodic_return=11.0\n",
      "global_step=18432, episodic_return=18.0\n",
      "SPS: 186\n",
      "global_step=18712, episodic_return=35.0\n",
      "global_step=18744, episodic_return=62.0\n",
      "global_step=18744, episodic_return=58.0\n",
      "global_step=18752, episodic_return=48.0\n",
      "global_step=18904, episodic_return=24.0\n",
      "global_step=18936, episodic_return=74.0\n",
      "global_step=18976, episodic_return=72.0\n",
      "global_step=19000, episodic_return=32.0\n",
      "global_step=19088, episodic_return=19.0\n",
      "global_step=19088, episodic_return=152.0\n",
      "global_step=19128, episodic_return=28.0\n",
      "global_step=19136, episodic_return=106.0\n",
      "global_step=19160, episodic_return=20.0\n",
      "global_step=19208, episodic_return=29.0\n",
      "global_step=19240, episodic_return=62.0\n",
      "global_step=19256, episodic_return=21.0\n",
      "global_step=19280, episodic_return=15.0\n",
      "global_step=19336, episodic_return=10.0\n",
      "global_step=19336, episodic_return=12.0\n",
      "global_step=19424, episodic_return=37.0\n",
      "SPS: 194\n",
      "global_step=19464, episodic_return=23.0\n",
      "global_step=19488, episodic_return=35.0\n",
      "global_step=19608, episodic_return=34.0\n",
      "global_step=19624, episodic_return=61.0\n",
      "global_step=19632, episodic_return=26.0\n",
      "global_step=19640, episodic_return=111.0\n",
      "global_step=19648, episodic_return=23.0\n",
      "global_step=19696, episodic_return=76.0\n",
      "global_step=19712, episodic_return=28.0\n",
      "global_step=19744, episodic_return=51.0\n",
      "global_step=19760, episodic_return=14.0\n",
      "global_step=19832, episodic_return=26.0\n",
      "global_step=19880, episodic_return=34.0\n",
      "global_step=19896, episodic_return=25.0\n",
      "global_step=19944, episodic_return=29.0\n",
      "global_step=20032, episodic_return=11.0\n",
      "global_step=20032, episodic_return=50.0\n",
      "global_step=20064, episodic_return=21.0\n",
      "global_step=20112, episodic_return=35.0\n",
      "global_step=20120, episodic_return=45.0\n",
      "global_step=20160, episodic_return=65.0\n",
      "global_step=20224, episodic_return=60.0\n",
      "global_step=20224, episodic_return=20.0\n",
      "global_step=20232, episodic_return=44.0\n",
      "global_step=20272, episodic_return=20.0\n",
      "global_step=20312, episodic_return=35.0\n",
      "global_step=20400, episodic_return=22.0\n",
      "global_step=20480, episodic_return=40.0\n",
      "SPS: 186\n",
      "global_step=20552, episodic_return=40.0\n",
      "global_step=20584, episodic_return=45.0\n",
      "global_step=20608, episodic_return=61.0\n",
      "global_step=20712, episodic_return=85.0\n",
      "global_step=20752, episodic_return=55.0\n",
      "global_step=20752, episodic_return=21.0\n",
      "global_step=20776, episodic_return=21.0\n",
      "global_step=20792, episodic_return=65.0\n",
      "global_step=20816, episodic_return=42.0\n",
      "global_step=20872, episodic_return=59.0\n",
      "global_step=20968, episodic_return=27.0\n",
      "global_step=20984, episodic_return=54.0\n",
      "global_step=21016, episodic_return=28.0\n",
      "global_step=21112, episodic_return=18.0\n",
      "global_step=21224, episodic_return=64.0\n",
      "global_step=21240, episodic_return=61.0\n",
      "global_step=21304, episodic_return=40.0\n",
      "global_step=21392, episodic_return=72.0\n",
      "global_step=21408, episodic_return=49.0\n",
      "SPS: 194\n",
      "global_step=21520, episodic_return=93.0\n",
      "global_step=21528, episodic_return=15.0\n",
      "global_step=21544, episodic_return=40.0\n",
      "global_step=21568, episodic_return=87.0\n",
      "global_step=21720, episodic_return=24.0\n",
      "global_step=21768, episodic_return=66.0\n",
      "global_step=21800, episodic_return=32.0\n",
      "global_step=21912, episodic_return=18.0\n",
      "global_step=21920, episodic_return=77.0\n",
      "global_step=21928, episodic_return=67.0\n",
      "global_step=21976, episodic_return=108.0\n",
      "global_step=22048, episodic_return=60.0\n",
      "global_step=22104, episodic_return=38.0\n",
      "global_step=22136, episodic_return=20.0\n",
      "global_step=22168, episodic_return=15.0\n",
      "global_step=22192, episodic_return=33.0\n",
      "global_step=22288, episodic_return=96.0\n",
      "global_step=22288, episodic_return=46.0\n",
      "global_step=22328, episodic_return=17.0\n",
      "global_step=22328, episodic_return=76.0\n",
      "global_step=22352, episodic_return=55.0\n",
      "global_step=22408, episodic_return=34.0\n",
      "global_step=22440, episodic_return=19.0\n",
      "global_step=22456, episodic_return=36.0\n",
      "global_step=22472, episodic_return=18.0\n",
      "global_step=22504, episodic_return=22.0\n",
      "SPS: 187\n",
      "global_step=22632, episodic_return=16.0\n",
      "global_step=22640, episodic_return=44.0\n",
      "global_step=22696, episodic_return=32.0\n",
      "global_step=22744, episodic_return=80.0\n",
      "global_step=22784, episodic_return=47.0\n",
      "global_step=22816, episodic_return=15.0\n",
      "global_step=22872, episodic_return=52.0\n",
      "global_step=23008, episodic_return=82.0\n",
      "global_step=23040, episodic_return=51.0\n",
      "global_step=23072, episodic_return=75.0\n",
      "global_step=23096, episodic_return=35.0\n",
      "global_step=23184, episodic_return=68.0\n",
      "global_step=23224, episodic_return=19.0\n",
      "global_step=23280, episodic_return=62.0\n",
      "global_step=23328, episodic_return=40.0\n",
      "global_step=23360, episodic_return=22.0\n",
      "global_step=23384, episodic_return=80.0\n",
      "global_step=23456, episodic_return=52.0\n",
      "SPS: 194\n",
      "global_step=23568, episodic_return=59.0\n",
      "global_step=23584, episodic_return=32.0\n",
      "global_step=23592, episodic_return=46.0\n",
      "global_step=23648, episodic_return=33.0\n",
      "global_step=23768, episodic_return=112.0\n",
      "global_step=23832, episodic_return=33.0\n",
      "global_step=23872, episodic_return=35.0\n",
      "global_step=23992, episodic_return=15.0\n",
      "global_step=24000, episodic_return=80.0\n",
      "global_step=24000, episodic_return=21.0\n",
      "global_step=24016, episodic_return=54.0\n",
      "global_step=24056, episodic_return=97.0\n",
      "global_step=24104, episodic_return=81.0\n",
      "global_step=24112, episodic_return=43.0\n",
      "global_step=24152, episodic_return=63.0\n",
      "global_step=24248, episodic_return=24.0\n",
      "global_step=24392, episodic_return=30.0\n",
      "global_step=24408, episodic_return=38.0\n",
      "global_step=24480, episodic_return=46.0\n",
      "global_step=24544, episodic_return=19.0\n",
      "SPS: 188\n",
      "global_step=24600, episodic_return=75.0\n",
      "global_step=24608, episodic_return=74.0\n",
      "global_step=24632, episodic_return=79.0\n",
      "global_step=24648, episodic_return=21.0\n",
      "global_step=24688, episodic_return=87.0\n",
      "global_step=24704, episodic_return=13.0\n",
      "global_step=24720, episodic_return=22.0\n",
      "global_step=24728, episodic_return=60.0\n",
      "global_step=24840, episodic_return=15.0\n",
      "global_step=24848, episodic_return=30.0\n",
      "global_step=24856, episodic_return=56.0\n",
      "global_step=24936, episodic_return=29.0\n",
      "global_step=24960, episodic_return=39.0\n",
      "global_step=24992, episodic_return=45.0\n",
      "global_step=25176, episodic_return=40.0\n",
      "global_step=25224, episodic_return=36.0\n",
      "global_step=25280, episodic_return=74.0\n",
      "global_step=25416, episodic_return=53.0\n",
      "global_step=25448, episodic_return=75.0\n",
      "global_step=25472, episodic_return=37.0\n",
      "global_step=25536, episodic_return=87.0\n",
      "global_step=25592, episodic_return=108.0\n",
      "SPS: 194\n",
      "global_step=25608, episodic_return=24.0\n",
      "global_step=25640, episodic_return=52.0\n",
      "global_step=25928, episodic_return=40.0\n",
      "global_step=25984, episodic_return=43.0\n",
      "global_step=26080, episodic_return=140.0\n",
      "global_step=26112, episodic_return=104.0\n",
      "global_step=26120, episodic_return=84.0\n",
      "global_step=26160, episodic_return=22.0\n",
      "global_step=26192, episodic_return=75.0\n",
      "global_step=26328, episodic_return=31.0\n",
      "global_step=26344, episodic_return=28.0\n",
      "global_step=26376, episodic_return=23.0\n",
      "global_step=26456, episodic_return=66.0\n",
      "SPS: 184\n",
      "global_step=26640, episodic_return=37.0\n",
      "global_step=26680, episodic_return=44.0\n",
      "global_step=26768, episodic_return=82.0\n",
      "global_step=26824, episodic_return=56.0\n",
      "global_step=26880, episodic_return=53.0\n",
      "global_step=26880, episodic_return=168.0\n",
      "global_step=26888, episodic_return=177.0\n",
      "global_step=27096, episodic_return=57.0\n",
      "global_step=27128, episodic_return=38.0\n",
      "global_step=27216, episodic_return=67.0\n",
      "global_step=27304, episodic_return=143.0\n",
      "global_step=27368, episodic_return=34.0\n",
      "global_step=27576, episodic_return=101.0\n",
      "global_step=27576, episodic_return=56.0\n",
      "global_step=27624, episodic_return=93.0\n",
      "global_step=27640, episodic_return=95.0\n",
      "SPS: 190\n",
      "global_step=27680, episodic_return=47.0\n",
      "global_step=27720, episodic_return=18.0\n",
      "global_step=27752, episodic_return=16.0\n",
      "global_step=27976, episodic_return=95.0\n",
      "global_step=28024, episodic_return=142.0\n",
      "global_step=28056, episodic_return=86.0\n",
      "global_step=28072, episodic_return=40.0\n",
      "global_step=28104, episodic_return=48.0\n",
      "global_step=28192, episodic_return=15.0\n",
      "global_step=28264, episodic_return=36.0\n",
      "global_step=28344, episodic_return=30.0\n",
      "global_step=28408, episodic_return=96.0\n",
      "global_step=28496, episodic_return=115.0\n",
      "global_step=28504, episodic_return=103.0\n",
      "global_step=28552, episodic_return=62.0\n",
      "global_step=28560, episodic_return=67.0\n",
      "global_step=28664, episodic_return=32.0\n",
      "SPS: 177\n",
      "global_step=28712, episodic_return=26.0\n",
      "global_step=28728, episodic_return=22.0\n",
      "global_step=28928, episodic_return=33.0\n",
      "global_step=28944, episodic_return=75.0\n",
      "global_step=29032, episodic_return=96.0\n",
      "global_step=29216, episodic_return=61.0\n",
      "global_step=29264, episodic_return=40.0\n",
      "global_step=29296, episodic_return=92.0\n",
      "global_step=29360, episodic_return=146.0\n",
      "global_step=29400, episodic_return=13.0\n",
      "global_step=29544, episodic_return=131.0\n",
      "global_step=29552, episodic_return=19.0\n",
      "global_step=29552, episodic_return=78.0\n",
      "global_step=29592, episodic_return=70.0\n",
      "global_step=29632, episodic_return=11.0\n",
      "global_step=29640, episodic_return=116.0\n",
      "global_step=29648, episodic_return=36.0\n",
      "global_step=29688, episodic_return=59.0\n",
      "SPS: 183\n",
      "global_step=29712, episodic_return=56.0\n",
      "global_step=29856, episodic_return=38.0\n",
      "global_step=30064, episodic_return=44.0\n",
      "global_step=30104, episodic_return=52.0\n",
      "global_step=30216, episodic_return=73.0\n",
      "global_step=30376, episodic_return=103.0\n",
      "global_step=30408, episodic_return=95.0\n",
      "global_step=30432, episodic_return=72.0\n",
      "global_step=30520, episodic_return=110.0\n",
      "global_step=30552, episodic_return=61.0\n",
      "global_step=30560, episodic_return=57.0\n",
      "global_step=30592, episodic_return=125.0\n",
      "SPS: 171\n",
      "global_step=30776, episodic_return=70.0\n",
      "global_step=30792, episodic_return=30.0\n",
      "global_step=30872, episodic_return=44.0\n",
      "global_step=30936, episodic_return=43.0\n",
      "global_step=30976, episodic_return=13.0\n",
      "global_step=31032, episodic_return=82.0\n",
      "global_step=31040, episodic_return=76.0\n",
      "global_step=31072, episodic_return=37.0\n",
      "global_step=31088, episodic_return=66.0\n",
      "SPS: 176\n",
      "global_step=31784, episodic_return=93.0\n",
      "global_step=31856, episodic_return=110.0\n",
      "global_step=31880, episodic_return=106.0\n",
      "global_step=31904, episodic_return=139.0\n",
      "global_step=31928, episodic_return=105.0\n",
      "global_step=32104, episodic_return=146.0\n",
      "global_step=32224, episodic_return=227.0\n",
      "global_step=32328, episodic_return=56.0\n",
      "global_step=32352, episodic_return=53.0\n",
      "global_step=32400, episodic_return=68.0\n",
      "global_step=32480, episodic_return=176.0\n",
      "global_step=32696, episodic_return=46.0\n",
      "global_step=32752, episodic_return=50.0\n",
      "global_step=32752, episodic_return=121.0\n",
      "SPS: 167\n",
      "global_step=32992, episodic_return=111.0\n",
      "global_step=33024, episodic_return=34.0\n",
      "global_step=33208, episodic_return=123.0\n",
      "global_step=33336, episodic_return=179.0\n",
      "global_step=33368, episodic_return=47.0\n",
      "global_step=33576, episodic_return=46.0\n",
      "global_step=33592, episodic_return=28.0\n",
      "global_step=33616, episodic_return=35.0\n",
      "global_step=33784, episodic_return=163.0\n",
      "SPS: 171\n",
      "global_step=33848, episodic_return=181.0\n",
      "global_step=33888, episodic_return=149.0\n",
      "global_step=34000, episodic_return=122.0\n",
      "global_step=34008, episodic_return=157.0\n",
      "global_step=34096, episodic_return=39.0\n",
      "global_step=34168, episodic_return=72.0\n",
      "global_step=34184, episodic_return=71.0\n",
      "global_step=34272, episodic_return=87.0\n",
      "global_step=34440, episodic_return=55.0\n",
      "global_step=34624, episodic_return=57.0\n",
      "global_step=34680, episodic_return=62.0\n",
      "global_step=34720, episodic_return=35.0\n",
      "global_step=34768, episodic_return=110.0\n",
      "global_step=34776, episodic_return=19.0\n",
      "global_step=34808, episodic_return=89.0\n",
      "SPS: 160\n",
      "global_step=34992, episodic_return=123.0\n",
      "global_step=35248, episodic_return=32.0\n",
      "global_step=35368, episodic_return=81.0\n",
      "global_step=35384, episodic_return=72.0\n",
      "global_step=35520, episodic_return=156.0\n",
      "global_step=35520, episodic_return=105.0\n",
      "global_step=35616, episodic_return=46.0\n",
      "global_step=35696, episodic_return=116.0\n",
      "global_step=35712, episodic_return=24.0\n",
      "global_step=35736, episodic_return=120.0\n",
      "global_step=35768, episodic_return=48.0\n",
      "global_step=35824, episodic_return=38.0\n",
      "SPS: 164\n",
      "global_step=36312, episodic_return=68.0\n",
      "global_step=36312, episodic_return=308.0\n",
      "global_step=36512, episodic_return=25.0\n",
      "global_step=36528, episodic_return=104.0\n",
      "global_step=36528, episodic_return=99.0\n",
      "global_step=36584, episodic_return=152.0\n",
      "global_step=36672, episodic_return=132.0\n",
      "global_step=36848, episodic_return=40.0\n",
      "SPS: 156\n",
      "global_step=36888, episodic_return=47.0\n",
      "global_step=37224, episodic_return=175.0\n",
      "global_step=37408, episodic_return=103.0\n",
      "global_step=37544, episodic_return=154.0\n",
      "global_step=37648, episodic_return=95.0\n",
      "global_step=37736, episodic_return=111.0\n",
      "global_step=37832, episodic_return=163.0\n",
      "SPS: 160\n",
      "global_step=37936, episodic_return=158.0\n",
      "global_step=38008, episodic_return=58.0\n",
      "global_step=38048, episodic_return=80.0\n",
      "global_step=38384, episodic_return=334.0\n",
      "global_step=38488, episodic_return=158.0\n",
      "global_step=38528, episodic_return=74.0\n",
      "global_step=38560, episodic_return=114.0\n",
      "global_step=38600, episodic_return=108.0\n",
      "global_step=38616, episodic_return=98.0\n",
      "global_step=38912, episodic_return=53.0\n",
      "SPS: 151\n",
      "global_step=39016, episodic_return=52.0\n",
      "global_step=39088, episodic_return=135.0\n",
      "global_step=39240, episodic_return=149.0\n",
      "global_step=39336, episodic_return=101.0\n",
      "global_step=39472, episodic_return=48.0\n",
      "global_step=39640, episodic_return=128.0\n",
      "global_step=39664, episodic_return=53.0\n",
      "global_step=39832, episodic_return=62.0\n",
      "global_step=39920, episodic_return=35.0\n",
      "SPS: 154\n",
      "global_step=39992, episodic_return=20.0\n",
      "global_step=40120, episodic_return=151.0\n",
      "global_step=40152, episodic_return=221.0\n",
      "global_step=40168, episodic_return=31.0\n",
      "global_step=40296, episodic_return=217.0\n",
      "global_step=40456, episodic_return=123.0\n",
      "global_step=40568, episodic_return=52.0\n",
      "global_step=40712, episodic_return=131.0\n",
      "global_step=40808, episodic_return=64.0\n",
      "SPS: 146\n",
      "global_step=41072, episodic_return=257.0\n",
      "global_step=41248, episodic_return=67.0\n",
      "global_step=41464, episodic_return=112.0\n",
      "global_step=41560, episodic_return=196.0\n",
      "global_step=41616, episodic_return=101.0\n",
      "global_step=41984, episodic_return=233.0\n",
      "SPS: 149\n",
      "global_step=42096, episodic_return=128.0\n",
      "global_step=42128, episodic_return=245.0\n",
      "global_step=42296, episodic_return=92.0\n",
      "global_step=42360, episodic_return=238.0\n",
      "global_step=42384, episodic_return=96.0\n",
      "global_step=42568, episodic_return=138.0\n",
      "global_step=42672, episodic_return=178.0\n",
      "global_step=42696, episodic_return=89.0\n",
      "global_step=42944, episodic_return=73.0\n",
      "global_step=42952, episodic_return=32.0\n",
      "SPS: 141\n",
      "global_step=43088, episodic_return=99.0\n",
      "global_step=43192, episodic_return=133.0\n",
      "global_step=43208, episodic_return=103.0\n",
      "global_step=43448, episodic_return=169.0\n",
      "global_step=43520, episodic_return=119.0\n",
      "global_step=43784, episodic_return=139.0\n",
      "global_step=44032, episodic_return=105.0\n",
      "SPS: 144\n",
      "global_step=44088, episodic_return=142.0\n",
      "global_step=44088, episodic_return=143.0\n",
      "global_step=44336, episodic_return=111.0\n",
      "global_step=44616, episodic_return=104.0\n",
      "global_step=44792, episodic_return=22.0\n",
      "global_step=44888, episodic_return=69.0\n",
      "global_step=44912, episodic_return=110.0\n",
      "SPS: 137\n",
      "global_step=45104, episodic_return=237.0\n",
      "global_step=45168, episodic_return=260.0\n",
      "global_step=45240, episodic_return=56.0\n",
      "global_step=45304, episodic_return=223.0\n",
      "global_step=45336, episodic_return=56.0\n",
      "global_step=45344, episodic_return=157.0\n",
      "global_step=45376, episodic_return=26.0\n",
      "global_step=45464, episodic_return=69.0\n",
      "global_step=45592, episodic_return=27.0\n",
      "global_step=45608, episodic_return=190.0\n",
      "global_step=45656, episodic_return=44.0\n",
      "global_step=45664, episodic_return=25.0\n",
      "global_step=45960, episodic_return=90.0\n",
      "SPS: 140\n",
      "global_step=46160, episodic_return=63.0\n",
      "global_step=46360, episodic_return=157.0\n",
      "global_step=46736, episodic_return=141.0\n",
      "global_step=46744, episodic_return=144.0\n",
      "global_step=47000, episodic_return=105.0\n",
      "global_step=47064, episodic_return=138.0\n",
      "global_step=47064, episodic_return=215.0\n",
      "SPS: 133\n",
      "global_step=47224, episodic_return=236.0\n",
      "global_step=47232, episodic_return=29.0\n",
      "global_step=47264, episodic_return=200.0\n",
      "global_step=47408, episodic_return=22.0\n",
      "global_step=47464, episodic_return=50.0\n",
      "global_step=47640, episodic_return=52.0\n",
      "global_step=48008, episodic_return=206.0\n",
      "global_step=48016, episodic_return=159.0\n",
      "SPS: 136\n",
      "global_step=48408, episodic_return=125.0\n",
      "global_step=48416, episodic_return=119.0\n",
      "global_step=48464, episodic_return=175.0\n",
      "global_step=48504, episodic_return=61.0\n",
      "global_step=48584, episodic_return=72.0\n",
      "global_step=48720, episodic_return=17.0\n",
      "global_step=48800, episodic_return=37.0\n",
      "global_step=48808, episodic_return=43.0\n",
      "global_step=48848, episodic_return=55.0\n",
      "global_step=48952, episodic_return=67.0\n",
      "global_step=49016, episodic_return=172.0\n",
      "global_step=49024, episodic_return=38.0\n",
      "SPS: 130\n",
      "global_step=49176, episodic_return=47.0\n",
      "global_step=49440, episodic_return=272.0\n",
      "global_step=49488, episodic_return=85.0\n",
      "global_step=49752, episodic_return=377.0\n",
      "global_step=49912, episodic_return=120.0\n",
      "global_step=50016, episodic_return=125.0\n",
      "global_step=50032, episodic_return=68.0\n",
      "global_step=50104, episodic_return=157.0\n",
      "SPS: 132\n",
      "global_step=50432, episodic_return=85.0\n",
      "global_step=50584, episodic_return=143.0\n",
      "global_step=50856, episodic_return=229.0\n",
      "global_step=50920, episodic_return=111.0\n",
      "global_step=50936, episodic_return=115.0\n",
      "global_step=50992, episodic_return=227.0\n",
      "global_step=51088, episodic_return=82.0\n",
      "SPS: 126\n",
      "global_step=51264, episodic_return=43.0\n",
      "global_step=51472, episodic_return=171.0\n",
      "global_step=51480, episodic_return=61.0\n",
      "global_step=51736, episodic_return=33.0\n",
      "global_step=51816, episodic_return=238.0\n",
      "global_step=51984, episodic_return=141.0\n",
      "SPS: 121\n",
      "global_step=52264, episodic_return=98.0\n",
      "global_step=52304, episodic_return=152.0\n",
      "global_step=52520, episodic_return=157.0\n",
      "global_step=52624, episodic_return=211.0\n",
      "global_step=52864, episodic_return=131.0\n",
      "global_step=52904, episodic_return=115.0\n",
      "global_step=53056, episodic_return=165.0\n",
      "global_step=53088, episodic_return=71.0\n",
      "SPS: 123\n",
      "global_step=53280, episodic_return=337.0\n",
      "global_step=53328, episodic_return=128.0\n",
      "global_step=53384, episodic_return=95.0\n",
      "global_step=53496, episodic_return=79.0\n",
      "global_step=53768, episodic_return=188.0\n",
      "global_step=54064, episodic_return=126.0\n",
      "SPS: 118\n",
      "global_step=54312, episodic_return=123.0\n",
      "global_step=54352, episodic_return=158.0\n",
      "global_step=54440, episodic_return=132.0\n",
      "global_step=54712, episodic_return=179.0\n",
      "global_step=54800, episodic_return=92.0\n",
      "global_step=54864, episodic_return=171.0\n",
      "global_step=54960, episodic_return=257.0\n",
      "global_step=54960, episodic_return=76.0\n",
      "global_step=55032, episodic_return=158.0\n",
      "global_step=55080, episodic_return=27.0\n",
      "global_step=55168, episodic_return=107.0\n",
      "global_step=55200, episodic_return=30.0\n",
      "SPS: 120\n",
      "global_step=55584, episodic_return=52.0\n",
      "global_step=55856, episodic_return=132.0\n",
      "global_step=55912, episodic_return=150.0\n",
      "global_step=55984, episodic_return=193.0\n",
      "global_step=56256, episodic_return=84.0\n",
      "global_step=56312, episodic_return=169.0\n",
      "SPS: 115\n",
      "global_step=56368, episodic_return=146.0\n",
      "global_step=56384, episodic_return=50.0\n",
      "global_step=56424, episodic_return=174.0\n",
      "global_step=56656, episodic_return=50.0\n",
      "global_step=57144, episodic_return=97.0\n",
      "global_step=57288, episodic_return=108.0\n",
      "SPS: 117\n",
      "global_step=57400, episodic_return=93.0\n",
      "global_step=57528, episodic_return=202.0\n",
      "global_step=57800, episodic_return=340.0\n",
      "global_step=58184, episodic_return=112.0\n",
      "global_step=58232, episodic_return=231.0\n",
      "SPS: 114\n",
      "global_step=58480, episodic_return=328.0\n",
      "global_step=58560, episodic_return=145.0\n",
      "global_step=58656, episodic_return=107.0\n",
      "global_step=58688, episodic_return=57.0\n",
      "global_step=58744, episodic_return=152.0\n",
      "global_step=58864, episodic_return=38.0\n",
      "global_step=59000, episodic_return=336.0\n",
      "global_step=59072, episodic_return=52.0\n",
      "global_step=59184, episodic_return=40.0\n",
      "SPS: 115\n",
      "global_step=59680, episodic_return=187.0\n",
      "global_step=59904, episodic_return=145.0\n",
      "global_step=60088, episodic_return=136.0\n",
      "global_step=60328, episodic_return=81.0\n",
      "SPS: 112\n",
      "global_step=60424, episodic_return=410.0\n",
      "global_step=60576, episodic_return=236.0\n",
      "global_step=60600, episodic_return=34.0\n",
      "global_step=60640, episodic_return=69.0\n",
      "global_step=60704, episodic_return=278.0\n",
      "global_step=60920, episodic_return=217.0\n",
      "global_step=61080, episodic_return=147.0\n",
      "global_step=61160, episodic_return=92.0\n",
      "global_step=61344, episodic_return=284.0\n",
      "global_step=61352, episodic_return=54.0\n",
      "SPS: 114\n",
      "global_step=61680, episodic_return=122.0\n",
      "global_step=61976, episodic_return=175.0\n",
      "global_step=62128, episodic_return=56.0\n",
      "global_step=62160, episodic_return=190.0\n",
      "global_step=62336, episodic_return=26.0\n",
      "global_step=62344, episodic_return=218.0\n",
      "SPS: 110\n",
      "global_step=62544, episodic_return=150.0\n",
      "global_step=62680, episodic_return=42.0\n",
      "global_step=62696, episodic_return=202.0\n",
      "global_step=62896, episodic_return=44.0\n",
      "global_step=62928, episodic_return=96.0\n",
      "global_step=63000, episodic_return=230.0\n",
      "global_step=63080, episodic_return=93.0\n",
      "global_step=63280, episodic_return=163.0\n",
      "global_step=63480, episodic_return=50.0\n",
      "SPS: 112\n",
      "global_step=64032, episodic_return=167.0\n",
      "global_step=64040, episodic_return=336.0\n",
      "global_step=64104, episodic_return=78.0\n",
      "global_step=64256, episodic_return=157.0\n",
      "global_step=64352, episodic_return=182.0\n",
      "global_step=64512, episodic_return=229.0\n",
      "SPS: 108\n",
      "global_step=64808, episodic_return=96.0\n",
      "global_step=64904, episodic_return=109.0\n",
      "global_step=65048, episodic_return=265.0\n",
      "global_step=65056, episodic_return=88.0\n",
      "global_step=65168, episodic_return=133.0\n",
      "global_step=65536, episodic_return=128.0\n",
      "SPS: 109\n",
      "global_step=65656, episodic_return=106.0\n",
      "global_step=65664, episodic_return=298.0\n",
      "global_step=65840, episodic_return=117.0\n",
      "global_step=66072, episodic_return=67.0\n",
      "global_step=66312, episodic_return=257.0\n",
      "SPS: 106\n",
      "global_step=66592, episodic_return=116.0\n",
      "global_step=66736, episodic_return=112.0\n",
      "global_step=66952, episodic_return=223.0\n",
      "global_step=67040, episodic_return=249.0\n",
      "global_step=67104, episodic_return=99.0\n",
      "global_step=67416, episodic_return=168.0\n",
      "global_step=67432, episodic_return=41.0\n",
      "SPS: 107\n",
      "global_step=68144, episodic_return=89.0\n",
      "global_step=68184, episodic_return=96.0\n",
      "global_step=68224, episodic_return=321.0\n",
      "global_step=68304, episodic_return=406.0\n",
      "global_step=68336, episodic_return=200.0\n",
      "global_step=68376, episodic_return=178.0\n",
      "SPS: 105\n",
      "global_step=68656, episodic_return=258.0\n",
      "global_step=68840, episodic_return=225.0\n",
      "global_step=68896, episodic_return=94.0\n",
      "global_step=69288, episodic_return=138.0\n",
      "global_step=69512, episodic_return=161.0\n",
      "SPS: 106\n",
      "global_step=69672, episodic_return=171.0\n",
      "global_step=69752, episodic_return=30.0\n",
      "global_step=69952, episodic_return=162.0\n",
      "global_step=70000, episodic_return=31.0\n",
      "global_step=70144, episodic_return=221.0\n",
      "global_step=70232, episodic_return=118.0\n",
      "global_step=70248, episodic_return=169.0\n",
      "global_step=70608, episodic_return=284.0\n",
      "SPS: 103\n",
      "global_step=70952, episodic_return=90.0\n",
      "global_step=70968, episodic_return=162.0\n",
      "global_step=71320, episodic_return=171.0\n",
      "global_step=71328, episodic_return=47.0\n",
      "global_step=71488, episodic_return=110.0\n",
      "global_step=71496, episodic_return=332.0\n",
      "global_step=71496, episodic_return=156.0\n",
      "global_step=71608, episodic_return=201.0\n",
      "SPS: 104\n",
      "global_step=71720, episodic_return=94.0\n",
      "global_step=72048, episodic_return=69.0\n",
      "global_step=72128, episodic_return=248.0\n",
      "global_step=72136, episodic_return=81.0\n",
      "global_step=72160, episodic_return=83.0\n",
      "global_step=72192, episodic_return=108.0\n",
      "global_step=72488, episodic_return=146.0\n",
      "SPS: 102\n",
      "global_step=72856, episodic_return=83.0\n",
      "global_step=72856, episodic_return=101.0\n",
      "global_step=72920, episodic_return=150.0\n",
      "global_step=73088, episodic_return=120.0\n",
      "global_step=73136, episodic_return=125.0\n",
      "global_step=73192, episodic_return=129.0\n",
      "global_step=73608, episodic_return=250.0\n",
      "SPS: 103\n",
      "global_step=73880, episodic_return=86.0\n",
      "global_step=74112, episodic_return=149.0\n",
      "global_step=74208, episodic_return=134.0\n",
      "global_step=74640, episodic_return=223.0\n",
      "global_step=74720, episodic_return=279.0\n",
      "SPS: 101\n",
      "global_step=74792, episodic_return=114.0\n",
      "global_step=75008, episodic_return=269.0\n",
      "global_step=75176, episodic_return=121.0\n",
      "global_step=75256, episodic_return=58.0\n",
      "global_step=75328, episodic_return=215.0\n",
      "global_step=75616, episodic_return=36.0\n",
      "global_step=75640, episodic_return=191.0\n",
      "global_step=75704, episodic_return=123.0\n",
      "SPS: 102\n",
      "global_step=75784, episodic_return=66.0\n",
      "global_step=75848, episodic_return=105.0\n",
      "global_step=76056, episodic_return=110.0\n",
      "global_step=76128, episodic_return=64.0\n",
      "global_step=76152, episodic_return=189.0\n",
      "global_step=76520, episodic_return=110.0\n",
      "global_step=76576, episodic_return=99.0\n",
      "global_step=76640, episodic_return=444.0\n",
      "SPS: 100\n",
      "global_step=76952, episodic_return=103.0\n",
      "global_step=77248, episodic_return=193.0\n",
      "global_step=77256, episodic_return=92.0\n",
      "global_step=77288, episodic_return=154.0\n",
      "global_step=77288, episodic_return=142.0\n",
      "global_step=77408, episodic_return=104.0\n",
      "global_step=77552, episodic_return=213.0\n",
      "global_step=77648, episodic_return=126.0\n",
      "SPS: 101\n",
      "global_step=77856, episodic_return=76.0\n",
      "global_step=77928, episodic_return=84.0\n",
      "global_step=77936, episodic_return=123.0\n",
      "global_step=78184, episodic_return=112.0\n",
      "global_step=78464, episodic_return=147.0\n",
      "global_step=78544, episodic_return=142.0\n",
      "SPS: 98\n",
      "global_step=78904, episodic_return=169.0\n",
      "global_step=78912, episodic_return=122.0\n",
      "global_step=79088, episodic_return=145.0\n",
      "global_step=79136, episodic_return=186.0\n",
      "global_step=79464, episodic_return=201.0\n",
      "global_step=79600, episodic_return=142.0\n",
      "SPS: 99\n",
      "global_step=79960, episodic_return=222.0\n",
      "global_step=79984, episodic_return=134.0\n",
      "global_step=80048, episodic_return=120.0\n",
      "global_step=80208, episodic_return=93.0\n",
      "global_step=80224, episodic_return=78.0\n",
      "global_step=80624, episodic_return=72.0\n",
      "global_step=80624, episodic_return=260.0\n",
      "global_step=80664, episodic_return=220.0\n",
      "global_step=80720, episodic_return=64.0\n",
      "SPS: 97\n",
      "global_step=80912, episodic_return=86.0\n",
      "global_step=80928, episodic_return=38.0\n",
      "global_step=81184, episodic_return=256.0\n",
      "global_step=81312, episodic_return=169.0\n",
      "global_step=81328, episodic_return=88.0\n",
      "global_step=81576, episodic_return=83.0\n",
      "global_step=81784, episodic_return=75.0\n",
      "global_step=81824, episodic_return=64.0\n",
      "SPS: 98\n",
      "global_step=82104, episodic_return=173.0\n",
      "global_step=82128, episodic_return=268.0\n",
      "global_step=82288, episodic_return=203.0\n",
      "global_step=82328, episodic_return=68.0\n",
      "global_step=82360, episodic_return=129.0\n",
      "global_step=82400, episodic_return=14.0\n",
      "global_step=82800, episodic_return=87.0\n",
      "SPS: 96\n",
      "global_step=83176, episodic_return=200.0\n",
      "global_step=83280, episodic_return=182.0\n",
      "global_step=83448, episodic_return=131.0\n",
      "global_step=83672, episodic_return=343.0\n",
      "global_step=83848, episodic_return=71.0\n",
      "global_step=83920, episodic_return=195.0\n",
      "global_step=83944, episodic_return=227.0\n",
      "SPS: 97\n",
      "global_step=84496, episodic_return=212.0\n",
      "global_step=84800, episodic_return=203.0\n",
      "global_step=84848, episodic_return=315.0\n",
      "global_step=84952, episodic_return=129.0\n",
      "SPS: 95\n",
      "global_step=85016, episodic_return=196.0\n",
      "global_step=85640, episodic_return=246.0\n",
      "global_step=85768, episodic_return=102.0\n",
      "global_step=85784, episodic_return=123.0\n",
      "global_step=85968, episodic_return=184.0\n",
      "global_step=85968, episodic_return=253.0\n",
      "global_step=85968, episodic_return=265.0\n",
      "SPS: 96\n",
      "global_step=86080, episodic_return=133.0\n",
      "global_step=86184, episodic_return=167.0\n",
      "global_step=86360, episodic_return=35.0\n",
      "global_step=86368, episodic_return=50.0\n",
      "global_step=86664, episodic_return=87.0\n",
      "global_step=86744, episodic_return=47.0\n",
      "global_step=86800, episodic_return=129.0\n",
      "global_step=86840, episodic_return=109.0\n",
      "global_step=86864, episodic_return=63.0\n",
      "SPS: 94\n",
      "global_step=87168, episodic_return=191.0\n",
      "global_step=87192, episodic_return=176.0\n",
      "global_step=87256, episodic_return=134.0\n",
      "global_step=87784, episodic_return=115.0\n",
      "global_step=87800, episodic_return=132.0\n",
      "global_step=88024, episodic_return=107.0\n",
      "SPS: 95\n",
      "global_step=88128, episodic_return=117.0\n",
      "global_step=88136, episodic_return=167.0\n",
      "global_step=88272, episodic_return=127.0\n",
      "global_step=88344, episodic_return=68.0\n",
      "global_step=88520, episodic_return=232.0\n",
      "global_step=88712, episodic_return=55.0\n",
      "global_step=88912, episodic_return=111.0\n",
      "SPS: 93\n",
      "global_step=89408, episodic_return=111.0\n",
      "global_step=89456, episodic_return=165.0\n",
      "global_step=89472, episodic_return=329.0\n",
      "global_step=89520, episodic_return=174.0\n",
      "global_step=89544, episodic_return=150.0\n",
      "global_step=89832, episodic_return=115.0\n",
      "global_step=89872, episodic_return=261.0\n",
      "SPS: 94\n",
      "global_step=90200, episodic_return=82.0\n",
      "global_step=90528, episodic_return=41.0\n",
      "global_step=90608, episodic_return=150.0\n",
      "global_step=90696, episodic_return=153.0\n",
      "global_step=90760, episodic_return=29.0\n",
      "global_step=90912, episodic_return=182.0\n",
      "global_step=90944, episodic_return=178.0\n",
      "global_step=90952, episodic_return=135.0\n",
      "SPS: 92\n",
      "global_step=91184, episodic_return=309.0\n",
      "global_step=91520, episodic_return=211.0\n",
      "global_step=91760, episodic_return=30.0\n",
      "global_step=91808, episodic_return=139.0\n",
      "SPS: 93\n",
      "global_step=92312, episodic_return=141.0\n",
      "global_step=92376, episodic_return=202.0\n",
      "global_step=92400, episodic_return=74.0\n",
      "global_step=92488, episodic_return=91.0\n",
      "global_step=92624, episodic_return=39.0\n",
      "global_step=92696, episodic_return=218.0\n",
      "global_step=92776, episodic_return=229.0\n",
      "global_step=93080, episodic_return=271.0\n",
      "global_step=93136, episodic_return=45.0\n",
      "global_step=93160, episodic_return=319.0\n",
      "SPS: 91\n",
      "global_step=93432, episodic_return=132.0\n",
      "global_step=93696, episodic_return=151.0\n",
      "global_step=93848, episodic_return=89.0\n",
      "SPS: 92\n",
      "global_step=94216, episodic_return=142.0\n",
      "global_step=94336, episodic_return=205.0\n",
      "global_step=94384, episodic_return=153.0\n",
      "global_step=94400, episodic_return=121.0\n",
      "global_step=94728, episodic_return=129.0\n",
      "global_step=94848, episodic_return=125.0\n",
      "global_step=95008, episodic_return=298.0\n",
      "global_step=95080, episodic_return=85.0\n",
      "global_step=95160, episodic_return=345.0\n",
      "global_step=95176, episodic_return=120.0\n",
      "SPS: 90\n",
      "global_step=95408, episodic_return=128.0\n",
      "global_step=95520, episodic_return=148.0\n",
      "global_step=95896, episodic_return=90.0\n",
      "global_step=95960, episodic_return=139.0\n",
      "SPS: 91\n",
      "global_step=96432, episodic_return=159.0\n",
      "global_step=96480, episodic_return=175.0\n",
      "global_step=96504, episodic_return=123.0\n",
      "global_step=96792, episodic_return=39.0\n",
      "global_step=97056, episodic_return=291.0\n",
      "global_step=97152, episodic_return=149.0\n",
      "global_step=97160, episodic_return=219.0\n",
      "SPS: 90\n",
      "global_step=97312, episodic_return=177.0\n",
      "global_step=97472, episodic_return=39.0\n",
      "global_step=97576, episodic_return=65.0\n",
      "global_step=97608, episodic_return=325.0\n",
      "global_step=97768, episodic_return=57.0\n",
      "global_step=97912, episodic_return=55.0\n",
      "global_step=97992, episodic_return=52.0\n",
      "global_step=97992, episodic_return=105.0\n",
      "global_step=98240, episodic_return=217.0\n",
      "SPS: 91\n",
      "global_step=98336, episodic_return=193.0\n",
      "global_step=98600, episodic_return=124.0\n",
      "global_step=98720, episodic_return=91.0\n",
      "global_step=98920, episodic_return=126.0\n",
      "global_step=99080, episodic_return=60.0\n",
      "global_step=99112, episodic_return=140.0\n",
      "SPS: 89\n"
     ]
    }
   ],
   "source": [
    "batch_size = int(params[\"num_envs\"] * params[\"num_steps\"])                \n",
    "minibatch_size = int(batch_size // params[\"num_minibatches\"])\n",
    "num_iterations = params[\"total_timesteps\"] // batch_size     \n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "next_obs = torch.Tensor(envs.reset()[0]).to(device)\n",
    "next_done = torch.zeros(params[\"num_envs\"]).to(device)\n",
    "results_simple_PPO = {\"global_step\":[],\n",
    "                      \"return_value\":[]}\n",
    "\n",
    "tracking_global_step = 0\n",
    "\n",
    "for iteration in range(1, num_iterations+1):\n",
    "    if params[\"anneal_lr\"]:\n",
    "        updated_lr = (1.0 - (iteration - 1.0) / num_iterations) * params[\"learning_rate\"]\n",
    "        optimizer.param_groups[0][\"lr\"] = updated_lr\n",
    "    \n",
    "    for step in range(0, params[\"num_steps\"]):\n",
    "        global_step += 1 * params[\"num_envs\"]\n",
    "        obs[step] = next_obs\n",
    "        dones[step] = next_done \n",
    "\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value = Agent.get_action_and_value(next_obs)\n",
    "        values[step] = value.flatten()\n",
    "        actions[step] = action\n",
    "        logprobs[step] = logprob\n",
    "        \n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "        done = np.logical_or(terminated, truncated)\n",
    "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
    "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
    "\n",
    "        if \"final_info\" in info:\n",
    "            for info in info[\"final_info\"]:\n",
    "                if info and \"episode\" in info:\n",
    "                    print(\n",
    "                    f\"global_step={global_step}, episodic_return={info['episode']['r'][0]}\"\n",
    "                        )\n",
    "                    \n",
    "        if global_step - tracking_global_step > 2000:\n",
    "            return_eval = evaluate(params[\"env_id\"], Agent, use_int_rews=False)\n",
    "            results_simple_PPO[\"global_step\"].append(global_step)\n",
    "            results_simple_PPO[\"return_value\"].append(return_eval)\n",
    "            tracking_global_step = global_step\n",
    "\n",
    "    # bootstrap value if not done\n",
    "    with torch.no_grad():\n",
    "        next_value = Agent.get_value(next_obs).reshape(1, -1)\n",
    "        advantages = torch.zeros_like(rewards).to(device)\n",
    "        lastgaelam = 0\n",
    "        for t in reversed(range(params[\"num_steps\"])):\n",
    "            if t == params[\"num_steps\"] - 1:\n",
    "                nextnonterminal = 1.0 - next_done\n",
    "                nextvalues = next_value\n",
    "            else:\n",
    "                nextnonterminal = 1.0 - dones[t + 1]\n",
    "                nextvalues = values[t + 1]\n",
    "            delta = rewards[t] + params[\"gamma\"] * nextvalues * nextnonterminal - values[t]\n",
    "            advantages[t] = lastgaelam = delta + params[\"gamma\"] * params[\"gae_lambda\"] * nextnonterminal * lastgaelam\n",
    "        returns = advantages + values\n",
    "\n",
    "    # flatten the batch\n",
    "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_logprobs = logprobs.reshape(-1)\n",
    "    b_actions = actions.reshape((-1,) + envs.single_action_space.shape)\n",
    "    b_advantages = advantages.reshape(-1)\n",
    "    b_returns = returns.reshape(-1)\n",
    "    b_values = values.reshape(-1)\n",
    "\n",
    "    # Optimizing the policy and value network\n",
    "    b_inds = np.arange(batch_size)\n",
    "    clipfracs = []\n",
    "    for epoch in range(params[\"update_epochs\"]):\n",
    "        np.random.shuffle(b_inds)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            mb_inds = b_inds[start:end]\n",
    "\n",
    "            _, newlogprob, entropy, newvalue = Agent.get_action_and_value(b_obs[mb_inds], b_actions.long()[mb_inds])\n",
    "            logratio = newlogprob - b_logprobs[mb_inds]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "                old_approx_kl = (-logratio).mean()\n",
    "                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                clipfracs += [((ratio - 1.0).abs() > params[\"clip_coef\"]).float().mean().item()]\n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            if params[\"norm_adv\"]:\n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - params[\"clip_coef\"], 1 + params[\"clip_coef\"])\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            newvalue = newvalue.view(-1)\n",
    "            if params[\"clip_vloss\"]:\n",
    "                value_loss_unclipped = (newvalue - b_returns[mb_inds]) ** 2\n",
    "                v_clipped = b_values[mb_inds] + torch.clamp(\n",
    "                    newvalue - b_values[mb_inds],\n",
    "                    -params[\"clip_coef\"],\n",
    "                    params[\"clip_coef\"],\n",
    "                )\n",
    "                value_loss_clipped = (v_clipped - b_returns[mb_inds]) ** 2\n",
    "                value_loss_max = torch.max(value_loss_unclipped, value_loss_clipped)\n",
    "                value_loss = 0.5 * value_loss_max.mean()\n",
    "            else:\n",
    "                value_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss - params[\"ent_coef\"] * entropy_loss + value_loss * params[\"vf_coef\"]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(Agent.parameters(), params[\"max_grad_norm\"])\n",
    "            optimizer.step()\n",
    "\n",
    "        if params[\"target_kl\"] is not None and approx_kl > params[\"target_kl\"]:\n",
    "            break\n",
    "\n",
    "    y_pred, y_true = b_values.cpu().numpy(), b_returns.cpu().numpy()\n",
    "    var_y = np.var(y_true)\n",
    "    explained_var = np.nan if var_y == 0 else 1 - np.var(y_true - y_pred) / var_y\n",
    "\n",
    "    print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Agent, \"pretrained_models/simple_ppo_for_suprised.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from results_simple_PPO\n",
    "ppo_global_step = results_simple_PPO[\"global_step\"]\n",
    "ppo_return_value = results_simple_PPO[\"return_value\"]\n",
    "\n",
    "\n",
    "df_ppo = pd.DataFrame({'global_step': ppo_global_step, 'return_value': ppo_return_value})\n",
    "\n",
    "\n",
    "df_ppo.to_csv('./data/results_simple_ppo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Random Network Distillation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Key Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction problem is randomly generated. This involves 2 NNs, fixed target network sets the prediction problem (find an embedding $f(O)$ for an observation) and predictor network trained on data collected (with the task to predict $\\hat{f}(O)$) from the agent, minimizing MSE Loss $\\text{MSE} = \\| \\hat{f}(x; \\theta) - f(x) \\|^{2}_2$.\n",
    "- Prediction error is expected to be higher in novel state (suprise state) that the agent is not familiar with. \n",
    "- $R=R_E+R_I$, thus, $V=V_E+V_I$.\n",
    "- Reward and Observation Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.1 RND Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNDModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Prediction network\n",
    "        self.predictor = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 256)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(256, 256)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(256, 256), std=1.0),\n",
    "        )\n",
    "\n",
    "        # Target network\n",
    "        self.target = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 256)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(256, 256)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(256, 256), std=1.0),)\n",
    "\n",
    "        # fixed the target network params\n",
    "        for param in self.target.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, next_obs):\n",
    "        target_feature = self.target(next_obs)\n",
    "        predict_feature = self.predictor(next_obs)\n",
    "\n",
    "        return predict_feature, target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingSumOfReward:\n",
    "    def __init__(self, gamma):\n",
    "        self.moving_sum_of_reward = None\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def update(self, rews):\n",
    "        if self.moving_sum_of_reward is None:\n",
    "            self.moving_sum_of_reward = rews\n",
    "        else:\n",
    "            self.moving_sum_of_reward = self.moving_sum_of_reward * self.gamma + rews\n",
    "        return self.moving_sum_of_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.2 Main Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = params[\"env_id\"]\n",
    "exp_name = params[\"exp_name\"]\n",
    "seed = params[\"seed\"]\n",
    "run_name = f\"{env_id}__{exp_name}__{seed}__{int(time.time())}\"\n",
    "\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(env_id) for i in range(params[\"num_envs\"])],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up agent and model\n",
    "Agent = PPOAgent(envs, use_int_rews=True).to(device)\n",
    "optimizer = optim.Adam(\n",
    "    Agent.parameters(),\n",
    "    lr=params[\"learning_rate\"],\n",
    "    eps=1e-5,\n",
    ")\n",
    "rnd_model = RNDModel().to(device)\n",
    "combined_parameters = list(Agent.parameters()) + list(rnd_model.predictor.parameters())\n",
    "optimizer = optim.Adam(\n",
    "    combined_parameters,\n",
    "    lr=params[\"learning_rate\"],\n",
    "    eps=1e-5,\n",
    ")\n",
    "\n",
    "rew_runnning_mean_std = RunningMeanStd()\n",
    "discounted_reward = MovingSumOfReward(params[\"int_gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.zeros((params[\"num_steps\"], params[\"num_envs\"]) + envs.single_observation_space.shape).to(device)  # (128, 4,, 4, 84, 84)\n",
    "actions = torch.zeros((params[\"num_steps\"], params[\"num_envs\"]) + envs.single_action_space.shape).to(device)   # (128, 4) \n",
    "logprobs = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "rewards = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "surprise_rewards = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "dones = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "ext_values = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "int_values = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "avg_returns = deque(maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=72, episodic_return=9.0, surprise_reward=0.862743616104126\n",
      "global_step=112, episodic_return=14.0, surprise_reward=0.9250522255897522\n",
      "global_step=112, episodic_return=14.0, surprise_reward=0.9250522255897522\n",
      "global_step=120, episodic_return=15.0, surprise_reward=0.7132278680801392\n",
      "global_step=144, episodic_return=18.0, surprise_reward=0.3221203088760376\n",
      "global_step=168, episodic_return=21.0, surprise_reward=0.6108599901199341\n",
      "global_step=200, episodic_return=16.0, surprise_reward=0.9342354536056519\n",
      "global_step=208, episodic_return=26.0, surprise_reward=0.8627562522888184\n",
      "global_step=240, episodic_return=15.0, surprise_reward=0.9522631764411926\n",
      "global_step=248, episodic_return=13.0, surprise_reward=0.8610756397247314\n",
      "global_step=280, episodic_return=14.0, surprise_reward=0.7871707677841187\n",
      "global_step=296, episodic_return=12.0, surprise_reward=1.0107189416885376\n",
      "global_step=304, episodic_return=24.0, surprise_reward=0.6005173921585083\n",
      "global_step=328, episodic_return=11.0, surprise_reward=1.0370194911956787\n",
      "global_step=360, episodic_return=10.0, surprise_reward=0.5232802033424377\n",
      "global_step=384, episodic_return=22.0, surprise_reward=0.6341608166694641\n",
      "global_step=400, episodic_return=19.0, surprise_reward=0.3492274284362793\n",
      "global_step=440, episodic_return=41.0, surprise_reward=0.15622779726982117\n",
      "global_step=528, episodic_return=29.0, surprise_reward=0.5584306716918945\n",
      "global_step=544, episodic_return=20.0, surprise_reward=0.5455235838890076\n",
      "global_step=552, episodic_return=31.0, surprise_reward=0.4158962368965149\n",
      "global_step=560, episodic_return=29.0, surprise_reward=0.4254510998725891\n",
      "global_step=608, episodic_return=21.0, surprise_reward=0.6445212364196777\n",
      "global_step=632, episodic_return=29.0, surprise_reward=0.5288190841674805\n",
      "global_step=696, episodic_return=18.0, surprise_reward=0.9182883501052856\n",
      "global_step=704, episodic_return=20.0, surprise_reward=1.139463186264038\n",
      "global_step=720, episodic_return=20.0, surprise_reward=1.5959080457687378\n",
      "global_step=728, episodic_return=12.0, surprise_reward=0.30271175503730774\n",
      "global_step=728, episodic_return=91.0, surprise_reward=0.30271175503730774\n",
      "global_step=752, episodic_return=49.0, surprise_reward=0.9515573382377625\n",
      "global_step=792, episodic_return=23.0, surprise_reward=1.3428566455841064\n",
      "global_step=808, episodic_return=13.0, surprise_reward=0.38112714886665344\n",
      "global_step=816, episodic_return=12.0, surprise_reward=0.24447333812713623\n",
      "global_step=848, episodic_return=19.0, surprise_reward=0.7097635269165039\n",
      "global_step=848, episodic_return=40.0, surprise_reward=0.7097635269165039\n",
      "global_step=872, episodic_return=18.0, surprise_reward=1.123607873916626\n",
      "global_step=880, episodic_return=19.0, surprise_reward=1.1109853982925415\n",
      "global_step=920, episodic_return=16.0, surprise_reward=0.9647658467292786\n",
      "global_step=920, episodic_return=13.0, surprise_reward=0.9647658467292786\n",
      "global_step=920, episodic_return=14.0, surprise_reward=0.9647658467292786\n",
      "global_step=960, episodic_return=14.0, surprise_reward=1.026743769645691\n",
      "global_step=976, episodic_return=16.0, surprise_reward=0.6419918537139893\n",
      "global_step=976, episodic_return=12.0, surprise_reward=0.6419918537139893\n",
      "global_step=992, episodic_return=15.0, surprise_reward=1.170836091041565\n",
      "global_step=1000, episodic_return=10.0, surprise_reward=0.42780131101608276\n",
      "global_step=1024, episodic_return=34.0, surprise_reward=0.815296471118927\n",
      "SPS: 803\n",
      "global_step=1040, episodic_return=15.0, surprise_reward=0.37938839197158813\n",
      "global_step=1072, episodic_return=12.0, surprise_reward=0.3244631290435791\n",
      "global_step=1112, episodic_return=19.0, surprise_reward=0.7992591857910156\n",
      "global_step=1120, episodic_return=12.0, surprise_reward=0.6083332300186157\n",
      "global_step=1160, episodic_return=15.0, surprise_reward=0.26721808314323425\n",
      "global_step=1176, episodic_return=32.0, surprise_reward=0.3423304259777069\n",
      "global_step=1200, episodic_return=26.0, surprise_reward=0.5793700218200684\n",
      "global_step=1208, episodic_return=29.0, surprise_reward=0.6736734509468079\n",
      "global_step=1232, episodic_return=15.0, surprise_reward=0.23243404924869537\n",
      "global_step=1280, episodic_return=35.0, surprise_reward=0.3140779733657837\n",
      "global_step=1336, episodic_return=16.0, surprise_reward=0.4077713191509247\n",
      "global_step=1336, episodic_return=20.0, surprise_reward=0.4077713191509247\n",
      "global_step=1352, episodic_return=24.0, surprise_reward=0.28072255849838257\n",
      "global_step=1368, episodic_return=21.0, surprise_reward=0.24447540938854218\n",
      "global_step=1400, episodic_return=21.0, surprise_reward=0.9143841862678528\n",
      "global_step=1416, episodic_return=43.0, surprise_reward=0.6647751331329346\n",
      "global_step=1448, episodic_return=14.0, surprise_reward=1.1679341793060303\n",
      "global_step=1456, episodic_return=22.0, surprise_reward=0.6650763750076294\n",
      "global_step=1464, episodic_return=16.0, surprise_reward=0.378844678401947\n",
      "global_step=1472, episodic_return=44.0, surprise_reward=0.5050377249717712\n",
      "global_step=1496, episodic_return=16.0, surprise_reward=0.7218981385231018\n",
      "global_step=1504, episodic_return=19.0, surprise_reward=0.1690705567598343\n",
      "global_step=1640, episodic_return=21.0, surprise_reward=0.9136124849319458\n",
      "global_step=1648, episodic_return=24.0, surprise_reward=0.18357405066490173\n",
      "global_step=1648, episodic_return=23.0, surprise_reward=0.18357405066490173\n",
      "global_step=1656, episodic_return=19.0, surprise_reward=0.21788673102855682\n",
      "global_step=1720, episodic_return=40.0, surprise_reward=0.4770503342151642\n",
      "global_step=1760, episodic_return=43.0, surprise_reward=0.5928230285644531\n",
      "global_step=1768, episodic_return=40.0, surprise_reward=0.5723204612731934\n",
      "global_step=1784, episodic_return=17.0, surprise_reward=0.6805691719055176\n",
      "global_step=1800, episodic_return=18.0, surprise_reward=0.7765130996704102\n",
      "global_step=1816, episodic_return=40.0, surprise_reward=0.9215661883354187\n",
      "global_step=1824, episodic_return=22.0, surprise_reward=0.1788712739944458\n",
      "global_step=1864, episodic_return=28.0, surprise_reward=0.4854208528995514\n",
      "global_step=1896, episodic_return=14.0, surprise_reward=0.8988885879516602\n",
      "global_step=1912, episodic_return=24.0, surprise_reward=0.6339048147201538\n",
      "global_step=1936, episodic_return=9.0, surprise_reward=0.42657214403152466\n",
      "global_step=2024, episodic_return=26.0, surprise_reward=0.3055526316165924\n",
      "global_step=2024, episodic_return=25.0, surprise_reward=0.3055526316165924\n",
      "global_step=2032, episodic_return=17.0, surprise_reward=0.24466940760612488\n",
      "global_step=2048, episodic_return=17.0, surprise_reward=0.3376736044883728\n",
      "SPS: 281\n",
      "global_step=2104, episodic_return=42.0, surprise_reward=0.8489158153533936\n",
      "global_step=2120, episodic_return=11.0, surprise_reward=0.4606734812259674\n",
      "global_step=2136, episodic_return=42.0, surprise_reward=0.49883541464805603\n",
      "global_step=2160, episodic_return=14.0, surprise_reward=0.5911216735839844\n",
      "global_step=2160, episodic_return=17.0, surprise_reward=0.5911216735839844\n",
      "global_step=2168, episodic_return=51.0, surprise_reward=0.4453965425491333\n",
      "global_step=2200, episodic_return=12.0, surprise_reward=0.22210825979709625\n",
      "global_step=2240, episodic_return=38.0, surprise_reward=0.759610652923584\n",
      "global_step=2256, episodic_return=12.0, surprise_reward=0.6225473880767822\n",
      "global_step=2256, episodic_return=29.0, surprise_reward=0.6225473880767822\n",
      "global_step=2264, episodic_return=16.0, surprise_reward=0.2094687819480896\n",
      "global_step=2304, episodic_return=23.0, surprise_reward=0.24478591978549957\n",
      "global_step=2312, episodic_return=14.0, surprise_reward=0.1451376974582672\n",
      "global_step=2344, episodic_return=11.0, surprise_reward=0.25243473052978516\n",
      "global_step=2376, episodic_return=27.0, surprise_reward=0.35321244597435\n",
      "global_step=2384, episodic_return=27.0, surprise_reward=0.39026588201522827\n",
      "global_step=2408, episodic_return=13.0, surprise_reward=0.2894178330898285\n",
      "global_step=2424, episodic_return=20.0, surprise_reward=0.055811598896980286\n",
      "global_step=2480, episodic_return=17.0, surprise_reward=0.5905569791793823\n",
      "global_step=2496, episodic_return=14.0, surprise_reward=0.43718165159225464\n",
      "global_step=2520, episodic_return=18.0, surprise_reward=0.4371420443058014\n",
      "global_step=2536, episodic_return=28.0, surprise_reward=0.40710562467575073\n",
      "global_step=2544, episodic_return=15.0, surprise_reward=0.5651611685752869\n",
      "global_step=2560, episodic_return=19.0, surprise_reward=0.39111199975013733\n",
      "global_step=2576, episodic_return=10.0, surprise_reward=0.1832994818687439\n",
      "global_step=2648, episodic_return=21.0, surprise_reward=0.25860464572906494\n",
      "global_step=2648, episodic_return=14.0, surprise_reward=0.25860464572906494\n",
      "global_step=2648, episodic_return=49.0, surprise_reward=0.25860464572906494\n",
      "global_step=2664, episodic_return=18.0, surprise_reward=0.4210033714771271\n",
      "global_step=2688, episodic_return=16.0, surprise_reward=0.34717753529548645\n",
      "global_step=2696, episodic_return=15.0, surprise_reward=0.17808306217193604\n",
      "global_step=2736, episodic_return=24.0, surprise_reward=0.4010997712612152\n",
      "global_step=2736, episodic_return=62.0, surprise_reward=0.4010997712612152\n",
      "global_step=2752, episodic_return=13.0, surprise_reward=0.15931198000907898\n",
      "global_step=2760, episodic_return=14.0, surprise_reward=0.17831121385097504\n",
      "global_step=2816, episodic_return=15.0, surprise_reward=0.46688276529312134\n",
      "global_step=2824, episodic_return=9.0, surprise_reward=0.33611220121383667\n",
      "global_step=2856, episodic_return=12.0, surprise_reward=0.45986407995224\n",
      "global_step=2896, episodic_return=26.0, surprise_reward=0.1691291630268097\n",
      "global_step=2896, episodic_return=29.0, surprise_reward=0.1691291630268097\n",
      "global_step=2952, episodic_return=12.0, surprise_reward=0.6034963726997375\n",
      "global_step=2960, episodic_return=28.0, surprise_reward=0.21829834580421448\n",
      "global_step=3000, episodic_return=44.0, surprise_reward=0.41769111156463623\n",
      "global_step=3000, episodic_return=22.0, surprise_reward=0.41769111156463623\n",
      "global_step=3016, episodic_return=25.0, surprise_reward=0.41264232993125916\n",
      "global_step=3040, episodic_return=18.0, surprise_reward=0.4452234208583832\n",
      "global_step=3072, episodic_return=42.0, surprise_reward=0.6655775904655457\n",
      "global_step=3072, episodic_return=9.0, surprise_reward=0.6655775904655457\n",
      "SPS: 369\n",
      "global_step=3080, episodic_return=23.0, surprise_reward=0.2241082489490509\n",
      "global_step=3096, episodic_return=17.0, surprise_reward=0.07783258706331253\n",
      "global_step=3176, episodic_return=20.0, surprise_reward=0.3907496929168701\n",
      "global_step=3184, episodic_return=18.0, surprise_reward=0.4163174331188202\n",
      "global_step=3200, episodic_return=16.0, surprise_reward=0.40308475494384766\n",
      "global_step=3216, episodic_return=17.0, surprise_reward=0.2785440683364868\n",
      "global_step=3216, episodic_return=15.0, surprise_reward=0.2785440683364868\n",
      "global_step=3224, episodic_return=34.0, surprise_reward=0.3040556311607361\n",
      "global_step=3248, episodic_return=22.0, surprise_reward=0.24750414490699768\n",
      "global_step=3256, episodic_return=9.0, surprise_reward=0.19220741093158722\n",
      "global_step=3304, episodic_return=16.0, surprise_reward=0.2237967848777771\n",
      "global_step=3312, episodic_return=14.0, surprise_reward=0.20261958241462708\n",
      "global_step=3328, episodic_return=14.0, surprise_reward=0.549164354801178\n",
      "global_step=3352, episodic_return=12.0, surprise_reward=0.44661056995391846\n",
      "global_step=3360, episodic_return=17.0, surprise_reward=0.2414393573999405\n",
      "global_step=3376, episodic_return=47.0, surprise_reward=0.2565535306930542\n",
      "global_step=3376, episodic_return=16.0, surprise_reward=0.2565535306930542\n",
      "global_step=3408, episodic_return=24.0, surprise_reward=0.16911442577838898\n",
      "global_step=3432, episodic_return=13.0, surprise_reward=0.06906259804964066\n",
      "global_step=3480, episodic_return=13.0, surprise_reward=0.0625784695148468\n",
      "global_step=3504, episodic_return=25.0, surprise_reward=0.11369643360376358\n",
      "global_step=3520, episodic_return=21.0, surprise_reward=0.24130192399024963\n",
      "global_step=3592, episodic_return=29.0, surprise_reward=0.3258668780326843\n",
      "global_step=3600, episodic_return=24.0, surprise_reward=0.3581525981426239\n",
      "global_step=3608, episodic_return=37.0, surprise_reward=0.21412810683250427\n",
      "global_step=3616, episodic_return=14.0, surprise_reward=0.14674165844917297\n",
      "global_step=3624, episodic_return=24.0, surprise_reward=0.05582881718873978\n",
      "global_step=3696, episodic_return=11.0, surprise_reward=0.2043212354183197\n",
      "global_step=3720, episodic_return=15.0, surprise_reward=0.13991591334342957\n",
      "global_step=3752, episodic_return=17.0, surprise_reward=0.2567775845527649\n",
      "global_step=3760, episodic_return=17.0, surprise_reward=0.16044972836971283\n",
      "global_step=3776, episodic_return=32.0, surprise_reward=0.13407203555107117\n",
      "global_step=3824, episodic_return=29.0, surprise_reward=0.34687328338623047\n",
      "global_step=3848, episodic_return=12.0, surprise_reward=0.32249704003334045\n",
      "global_step=3880, episodic_return=20.0, surprise_reward=0.4434536099433899\n",
      "global_step=3904, episodic_return=26.0, surprise_reward=0.3305698037147522\n",
      "global_step=3912, episodic_return=17.0, surprise_reward=0.36077266931533813\n",
      "global_step=3936, episodic_return=57.0, surprise_reward=0.47180771827697754\n",
      "global_step=3944, episodic_return=15.0, surprise_reward=0.4544394314289093\n",
      "global_step=3960, episodic_return=14.0, surprise_reward=0.40588992834091187\n",
      "global_step=3968, episodic_return=74.0, surprise_reward=0.2583584487438202\n",
      "global_step=3976, episodic_return=27.0, surprise_reward=0.14395549893379211\n",
      "global_step=4032, episodic_return=11.0, surprise_reward=0.27524784207344055\n",
      "global_step=4032, episodic_return=16.0, surprise_reward=0.27524784207344055\n",
      "global_step=4048, episodic_return=10.0, surprise_reward=0.3438102602958679\n",
      "global_step=4056, episodic_return=10.0, surprise_reward=0.029328614473342896\n",
      "SPS: 270\n",
      "global_step=4104, episodic_return=24.0, surprise_reward=0.2501319646835327\n",
      "global_step=4152, episodic_return=24.0, surprise_reward=0.28673693537712097\n",
      "global_step=4168, episodic_return=36.0, surprise_reward=0.18803229928016663\n",
      "global_step=4176, episodic_return=16.0, surprise_reward=0.10031014680862427\n",
      "global_step=4216, episodic_return=23.0, surprise_reward=0.27381056547164917\n",
      "global_step=4232, episodic_return=25.0, surprise_reward=0.0884041115641594\n",
      "global_step=4232, episodic_return=22.0, surprise_reward=0.0884041115641594\n",
      "global_step=4272, episodic_return=42.0, surprise_reward=0.2030901461839676\n",
      "global_step=4288, episodic_return=14.0, surprise_reward=0.14348654448986053\n",
      "global_step=4320, episodic_return=27.0, surprise_reward=0.24162307381629944\n",
      "global_step=4344, episodic_return=22.0, surprise_reward=0.049236372113227844\n",
      "global_step=4384, episodic_return=19.0, surprise_reward=0.11061900854110718\n",
      "global_step=4416, episodic_return=25.0, surprise_reward=0.14105269312858582\n",
      "global_step=4424, episodic_return=24.0, surprise_reward=0.18852181732654572\n",
      "global_step=4464, episodic_return=24.0, surprise_reward=0.12993454933166504\n",
      "global_step=4472, episodic_return=19.0, surprise_reward=0.13322508335113525\n",
      "global_step=4488, episodic_return=18.0, surprise_reward=0.12122192978858948\n",
      "global_step=4496, episodic_return=43.0, surprise_reward=0.14512410759925842\n",
      "global_step=4560, episodic_return=34.0, surprise_reward=0.21443164348602295\n",
      "global_step=4600, episodic_return=17.0, surprise_reward=0.19940185546875\n",
      "global_step=4600, episodic_return=13.0, surprise_reward=0.19940185546875\n",
      "global_step=4608, episodic_return=24.0, surprise_reward=0.2171798199415207\n",
      "global_step=4616, episodic_return=24.0, surprise_reward=0.22258324921131134\n",
      "global_step=4640, episodic_return=19.0, surprise_reward=0.027101054787635803\n",
      "global_step=4672, episodic_return=25.0, surprise_reward=0.15794891119003296\n",
      "global_step=4704, episodic_return=18.0, surprise_reward=0.2109609991312027\n",
      "global_step=4720, episodic_return=15.0, surprise_reward=0.06768699735403061\n",
      "global_step=4800, episodic_return=23.0, surprise_reward=0.3635384440422058\n",
      "global_step=4808, episodic_return=26.0, surprise_reward=0.5848332643508911\n",
      "global_step=4816, episodic_return=22.0, surprise_reward=0.2467401921749115\n",
      "global_step=4816, episodic_return=12.0, surprise_reward=0.2467401921749115\n",
      "global_step=4840, episodic_return=21.0, surprise_reward=0.37624824047088623\n",
      "global_step=4840, episodic_return=17.0, surprise_reward=0.37624824047088623\n",
      "global_step=4864, episodic_return=60.0, surprise_reward=0.15832343697547913\n",
      "global_step=4920, episodic_return=15.0, surprise_reward=0.2357138842344284\n",
      "global_step=4928, episodic_return=14.0, surprise_reward=0.3218412399291992\n",
      "global_step=4944, episodic_return=13.0, surprise_reward=0.3240138292312622\n",
      "global_step=4952, episodic_return=17.0, surprise_reward=0.14325106143951416\n",
      "global_step=4952, episodic_return=18.0, surprise_reward=0.14325106143951416\n",
      "global_step=5024, episodic_return=23.0, surprise_reward=0.2695160210132599\n",
      "global_step=5040, episodic_return=22.0, surprise_reward=0.2052498757839203\n",
      "global_step=5064, episodic_return=14.0, surprise_reward=0.23513181507587433\n",
      "global_step=5096, episodic_return=19.0, surprise_reward=0.6236109733581543\n",
      "global_step=5104, episodic_return=19.0, surprise_reward=0.49736571311950684\n",
      "SPS: 317\n",
      "global_step=5136, episodic_return=14.0, surprise_reward=0.5262504816055298\n",
      "global_step=5144, episodic_return=28.0, surprise_reward=0.32048070430755615\n",
      "global_step=5152, episodic_return=68.0, surprise_reward=0.0881396159529686\n",
      "global_step=5168, episodic_return=30.0, surprise_reward=0.0912579670548439\n",
      "global_step=5168, episodic_return=13.0, surprise_reward=0.0912579670548439\n",
      "global_step=5192, episodic_return=19.0, surprise_reward=0.06095520406961441\n",
      "global_step=5272, episodic_return=17.0, surprise_reward=0.30906498432159424\n",
      "global_step=5304, episodic_return=17.0, surprise_reward=0.3079056143760681\n",
      "global_step=5312, episodic_return=20.0, surprise_reward=0.14807145297527313\n",
      "global_step=5336, episodic_return=18.0, surprise_reward=0.17344535887241364\n",
      "global_step=5336, episodic_return=29.0, surprise_reward=0.17344535887241364\n",
      "global_step=5344, episodic_return=22.0, surprise_reward=0.07851230353116989\n",
      "global_step=5376, episodic_return=35.0, surprise_reward=0.19960570335388184\n",
      "global_step=5408, episodic_return=12.0, surprise_reward=0.11352206021547318\n",
      "global_step=5480, episodic_return=18.0, surprise_reward=0.44112905859947205\n",
      "global_step=5488, episodic_return=27.0, surprise_reward=0.29545313119888306\n",
      "global_step=5488, episodic_return=18.0, surprise_reward=0.29545313119888306\n",
      "global_step=5504, episodic_return=12.0, surprise_reward=0.30165958404541016\n",
      "global_step=5528, episodic_return=24.0, surprise_reward=0.37333622574806213\n",
      "global_step=5528, episodic_return=28.0, surprise_reward=0.37333622574806213\n",
      "global_step=5536, episodic_return=20.0, surprise_reward=0.2434827983379364\n",
      "global_step=5592, episodic_return=13.0, surprise_reward=0.22875630855560303\n",
      "global_step=5616, episodic_return=14.0, surprise_reward=0.27416473627090454\n",
      "global_step=5624, episodic_return=60.0, surprise_reward=0.06895984709262848\n",
      "global_step=5696, episodic_return=26.0, surprise_reward=0.0962166041135788\n",
      "global_step=5712, episodic_return=15.0, surprise_reward=0.13918854296207428\n",
      "global_step=5752, episodic_return=34.0, surprise_reward=0.17217512428760529\n",
      "global_step=5776, episodic_return=31.0, surprise_reward=0.16336333751678467\n",
      "global_step=5800, episodic_return=33.0, surprise_reward=0.2974716126918793\n",
      "global_step=5832, episodic_return=38.0, surprise_reward=0.1464357078075409\n",
      "global_step=5856, episodic_return=30.0, surprise_reward=0.18292586505413055\n",
      "global_step=5856, episodic_return=13.0, surprise_reward=0.18292586505413055\n",
      "global_step=5872, episodic_return=9.0, surprise_reward=0.07427753508090973\n",
      "global_step=5896, episodic_return=25.0, surprise_reward=0.07663589715957642\n",
      "global_step=5936, episodic_return=28.0, surprise_reward=0.24612292647361755\n",
      "global_step=5968, episodic_return=14.0, surprise_reward=0.24998870491981506\n",
      "global_step=5976, episodic_return=44.0, surprise_reward=0.22838957607746124\n",
      "global_step=6000, episodic_return=18.0, surprise_reward=0.06382766366004944\n",
      "global_step=6000, episodic_return=28.0, surprise_reward=0.06382766366004944\n",
      "global_step=6024, episodic_return=24.0, surprise_reward=0.2211276888847351\n",
      "global_step=6056, episodic_return=15.0, surprise_reward=0.03722091391682625\n",
      "global_step=6056, episodic_return=20.0, surprise_reward=0.03722091391682625\n",
      "global_step=6080, episodic_return=26.0, surprise_reward=0.05768232047557831\n",
      "global_step=6120, episodic_return=18.0, surprise_reward=0.18410521745681763\n",
      "global_step=6136, episodic_return=17.0, surprise_reward=0.06486004590988159\n",
      "global_step=6144, episodic_return=22.0, surprise_reward=0.12723669409751892\n",
      "SPS: 267\n",
      "global_step=6160, episodic_return=20.0, surprise_reward=0.1422540694475174\n",
      "global_step=6192, episodic_return=17.0, surprise_reward=0.2392292022705078\n",
      "global_step=6232, episodic_return=26.0, surprise_reward=0.24572452902793884\n",
      "global_step=6232, episodic_return=12.0, surprise_reward=0.24572452902793884\n",
      "global_step=6232, episodic_return=19.0, surprise_reward=0.24572452902793884\n",
      "global_step=6240, episodic_return=10.0, surprise_reward=0.03426027670502663\n",
      "global_step=6280, episodic_return=11.0, surprise_reward=0.15539191663265228\n",
      "global_step=6312, episodic_return=24.0, surprise_reward=0.11283225566148758\n",
      "global_step=6312, episodic_return=10.0, surprise_reward=0.11283225566148758\n",
      "global_step=6352, episodic_return=14.0, surprise_reward=0.05031131953001022\n",
      "global_step=6368, episodic_return=39.0, surprise_reward=0.08703617751598358\n",
      "global_step=6480, episodic_return=21.0, surprise_reward=0.28259894251823425\n",
      "global_step=6488, episodic_return=22.0, surprise_reward=0.2904191315174103\n",
      "global_step=6496, episodic_return=33.0, surprise_reward=0.26659712195396423\n",
      "global_step=6512, episodic_return=46.0, surprise_reward=0.20172132551670074\n",
      "global_step=6520, episodic_return=21.0, surprise_reward=0.2542211413383484\n",
      "global_step=6552, episodic_return=34.0, surprise_reward=0.09291189163923264\n",
      "global_step=6552, episodic_return=40.0, surprise_reward=0.09291189163923264\n",
      "global_step=6600, episodic_return=15.0, surprise_reward=0.0426584929227829\n",
      "global_step=6600, episodic_return=29.0, surprise_reward=0.0426584929227829\n",
      "global_step=6600, episodic_return=13.0, surprise_reward=0.0426584929227829\n",
      "global_step=6664, episodic_return=22.0, surprise_reward=0.036072440445423126\n",
      "global_step=6712, episodic_return=14.0, surprise_reward=0.18374119699001312\n",
      "global_step=6744, episodic_return=18.0, surprise_reward=0.21332794427871704\n",
      "global_step=6760, episodic_return=26.0, surprise_reward=0.19181951880455017\n",
      "global_step=6768, episodic_return=13.0, surprise_reward=0.20225735008716583\n",
      "global_step=6792, episodic_return=34.0, surprise_reward=0.06365548819303513\n",
      "global_step=6792, episodic_return=35.0, surprise_reward=0.06365548819303513\n",
      "global_step=6808, episodic_return=32.0, surprise_reward=0.0401131734251976\n",
      "global_step=6856, episodic_return=32.0, surprise_reward=0.09366541355848312\n",
      "global_step=6872, episodic_return=20.0, surprise_reward=0.031861212104558945\n",
      "global_step=6968, episodic_return=28.0, surprise_reward=0.19205760955810547\n",
      "global_step=6976, episodic_return=13.0, surprise_reward=0.07923581451177597\n",
      "global_step=7008, episodic_return=27.0, surprise_reward=0.13683956861495972\n",
      "global_step=7024, episodic_return=32.0, surprise_reward=0.11045381426811218\n",
      "global_step=7032, episodic_return=30.0, surprise_reward=0.040197066962718964\n",
      "global_step=7032, episodic_return=28.0, surprise_reward=0.040197066962718964\n",
      "global_step=7104, episodic_return=31.0, surprise_reward=0.264505535364151\n",
      "global_step=7128, episodic_return=20.0, surprise_reward=0.20628544688224792\n",
      "global_step=7136, episodic_return=20.0, surprise_reward=0.15373137593269348\n",
      "global_step=7152, episodic_return=16.0, surprise_reward=0.0524582639336586\n",
      "SPS: 298\n",
      "global_step=7176, episodic_return=18.0, surprise_reward=0.10156217962503433\n",
      "global_step=7192, episodic_return=20.0, surprise_reward=0.1300775706768036\n",
      "global_step=7224, episodic_return=15.0, surprise_reward=0.07473833858966827\n",
      "global_step=7320, episodic_return=23.0, surprise_reward=0.2629556357860565\n",
      "global_step=7336, episodic_return=14.0, surprise_reward=0.2627527117729187\n",
      "global_step=7360, episodic_return=21.0, surprise_reward=0.1414378583431244\n",
      "global_step=7384, episodic_return=78.0, surprise_reward=0.1035860925912857\n",
      "global_step=7424, episodic_return=13.0, surprise_reward=0.19855818152427673\n",
      "global_step=7464, episodic_return=13.0, surprise_reward=0.22552481293678284\n",
      "global_step=7496, episodic_return=61.0, surprise_reward=0.0702008455991745\n",
      "global_step=7544, episodic_return=52.0, surprise_reward=0.03974854201078415\n",
      "global_step=7568, episodic_return=23.0, surprise_reward=0.045578718185424805\n",
      "global_step=7616, episodic_return=55.0, surprise_reward=0.16637371480464935\n",
      "global_step=7632, episodic_return=21.0, surprise_reward=0.11834758520126343\n",
      "global_step=7632, episodic_return=37.0, surprise_reward=0.11834758520126343\n",
      "global_step=7632, episodic_return=17.0, surprise_reward=0.11834758520126343\n",
      "global_step=7640, episodic_return=27.0, surprise_reward=0.051493000239133835\n",
      "global_step=7696, episodic_return=16.0, surprise_reward=0.10904775559902191\n",
      "global_step=7712, episodic_return=21.0, surprise_reward=0.10130196809768677\n",
      "global_step=7768, episodic_return=17.0, surprise_reward=0.09508810937404633\n",
      "global_step=7768, episodic_return=17.0, surprise_reward=0.09508810937404633\n",
      "global_step=7792, episodic_return=19.0, surprise_reward=0.14416858553886414\n",
      "global_step=7824, episodic_return=26.0, surprise_reward=0.24120092391967773\n",
      "global_step=7832, episodic_return=25.0, surprise_reward=0.10276775062084198\n",
      "global_step=7864, episodic_return=12.0, surprise_reward=0.19765377044677734\n",
      "global_step=7912, episodic_return=27.0, surprise_reward=0.16695186495780945\n",
      "global_step=7960, episodic_return=21.0, surprise_reward=0.1920088529586792\n",
      "global_step=7968, episodic_return=17.0, surprise_reward=0.21935173869132996\n",
      "global_step=7992, episodic_return=10.0, surprise_reward=0.21419548988342285\n",
      "global_step=8008, episodic_return=23.0, surprise_reward=0.2001398205757141\n",
      "global_step=8048, episodic_return=112.0, surprise_reward=0.2231607884168625\n",
      "global_step=8048, episodic_return=42.0, surprise_reward=0.2231607884168625\n",
      "global_step=8056, episodic_return=24.0, surprise_reward=0.041835568845272064\n",
      "global_step=8064, episodic_return=12.0, surprise_reward=0.0754285603761673\n",
      "global_step=8112, episodic_return=13.0, surprise_reward=0.352863609790802\n",
      "global_step=8120, episodic_return=9.0, surprise_reward=0.3917638063430786\n",
      "global_step=8136, episodic_return=10.0, surprise_reward=0.0966532826423645\n",
      "global_step=8136, episodic_return=18.0, surprise_reward=0.0966532826423645\n",
      "global_step=8168, episodic_return=13.0, surprise_reward=0.16826015710830688\n",
      "global_step=8184, episodic_return=52.0, surprise_reward=0.1868293136358261\n",
      "SPS: 262\n",
      "global_step=8200, episodic_return=19.0, surprise_reward=0.14946866035461426\n",
      "global_step=8232, episodic_return=12.0, surprise_reward=0.06989123672246933\n",
      "global_step=8272, episodic_return=20.0, surprise_reward=0.06375110149383545\n",
      "global_step=8272, episodic_return=39.0, surprise_reward=0.06375110149383545\n",
      "global_step=8312, episodic_return=24.0, surprise_reward=0.1208951324224472\n",
      "global_step=8368, episodic_return=29.0, surprise_reward=0.09091603755950928\n",
      "global_step=8400, episodic_return=16.0, surprise_reward=0.053165458142757416\n",
      "global_step=8424, episodic_return=24.0, surprise_reward=0.07478165626525879\n",
      "global_step=8448, episodic_return=33.0, surprise_reward=0.06038100644946098\n",
      "global_step=8448, episodic_return=17.0, surprise_reward=0.06038100644946098\n",
      "global_step=8488, episodic_return=36.0, surprise_reward=0.06941501051187515\n",
      "global_step=8544, episodic_return=22.0, surprise_reward=0.07178191095590591\n",
      "global_step=8592, episodic_return=24.0, surprise_reward=0.12368100881576538\n",
      "global_step=8648, episodic_return=13.0, surprise_reward=0.14855557680130005\n",
      "global_step=8648, episodic_return=28.0, surprise_reward=0.14855557680130005\n",
      "global_step=8696, episodic_return=26.0, surprise_reward=0.26363039016723633\n",
      "global_step=8712, episodic_return=15.0, surprise_reward=0.32593655586242676\n",
      "global_step=8720, episodic_return=9.0, surprise_reward=0.2959953546524048\n",
      "global_step=8736, episodic_return=71.0, surprise_reward=0.17875048518180847\n",
      "global_step=8744, episodic_return=37.0, surprise_reward=0.18220923840999603\n",
      "global_step=8760, episodic_return=39.0, surprise_reward=0.07920277118682861\n",
      "global_step=8840, episodic_return=71.0, surprise_reward=0.0934084802865982\n",
      "global_step=8856, episodic_return=14.0, surprise_reward=0.09368693083524704\n",
      "global_step=8912, episodic_return=19.0, surprise_reward=0.22635361552238464\n",
      "global_step=8920, episodic_return=26.0, surprise_reward=0.03970254212617874\n",
      "global_step=8920, episodic_return=28.0, surprise_reward=0.03970254212617874\n",
      "global_step=8920, episodic_return=10.0, surprise_reward=0.03970254212617874\n",
      "global_step=8968, episodic_return=31.0, surprise_reward=0.1305720955133438\n",
      "global_step=8984, episodic_return=42.0, surprise_reward=0.057116053998470306\n",
      "global_step=8984, episodic_return=31.0, surprise_reward=0.057116053998470306\n",
      "global_step=9008, episodic_return=12.0, surprise_reward=0.054041747003793716\n",
      "global_step=9016, episodic_return=20.0, surprise_reward=0.03319675475358963\n",
      "global_step=9072, episodic_return=19.0, surprise_reward=0.09244754910469055\n",
      "global_step=9104, episodic_return=17.0, surprise_reward=0.04527312517166138\n",
      "global_step=9104, episodic_return=23.0, surprise_reward=0.04527312517166138\n",
      "global_step=9144, episodic_return=17.0, surprise_reward=0.1485103964805603\n",
      "global_step=9176, episodic_return=20.0, surprise_reward=0.20497038960456848\n",
      "global_step=9184, episodic_return=10.0, surprise_reward=0.12501007318496704\n",
      "global_step=9200, episodic_return=35.0, surprise_reward=0.06969022750854492\n",
      "SPS: 285\n",
      "global_step=9256, episodic_return=9.0, surprise_reward=0.08415418118238449\n",
      "global_step=9272, episodic_return=25.0, surprise_reward=0.09140130877494812\n",
      "global_step=9288, episodic_return=18.0, surprise_reward=0.0672675371170044\n",
      "global_step=9288, episodic_return=38.0, surprise_reward=0.0672675371170044\n",
      "global_step=9336, episodic_return=29.0, surprise_reward=0.03661182522773743\n",
      "global_step=9408, episodic_return=17.0, surprise_reward=0.08077248185873032\n",
      "global_step=9472, episodic_return=17.0, surprise_reward=0.23536187410354614\n",
      "global_step=9480, episodic_return=62.0, surprise_reward=0.025881143286824226\n",
      "global_step=9480, episodic_return=38.0, surprise_reward=0.025881143286824226\n",
      "global_step=9552, episodic_return=9.0, surprise_reward=0.14803145825862885\n",
      "global_step=9560, episodic_return=34.0, surprise_reward=0.18191882967948914\n",
      "global_step=9560, episodic_return=45.0, surprise_reward=0.18191882967948914\n",
      "global_step=9592, episodic_return=42.0, surprise_reward=0.06740774214267731\n",
      "global_step=9592, episodic_return=14.0, surprise_reward=0.06740774214267731\n",
      "global_step=9608, episodic_return=25.0, surprise_reward=0.10504239797592163\n",
      "global_step=9624, episodic_return=19.0, surprise_reward=0.03238872438669205\n",
      "global_step=9792, episodic_return=21.0, surprise_reward=0.09020613878965378\n",
      "global_step=9792, episodic_return=30.0, surprise_reward=0.09020613878965378\n",
      "global_step=9856, episodic_return=37.0, surprise_reward=0.08614600449800491\n",
      "global_step=9864, episodic_return=32.0, surprise_reward=0.10136464983224869\n",
      "global_step=9880, episodic_return=36.0, surprise_reward=0.09090077877044678\n",
      "global_step=9920, episodic_return=79.0, surprise_reward=0.06473332643508911\n",
      "global_step=9928, episodic_return=17.0, surprise_reward=0.06374851614236832\n",
      "global_step=9976, episodic_return=14.0, surprise_reward=0.048218823969364166\n",
      "global_step=10000, episodic_return=51.0, surprise_reward=0.0912780612707138\n",
      "global_step=10024, episodic_return=12.0, surprise_reward=0.07783916592597961\n",
      "global_step=10040, episodic_return=60.0, surprise_reward=0.06003100052475929\n",
      "global_step=10072, episodic_return=19.0, surprise_reward=0.06747333705425262\n",
      "global_step=10112, episodic_return=11.0, surprise_reward=0.0761064738035202\n",
      "global_step=10144, episodic_return=33.0, surprise_reward=0.0761859267950058\n",
      "global_step=10144, episodic_return=36.0, surprise_reward=0.0761859267950058\n",
      "global_step=10168, episodic_return=12.0, surprise_reward=0.05658824369311333\n",
      "global_step=10208, episodic_return=21.0, surprise_reward=0.08457159250974655\n",
      "SPS: 257\n",
      "global_step=10272, episodic_return=20.0, surprise_reward=0.09708351641893387\n",
      "global_step=10296, episodic_return=37.0, surprise_reward=0.15837952494621277\n",
      "global_step=10304, episodic_return=20.0, surprise_reward=0.11817565560340881\n",
      "global_step=10312, episodic_return=18.0, surprise_reward=0.09813378751277924\n",
      "global_step=10320, episodic_return=43.0, surprise_reward=0.11764521896839142\n",
      "global_step=10336, episodic_return=24.0, surprise_reward=0.1444491147994995\n",
      "global_step=10360, episodic_return=19.0, surprise_reward=0.12104862928390503\n",
      "global_step=10384, episodic_return=14.0, surprise_reward=0.054396577179431915\n",
      "global_step=10384, episodic_return=10.0, surprise_reward=0.054396577179431915\n",
      "global_step=10448, episodic_return=16.0, surprise_reward=0.1311449408531189\n",
      "global_step=10456, episodic_return=83.0, surprise_reward=0.04492698609828949\n",
      "global_step=10584, episodic_return=36.0, surprise_reward=0.10148191452026367\n",
      "global_step=10592, episodic_return=32.0, surprise_reward=0.045900244265794754\n",
      "global_step=10592, episodic_return=29.0, surprise_reward=0.045900244265794754\n",
      "global_step=10664, episodic_return=44.0, surprise_reward=0.21805211901664734\n",
      "global_step=10664, episodic_return=26.0, surprise_reward=0.21805211901664734\n",
      "global_step=10688, episodic_return=38.0, surprise_reward=0.13557201623916626\n",
      "global_step=10688, episodic_return=13.0, surprise_reward=0.13557201623916626\n",
      "global_step=10704, episodic_return=14.0, surprise_reward=0.08186416327953339\n",
      "global_step=10704, episodic_return=32.0, surprise_reward=0.08186416327953339\n",
      "global_step=10712, episodic_return=15.0, surprise_reward=0.05420665442943573\n",
      "global_step=10752, episodic_return=11.0, surprise_reward=0.05122893303632736\n",
      "global_step=10792, episodic_return=16.0, surprise_reward=0.09242045879364014\n",
      "global_step=10824, episodic_return=14.0, surprise_reward=0.047026824206113815\n",
      "global_step=10856, episodic_return=59.0, surprise_reward=0.05163002759218216\n",
      "global_step=10872, episodic_return=21.0, surprise_reward=0.11975204944610596\n",
      "global_step=10880, episodic_return=24.0, surprise_reward=0.13169850409030914\n",
      "global_step=10920, episodic_return=27.0, surprise_reward=0.07768749445676804\n",
      "global_step=10928, episodic_return=30.0, surprise_reward=0.05945611745119095\n",
      "global_step=10984, episodic_return=20.0, surprise_reward=0.10330262780189514\n",
      "global_step=11016, episodic_return=12.0, surprise_reward=0.15293672680854797\n",
      "global_step=11024, episodic_return=29.0, surprise_reward=0.13050277531147003\n",
      "global_step=11032, episodic_return=22.0, surprise_reward=0.0978177860379219\n",
      "global_step=11080, episodic_return=41.0, surprise_reward=0.07083549350500107\n",
      "global_step=11128, episodic_return=31.0, surprise_reward=0.21759141981601715\n",
      "global_step=11136, episodic_return=26.0, surprise_reward=0.1280244141817093\n",
      "global_step=11136, episodic_return=19.0, surprise_reward=0.1280244141817093\n",
      "global_step=11144, episodic_return=14.0, surprise_reward=0.15255914628505707\n",
      "global_step=11168, episodic_return=37.0, surprise_reward=0.08108736574649811\n",
      "global_step=11208, episodic_return=23.0, surprise_reward=0.06568989902734756\n",
      "global_step=11240, episodic_return=14.0, surprise_reward=0.17780199646949768\n",
      "global_step=11264, episodic_return=16.0, surprise_reward=0.1354251503944397\n",
      "SPS: 276\n",
      "global_step=11280, episodic_return=33.0, surprise_reward=0.13173586130142212\n",
      "global_step=11320, episodic_return=23.0, surprise_reward=0.08781582117080688\n",
      "global_step=11344, episodic_return=13.0, surprise_reward=0.13710099458694458\n",
      "global_step=11352, episodic_return=26.0, surprise_reward=0.0666046068072319\n",
      "global_step=11352, episodic_return=18.0, surprise_reward=0.0666046068072319\n",
      "global_step=11392, episodic_return=16.0, surprise_reward=0.050034359097480774\n",
      "global_step=11456, episodic_return=47.0, surprise_reward=0.06800343096256256\n",
      "global_step=11496, episodic_return=22.0, surprise_reward=0.13355384767055511\n",
      "global_step=11552, episodic_return=34.0, surprise_reward=0.09015047550201416\n",
      "global_step=11568, episodic_return=28.0, surprise_reward=0.13471662998199463\n",
      "global_step=11632, episodic_return=22.0, surprise_reward=0.13244079053401947\n",
      "global_step=11664, episodic_return=21.0, surprise_reward=0.12162094563245773\n",
      "global_step=11664, episodic_return=34.0, surprise_reward=0.12162094563245773\n",
      "global_step=11672, episodic_return=40.0, surprise_reward=0.021573873236775398\n",
      "global_step=11672, episodic_return=63.0, surprise_reward=0.021573873236775398\n",
      "global_step=11728, episodic_return=22.0, surprise_reward=0.04580789804458618\n",
      "global_step=11768, episodic_return=52.0, surprise_reward=0.07045716047286987\n",
      "global_step=11816, episodic_return=19.0, surprise_reward=0.09899038821458817\n",
      "global_step=11848, episodic_return=35.0, surprise_reward=0.11166705191135406\n",
      "global_step=11880, episodic_return=14.0, surprise_reward=0.07186852395534515\n",
      "global_step=11896, episodic_return=28.0, surprise_reward=0.12110462039709091\n",
      "global_step=11928, episodic_return=32.0, surprise_reward=0.04785946011543274\n",
      "global_step=11952, episodic_return=36.0, surprise_reward=0.03781270608305931\n",
      "global_step=12008, episodic_return=20.0, surprise_reward=0.033776454627513885\n",
      "global_step=12008, episodic_return=24.0, surprise_reward=0.033776454627513885\n",
      "global_step=12040, episodic_return=51.0, surprise_reward=0.1968117356300354\n",
      "global_step=12072, episodic_return=18.0, surprise_reward=0.11861535161733627\n",
      "global_step=12096, episodic_return=46.0, surprise_reward=0.02144285850226879\n",
      "global_step=12176, episodic_return=35.0, surprise_reward=0.060051899403333664\n",
      "global_step=12216, episodic_return=22.0, surprise_reward=0.13764464855194092\n",
      "global_step=12232, episodic_return=28.0, surprise_reward=0.09336620569229126\n",
      "global_step=12256, episodic_return=47.0, surprise_reward=0.10699405521154404\n",
      "global_step=12288, episodic_return=42.0, surprise_reward=0.12747898697853088\n",
      "SPS: 252\n",
      "global_step=12336, episodic_return=15.0, surprise_reward=0.1522475779056549\n",
      "global_step=12376, episodic_return=25.0, surprise_reward=0.09302017092704773\n",
      "global_step=12416, episodic_return=20.0, surprise_reward=0.12416676431894302\n",
      "global_step=12456, episodic_return=56.0, surprise_reward=0.059374477714300156\n",
      "global_step=12528, episodic_return=30.0, surprise_reward=0.08526274561882019\n",
      "global_step=12584, episodic_return=61.0, surprise_reward=0.08988717198371887\n",
      "global_step=12608, episodic_return=34.0, surprise_reward=0.0534697026014328\n",
      "global_step=12656, episodic_return=35.0, surprise_reward=0.10567599534988403\n",
      "global_step=12672, episodic_return=55.0, surprise_reward=0.04405945912003517\n",
      "global_step=12688, episodic_return=20.0, surprise_reward=0.03574126958847046\n",
      "global_step=12736, episodic_return=40.0, surprise_reward=0.1397361308336258\n",
      "global_step=12752, episodic_return=18.0, surprise_reward=0.132464200258255\n",
      "global_step=12760, episodic_return=13.0, surprise_reward=0.15038059651851654\n",
      "global_step=12776, episodic_return=88.0, surprise_reward=0.06721524149179459\n",
      "global_step=12816, episodic_return=29.0, surprise_reward=0.09356557577848434\n",
      "global_step=12848, episodic_return=14.0, surprise_reward=0.10170011222362518\n",
      "global_step=12872, episodic_return=14.0, surprise_reward=0.10379227995872498\n",
      "global_step=12888, episodic_return=14.0, surprise_reward=0.03731534257531166\n",
      "global_step=12984, episodic_return=17.0, surprise_reward=0.15123237669467926\n",
      "global_step=12992, episodic_return=38.0, surprise_reward=0.1506490707397461\n",
      "global_step=13008, episodic_return=17.0, surprise_reward=0.08339756727218628\n",
      "global_step=13088, episodic_return=52.0, surprise_reward=0.10755742341279984\n",
      "global_step=13128, episodic_return=47.0, surprise_reward=0.11112216114997864\n",
      "global_step=13144, episodic_return=86.0, surprise_reward=0.04029381647706032\n",
      "global_step=13144, episodic_return=32.0, surprise_reward=0.04029381647706032\n",
      "global_step=13192, episodic_return=26.0, surprise_reward=0.06306461989879608\n",
      "global_step=13216, episodic_return=50.0, surprise_reward=0.06196309253573418\n",
      "global_step=13264, episodic_return=22.0, surprise_reward=0.11089427024126053\n",
      "global_step=13296, episodic_return=19.0, surprise_reward=0.05183921754360199\n",
      "global_step=13296, episodic_return=19.0, surprise_reward=0.05183921754360199\n",
      "SPS: 267\n",
      "global_step=13320, episodic_return=13.0, surprise_reward=0.05647718906402588\n",
      "global_step=13416, episodic_return=19.0, surprise_reward=0.07975518703460693\n",
      "global_step=13440, episodic_return=56.0, surprise_reward=0.14306847751140594\n",
      "global_step=13464, episodic_return=42.0, surprise_reward=0.06783096492290497\n",
      "global_step=13480, episodic_return=23.0, surprise_reward=0.061431992799043655\n",
      "global_step=13496, episodic_return=25.0, surprise_reward=0.051879335194826126\n",
      "global_step=13512, episodic_return=24.0, surprise_reward=0.07254835218191147\n",
      "global_step=13552, episodic_return=45.0, surprise_reward=0.09215335547924042\n",
      "global_step=13560, episodic_return=15.0, surprise_reward=0.08989139646291733\n",
      "global_step=13584, episodic_return=72.0, surprise_reward=0.06788694113492966\n",
      "global_step=13608, episodic_return=12.0, surprise_reward=0.031289905309677124\n",
      "global_step=13672, episodic_return=22.0, surprise_reward=0.062287651002407074\n",
      "global_step=13680, episodic_return=25.0, surprise_reward=0.08300204575061798\n",
      "global_step=13768, episodic_return=27.0, surprise_reward=0.07526811212301254\n",
      "global_step=13792, episodic_return=26.0, surprise_reward=0.06628018617630005\n",
      "global_step=13832, episodic_return=19.0, surprise_reward=0.07815209031105042\n",
      "global_step=13872, episodic_return=57.0, surprise_reward=0.09376754611730576\n",
      "global_step=13904, episodic_return=14.0, surprise_reward=0.04722781479358673\n",
      "global_step=13936, episodic_return=21.0, surprise_reward=0.03379715979099274\n",
      "global_step=13976, episodic_return=46.0, surprise_reward=0.08726295828819275\n",
      "global_step=14016, episodic_return=69.0, surprise_reward=0.05228558927774429\n",
      "global_step=14048, episodic_return=18.0, surprise_reward=0.03739696741104126\n",
      "global_step=14064, episodic_return=63.0, surprise_reward=0.033500492572784424\n",
      "global_step=14096, episodic_return=28.0, surprise_reward=0.05691508203744888\n",
      "global_step=14176, episodic_return=30.0, surprise_reward=0.0708470344543457\n",
      "global_step=14248, episodic_return=34.0, surprise_reward=0.045402854681015015\n",
      "global_step=14248, episodic_return=19.0, surprise_reward=0.045402854681015015\n",
      "global_step=14304, episodic_return=32.0, surprise_reward=0.07670540362596512\n",
      "global_step=14328, episodic_return=39.0, surprise_reward=0.1397765874862671\n",
      "SPS: 249\n",
      "global_step=14344, episodic_return=12.0, surprise_reward=0.1640506386756897\n",
      "global_step=14360, episodic_return=86.0, surprise_reward=0.09388542175292969\n",
      "global_step=14368, episodic_return=15.0, surprise_reward=0.05541187524795532\n",
      "global_step=14408, episodic_return=43.0, surprise_reward=0.10778775066137314\n",
      "global_step=14480, episodic_return=38.0, surprise_reward=0.03252296894788742\n",
      "global_step=14528, episodic_return=20.0, surprise_reward=0.05307255685329437\n",
      "global_step=14536, episodic_return=88.0, surprise_reward=0.07014510035514832\n",
      "global_step=14576, episodic_return=29.0, surprise_reward=0.05475106090307236\n",
      "global_step=14632, episodic_return=41.0, surprise_reward=0.13034836947917938\n",
      "global_step=14640, episodic_return=35.0, surprise_reward=0.10514400899410248\n",
      "global_step=14672, episodic_return=33.0, surprise_reward=0.10973984748125076\n",
      "global_step=14736, episodic_return=20.0, surprise_reward=0.08670070022344589\n",
      "global_step=14736, episodic_return=26.0, surprise_reward=0.08670070022344589\n",
      "global_step=14768, episodic_return=55.0, surprise_reward=0.030992642045021057\n",
      "global_step=14880, episodic_return=30.0, surprise_reward=0.04810592532157898\n",
      "global_step=14896, episodic_return=33.0, surprise_reward=0.0698854848742485\n",
      "global_step=15000, episodic_return=65.0, surprise_reward=0.07403627038002014\n",
      "global_step=15016, episodic_return=35.0, surprise_reward=0.09443263709545135\n",
      "global_step=15080, episodic_return=43.0, surprise_reward=0.1499294638633728\n",
      "global_step=15096, episodic_return=27.0, surprise_reward=0.11521629244089127\n",
      "global_step=15112, episodic_return=72.0, surprise_reward=0.12859435379505157\n",
      "global_step=15160, episodic_return=10.0, surprise_reward=0.142825648188591\n",
      "global_step=15160, episodic_return=49.0, surprise_reward=0.142825648188591\n",
      "global_step=15240, episodic_return=43.0, surprise_reward=0.22238464653491974\n",
      "global_step=15248, episodic_return=72.0, surprise_reward=0.10886871069669724\n",
      "global_step=15256, episodic_return=32.0, surprise_reward=0.06259174644947052\n",
      "global_step=15272, episodic_return=32.0, surprise_reward=0.08400292694568634\n",
      "global_step=15288, episodic_return=16.0, surprise_reward=0.07314489036798477\n",
      "global_step=15360, episodic_return=13.0, surprise_reward=0.06783205270767212\n",
      "SPS: 262\n",
      "global_step=15368, episodic_return=32.0, surprise_reward=0.06211452931165695\n",
      "global_step=15384, episodic_return=14.0, surprise_reward=0.06232109293341637\n",
      "global_step=15424, episodic_return=17.0, surprise_reward=0.10200420767068863\n",
      "global_step=15424, episodic_return=22.0, surprise_reward=0.10200420767068863\n",
      "global_step=15432, episodic_return=24.0, surprise_reward=0.03827602416276932\n",
      "global_step=15488, episodic_return=41.0, surprise_reward=0.10697135329246521\n",
      "global_step=15496, episodic_return=50.0, surprise_reward=0.04286131635308266\n",
      "global_step=15552, episodic_return=23.0, surprise_reward=0.07890498638153076\n",
      "global_step=15568, episodic_return=26.0, surprise_reward=0.10558253526687622\n",
      "global_step=15576, episodic_return=19.0, surprise_reward=0.07658252120018005\n",
      "global_step=15608, episodic_return=23.0, surprise_reward=0.06004412844777107\n",
      "global_step=15672, episodic_return=22.0, surprise_reward=0.06030050665140152\n",
      "global_step=15744, episodic_return=22.0, surprise_reward=0.12910716235637665\n",
      "global_step=15760, episodic_return=19.0, surprise_reward=0.10571540892124176\n",
      "global_step=15784, episodic_return=50.0, surprise_reward=0.0882473886013031\n",
      "global_step=15808, episodic_return=29.0, surprise_reward=0.10903337597846985\n",
      "global_step=15952, episodic_return=26.0, surprise_reward=0.14480912685394287\n",
      "global_step=15960, episodic_return=22.0, surprise_reward=0.12726545333862305\n",
      "global_step=16016, episodic_return=66.0, surprise_reward=0.0999755859375\n",
      "global_step=16048, episodic_return=62.0, surprise_reward=0.08762234449386597\n",
      "global_step=16056, episodic_return=31.0, surprise_reward=0.09217187762260437\n",
      "global_step=16064, episodic_return=79.0, surprise_reward=0.054638560861349106\n",
      "global_step=16096, episodic_return=42.0, surprise_reward=0.06348228454589844\n",
      "global_step=16120, episodic_return=13.0, surprise_reward=0.05402237921953201\n",
      "global_step=16160, episodic_return=25.0, surprise_reward=0.04980150982737541\n",
      "global_step=16168, episodic_return=62.0, surprise_reward=0.03579006716609001\n",
      "global_step=16224, episodic_return=21.0, surprise_reward=0.04971010982990265\n",
      "global_step=16280, episodic_return=20.0, surprise_reward=0.11870577186346054\n",
      "global_step=16288, episodic_return=42.0, surprise_reward=0.06295482814311981\n",
      "global_step=16360, episodic_return=39.0, surprise_reward=0.06860946118831635\n",
      "SPS: 244\n",
      "global_step=16440, episodic_return=35.0, surprise_reward=0.06265552341938019\n",
      "global_step=16456, episodic_return=29.0, surprise_reward=0.04847526550292969\n",
      "global_step=16496, episodic_return=54.0, surprise_reward=0.031042706221342087\n",
      "global_step=16544, episodic_return=33.0, surprise_reward=0.05189599469304085\n",
      "global_step=16576, episodic_return=36.0, surprise_reward=0.08897644281387329\n",
      "global_step=16600, episodic_return=54.0, surprise_reward=0.029533477500081062\n",
      "global_step=16664, episodic_return=28.0, surprise_reward=0.05091027915477753\n",
      "global_step=16688, episodic_return=74.0, surprise_reward=0.03411567211151123\n",
      "global_step=16792, episodic_return=54.0, surprise_reward=0.06354090571403503\n",
      "global_step=16824, episodic_return=20.0, surprise_reward=0.046088531613349915\n",
      "global_step=16824, episodic_return=17.0, surprise_reward=0.046088531613349915\n",
      "global_step=16920, episodic_return=53.0, surprise_reward=0.09466172754764557\n",
      "global_step=17056, episodic_return=29.0, surprise_reward=0.2247220277786255\n",
      "global_step=17080, episodic_return=32.0, surprise_reward=0.14883136749267578\n",
      "global_step=17152, episodic_return=45.0, surprise_reward=0.1685827225446701\n",
      "global_step=17232, episodic_return=97.0, surprise_reward=0.2531185448169708\n",
      "global_step=17240, episodic_return=80.0, surprise_reward=0.05285678431391716\n",
      "global_step=17240, episodic_return=83.0, surprise_reward=0.05285678431391716\n",
      "global_step=17256, episodic_return=42.0, surprise_reward=0.058678507804870605\n",
      "global_step=17320, episodic_return=11.0, surprise_reward=0.07627855241298676\n",
      "global_step=17328, episodic_return=22.0, surprise_reward=0.04952194169163704\n",
      "SPS: 254\n",
      "global_step=17416, episodic_return=42.0, surprise_reward=0.1188231110572815\n",
      "global_step=17416, episodic_return=109.0, surprise_reward=0.1188231110572815\n",
      "global_step=17432, episodic_return=13.0, surprise_reward=0.11445334553718567\n",
      "global_step=17448, episodic_return=26.0, surprise_reward=0.0734265074133873\n",
      "global_step=17520, episodic_return=33.0, surprise_reward=0.17367702722549438\n",
      "global_step=17568, episodic_return=64.0, surprise_reward=0.08375252038240433\n",
      "global_step=17616, episodic_return=25.0, surprise_reward=0.15544354915618896\n",
      "global_step=17648, episodic_return=41.0, surprise_reward=0.10869163274765015\n",
      "global_step=17656, episodic_return=28.0, surprise_reward=0.12025296688079834\n",
      "global_step=17704, episodic_return=17.0, surprise_reward=0.07935887575149536\n",
      "global_step=17768, episodic_return=40.0, surprise_reward=0.1985885053873062\n",
      "global_step=17784, episodic_return=10.0, surprise_reward=0.140468567609787\n",
      "global_step=17800, episodic_return=48.0, surprise_reward=0.11725451797246933\n",
      "global_step=17856, episodic_return=30.0, surprise_reward=0.14647942781448364\n",
      "global_step=17880, episodic_return=12.0, surprise_reward=0.14150720834732056\n",
      "global_step=17880, episodic_return=29.0, surprise_reward=0.14150720834732056\n",
      "global_step=17888, episodic_return=15.0, surprise_reward=0.08529666811227798\n",
      "global_step=17920, episodic_return=50.0, surprise_reward=0.08178744465112686\n",
      "global_step=17968, episodic_return=91.0, surprise_reward=0.055061228573322296\n",
      "global_step=18024, episodic_return=21.0, surprise_reward=0.03673943132162094\n",
      "global_step=18056, episodic_return=32.0, surprise_reward=0.06731074303388596\n",
      "global_step=18136, episodic_return=32.0, surprise_reward=0.09315916895866394\n",
      "global_step=18192, episodic_return=38.0, surprise_reward=0.08170309662818909\n",
      "global_step=18240, episodic_return=34.0, surprise_reward=0.10590355843305588\n",
      "global_step=18360, episodic_return=21.0, surprise_reward=0.1905927062034607\n",
      "global_step=18368, episodic_return=29.0, surprise_reward=0.18589362502098083\n",
      "global_step=18384, episodic_return=58.0, surprise_reward=0.08730332553386688\n",
      "global_step=18384, episodic_return=91.0, surprise_reward=0.08730332553386688\n",
      "SPS: 235\n",
      "global_step=18472, episodic_return=13.0, surprise_reward=0.11375969648361206\n",
      "global_step=18472, episodic_return=29.0, surprise_reward=0.11375969648361206\n",
      "global_step=18496, episodic_return=14.0, surprise_reward=0.11289166659116745\n",
      "global_step=18512, episodic_return=61.0, surprise_reward=0.13036876916885376\n",
      "global_step=18520, episodic_return=58.0, surprise_reward=0.04875197634100914\n",
      "global_step=18552, episodic_return=24.0, surprise_reward=0.07101858407258987\n",
      "global_step=18600, episodic_return=13.0, surprise_reward=0.06243781000375748\n",
      "global_step=18608, episodic_return=28.0, surprise_reward=0.049192190170288086\n",
      "global_step=18640, episodic_return=15.0, surprise_reward=0.06535982340574265\n",
      "global_step=18664, episodic_return=19.0, surprise_reward=0.055024564266204834\n",
      "global_step=18688, episodic_return=17.0, surprise_reward=0.05555325001478195\n",
      "global_step=18784, episodic_return=23.0, surprise_reward=0.12322971224784851\n",
      "global_step=18808, episodic_return=42.0, surprise_reward=0.05503035709261894\n",
      "global_step=18808, episodic_return=116.0, surprise_reward=0.05503035709261894\n",
      "global_step=18864, episodic_return=32.0, surprise_reward=0.0580957792699337\n",
      "global_step=18912, episodic_return=34.0, surprise_reward=0.08775794506072998\n",
      "global_step=18912, episodic_return=28.0, surprise_reward=0.08775794506072998\n",
      "global_step=18936, episodic_return=58.0, surprise_reward=0.024629563093185425\n",
      "global_step=18992, episodic_return=23.0, surprise_reward=0.04963422939181328\n",
      "global_step=19048, episodic_return=14.0, surprise_reward=0.05789707228541374\n",
      "global_step=19056, episodic_return=49.0, surprise_reward=0.031162597239017487\n",
      "global_step=19136, episodic_return=28.0, surprise_reward=0.03094540908932686\n",
      "global_step=19152, episodic_return=46.0, surprise_reward=0.03205078840255737\n",
      "global_step=19208, episodic_return=50.0, surprise_reward=0.02671908400952816\n",
      "global_step=19304, episodic_return=49.0, surprise_reward=0.06521612405776978\n",
      "global_step=19320, episodic_return=23.0, surprise_reward=0.06364267319440842\n",
      "global_step=19432, episodic_return=47.0, surprise_reward=0.10427841544151306\n",
      "global_step=19440, episodic_return=17.0, surprise_reward=0.14070269465446472\n",
      "global_step=19456, episodic_return=58.0, surprise_reward=0.09947538375854492\n",
      "SPS: 244\n",
      "global_step=19472, episodic_return=53.0, surprise_reward=0.044562455266714096\n",
      "global_step=19536, episodic_return=41.0, surprise_reward=0.07277022302150726\n",
      "global_step=19568, episodic_return=16.0, surprise_reward=0.10037750005722046\n",
      "global_step=19592, episodic_return=20.0, surprise_reward=0.08471710979938507\n",
      "global_step=19616, episodic_return=18.0, surprise_reward=0.06705202162265778\n",
      "global_step=19656, episodic_return=63.0, surprise_reward=0.040125586092472076\n",
      "global_step=19680, episodic_return=28.0, surprise_reward=0.0470428429543972\n",
      "global_step=19688, episodic_return=46.0, surprise_reward=0.034656718373298645\n",
      "global_step=19720, episodic_return=107.0, surprise_reward=0.04145575314760208\n",
      "global_step=19736, episodic_return=25.0, surprise_reward=0.04962484538555145\n",
      "global_step=19752, episodic_return=20.0, surprise_reward=0.04941972345113754\n",
      "global_step=19824, episodic_return=18.0, surprise_reward=0.03821989893913269\n",
      "global_step=19848, episodic_return=20.0, surprise_reward=0.04511640965938568\n",
      "global_step=19896, episodic_return=30.0, surprise_reward=0.07143089175224304\n",
      "global_step=19912, episodic_return=43.0, surprise_reward=0.05471285432577133\n",
      "global_step=19952, episodic_return=27.0, surprise_reward=0.03643003851175308\n",
      "global_step=19976, episodic_return=32.0, surprise_reward=0.029598411172628403\n",
      "global_step=20032, episodic_return=15.0, surprise_reward=0.07612516731023788\n",
      "global_step=20040, episodic_return=11.0, surprise_reward=0.051008328795433044\n",
      "global_step=20048, episodic_return=28.0, surprise_reward=0.041797615587711334\n",
      "global_step=20128, episodic_return=47.0, surprise_reward=0.04933951422572136\n",
      "global_step=20224, episodic_return=12.0, surprise_reward=0.037710510194301605\n",
      "global_step=20232, episodic_return=25.0, surprise_reward=0.03487539663910866\n",
      "global_step=20272, episodic_return=28.0, surprise_reward=0.051714345812797546\n",
      "global_step=20344, episodic_return=62.0, surprise_reward=0.03614219278097153\n",
      "global_step=20440, episodic_return=68.0, surprise_reward=0.04377437382936478\n",
      "global_step=20472, episodic_return=30.0, surprise_reward=0.03952450677752495\n",
      "SPS: 226\n",
      "global_step=20512, episodic_return=67.0, surprise_reward=0.04985683411359787\n",
      "global_step=20552, episodic_return=117.0, surprise_reward=0.047396183013916016\n",
      "global_step=20592, episodic_return=46.0, surprise_reward=0.0746026560664177\n",
      "global_step=20632, episodic_return=36.0, surprise_reward=0.09738650918006897\n",
      "global_step=20680, episodic_return=16.0, surprise_reward=0.08308979868888855\n",
      "global_step=20776, episodic_return=33.0, surprise_reward=0.20066896080970764\n",
      "global_step=20784, episodic_return=43.0, surprise_reward=0.13844969868659973\n",
      "global_step=20832, episodic_return=99.0, surprise_reward=0.09377885609865189\n",
      "global_step=20872, episodic_return=30.0, surprise_reward=0.16356784105300903\n",
      "global_step=21000, episodic_return=28.0, surprise_reward=0.2669582664966583\n",
      "global_step=21016, episodic_return=23.0, surprise_reward=0.21681568026542664\n",
      "global_step=21016, episodic_return=29.0, surprise_reward=0.21681568026542664\n",
      "global_step=21064, episodic_return=48.0, surprise_reward=0.2636815309524536\n",
      "global_step=21080, episodic_return=76.0, surprise_reward=0.2607765793800354\n",
      "global_step=21176, episodic_return=73.0, surprise_reward=0.25036147236824036\n",
      "global_step=21256, episodic_return=48.0, surprise_reward=0.32600969076156616\n",
      "global_step=21256, episodic_return=24.0, surprise_reward=0.32600969076156616\n",
      "global_step=21280, episodic_return=25.0, surprise_reward=0.30225786566734314\n",
      "global_step=21280, episodic_return=33.0, surprise_reward=0.30225786566734314\n",
      "global_step=21360, episodic_return=23.0, surprise_reward=0.2933623790740967\n",
      "global_step=21416, episodic_return=52.0, surprise_reward=0.25163161754608154\n",
      "global_step=21480, episodic_return=25.0, surprise_reward=0.2776350677013397\n",
      "global_step=21496, episodic_return=153.0, surprise_reward=0.04282022640109062\n",
      "SPS: 234\n",
      "global_step=21592, episodic_return=22.0, surprise_reward=0.043672867119312286\n",
      "global_step=21632, episodic_return=47.0, surprise_reward=0.05610949173569679\n",
      "global_step=21712, episodic_return=54.0, surprise_reward=0.1118733212351799\n",
      "global_step=21720, episodic_return=58.0, surprise_reward=0.08061455190181732\n",
      "global_step=21728, episodic_return=29.0, surprise_reward=0.07886597514152527\n",
      "global_step=21792, episodic_return=97.0, surprise_reward=0.05267532914876938\n",
      "global_step=21888, episodic_return=22.0, surprise_reward=0.06093103438615799\n",
      "global_step=21888, episodic_return=51.0, surprise_reward=0.06093103438615799\n",
      "global_step=21976, episodic_return=23.0, surprise_reward=0.09173564612865448\n",
      "global_step=22000, episodic_return=80.0, surprise_reward=0.07937981188297272\n",
      "global_step=22040, episodic_return=19.0, surprise_reward=0.08128831535577774\n",
      "global_step=22152, episodic_return=70.0, surprise_reward=0.1440819948911667\n",
      "global_step=22152, episodic_return=22.0, surprise_reward=0.1440819948911667\n",
      "global_step=22160, episodic_return=15.0, surprise_reward=0.14547324180603027\n",
      "global_step=22184, episodic_return=58.0, surprise_reward=0.10642150044441223\n",
      "global_step=22208, episodic_return=40.0, surprise_reward=0.11400565505027771\n",
      "global_step=22296, episodic_return=17.0, surprise_reward=0.18435457348823547\n",
      "global_step=22312, episodic_return=85.0, surprise_reward=0.09882137179374695\n",
      "global_step=22328, episodic_return=22.0, surprise_reward=0.0868920087814331\n",
      "global_step=22336, episodic_return=76.0, surprise_reward=0.038563601672649384\n",
      "global_step=22384, episodic_return=29.0, surprise_reward=0.04275267571210861\n",
      "global_step=22424, episodic_return=27.0, surprise_reward=0.05180829018354416\n",
      "global_step=22432, episodic_return=54.0, surprise_reward=0.03542543947696686\n",
      "SPS: 218\n",
      "global_step=22688, episodic_return=63.0, surprise_reward=0.07245926558971405\n",
      "global_step=22720, episodic_return=42.0, surprise_reward=0.07977514714002609\n",
      "global_step=22856, episodic_return=68.0, surprise_reward=0.11197914928197861\n",
      "global_step=22872, episodic_return=68.0, surprise_reward=0.11588267982006073\n",
      "global_step=22880, episodic_return=57.0, surprise_reward=0.061982717365026474\n",
      "global_step=22896, episodic_return=58.0, surprise_reward=0.06235989183187485\n",
      "global_step=23144, episodic_return=36.0, surprise_reward=0.25864917039871216\n",
      "global_step=23152, episodic_return=34.0, surprise_reward=0.28113988041877747\n",
      "global_step=23160, episodic_return=108.0, surprise_reward=0.12074019014835358\n",
      "global_step=23344, episodic_return=82.0, surprise_reward=0.13931246101856232\n",
      "global_step=23424, episodic_return=69.0, surprise_reward=0.15599840879440308\n",
      "global_step=23440, episodic_return=68.0, surprise_reward=0.08719755709171295\n",
      "global_step=23480, episodic_return=143.0, surprise_reward=0.05403741076588631\n",
      "global_step=23512, episodic_return=45.0, surprise_reward=0.0474594309926033\n",
      "SPS: 225\n",
      "global_step=23592, episodic_return=54.0, surprise_reward=0.06625315546989441\n",
      "global_step=23608, episodic_return=16.0, surprise_reward=0.06501779705286026\n",
      "global_step=23632, episodic_return=24.0, surprise_reward=0.07970783859491348\n",
      "global_step=23640, episodic_return=62.0, surprise_reward=0.06299693137407303\n",
      "global_step=23672, episodic_return=119.0, surprise_reward=0.06418286263942719\n",
      "global_step=23744, episodic_return=14.0, surprise_reward=0.10695867240428925\n",
      "global_step=23912, episodic_return=38.0, surprise_reward=0.1678532361984253\n",
      "global_step=23936, episodic_return=24.0, surprise_reward=0.14312320947647095\n",
      "global_step=23952, episodic_return=76.0, surprise_reward=0.11005978286266327\n",
      "global_step=24000, episodic_return=72.0, surprise_reward=0.13268747925758362\n",
      "global_step=24032, episodic_return=49.0, surprise_reward=0.07684050500392914\n",
      "global_step=24064, episodic_return=69.0, surprise_reward=0.09338732063770294\n",
      "global_step=24072, episodic_return=50.0, surprise_reward=0.05180944502353668\n",
      "global_step=24144, episodic_return=69.0, surprise_reward=0.036758631467819214\n",
      "global_step=24216, episodic_return=33.0, surprise_reward=0.027099156752228737\n",
      "global_step=24296, episodic_return=48.0, surprise_reward=0.03536592423915863\n",
      "global_step=24320, episodic_return=36.0, surprise_reward=0.037667836993932724\n",
      "global_step=24408, episodic_return=24.0, surprise_reward=0.04762004315853119\n",
      "global_step=24448, episodic_return=64.0, surprise_reward=0.05054877698421478\n",
      "SPS: 204\n",
      "global_step=24832, episodic_return=86.0, surprise_reward=0.38879507780075073\n",
      "global_step=24832, episodic_return=95.0, surprise_reward=0.38879507780075073\n",
      "global_step=24912, episodic_return=106.0, surprise_reward=0.48774632811546326\n",
      "global_step=24920, episodic_return=115.0, surprise_reward=0.15845081210136414\n",
      "global_step=25056, episodic_return=76.0, surprise_reward=0.2120063453912735\n",
      "global_step=25088, episodic_return=21.0, surprise_reward=0.20283713936805725\n",
      "global_step=25144, episodic_return=92.0, surprise_reward=0.20020762085914612\n",
      "global_step=25304, episodic_return=31.0, surprise_reward=0.24569693207740784\n",
      "global_step=25352, episodic_return=65.0, surprise_reward=0.2594486474990845\n",
      "global_step=25352, episodic_return=129.0, surprise_reward=0.2594486474990845\n",
      "global_step=25376, episodic_return=68.0, surprise_reward=0.04407010227441788\n",
      "global_step=25376, episodic_return=135.0, surprise_reward=0.04407010227441788\n",
      "global_step=25432, episodic_return=36.0, surprise_reward=0.025403231382369995\n",
      "global_step=25504, episodic_return=52.0, surprise_reward=0.030505049973726273\n",
      "global_step=25576, episodic_return=25.0, surprise_reward=0.023490017279982567\n",
      "SPS: 210\n",
      "global_step=25640, episodic_return=36.0, surprise_reward=0.03759266436100006\n",
      "global_step=25768, episodic_return=42.0, surprise_reward=0.06239493936300278\n",
      "global_step=25776, episodic_return=50.0, surprise_reward=0.043963104486465454\n",
      "global_step=26000, episodic_return=136.0, surprise_reward=0.13181006908416748\n",
      "global_step=26040, episodic_return=50.0, surprise_reward=0.08354681730270386\n",
      "global_step=26040, episodic_return=86.0, surprise_reward=0.08354681730270386\n",
      "global_step=26112, episodic_return=101.0, surprise_reward=0.03836672008037567\n",
      "global_step=26200, episodic_return=20.0, surprise_reward=0.05667898803949356\n",
      "global_step=26312, episodic_return=25.0, surprise_reward=0.1132979691028595\n",
      "global_step=26448, episodic_return=85.0, surprise_reward=0.12017799913883209\n",
      "global_step=26448, episodic_return=109.0, surprise_reward=0.12017799913883209\n",
      "global_step=26520, episodic_return=93.0, surprise_reward=0.05712366849184036\n",
      "global_step=26608, episodic_return=20.0, surprise_reward=0.12668375670909882\n",
      "SPS: 191\n",
      "global_step=26760, episodic_return=70.0, surprise_reward=0.221419095993042\n",
      "global_step=26808, episodic_return=36.0, surprise_reward=0.25647807121276855\n",
      "global_step=26928, episodic_return=116.0, surprise_reward=0.4373098313808441\n",
      "global_step=26936, episodic_return=112.0, surprise_reward=0.10440590977668762\n",
      "global_step=26968, episodic_return=82.0, surprise_reward=0.09458845853805542\n",
      "global_step=27056, episodic_return=31.0, surprise_reward=0.09612143039703369\n",
      "global_step=27064, episodic_return=195.0, surprise_reward=0.08555124700069427\n",
      "global_step=27080, episodic_return=79.0, surprise_reward=0.0481119267642498\n",
      "global_step=27136, episodic_return=47.0, surprise_reward=0.049216028302907944\n",
      "global_step=27144, episodic_return=27.0, surprise_reward=0.038291946053504944\n",
      "global_step=27256, episodic_return=81.0, surprise_reward=0.03825630620121956\n",
      "global_step=27272, episodic_return=24.0, surprise_reward=0.03144599869847298\n",
      "global_step=27304, episodic_return=31.0, surprise_reward=0.03931038826704025\n",
      "global_step=27344, episodic_return=51.0, surprise_reward=0.0743730366230011\n",
      "global_step=27408, episodic_return=43.0, surprise_reward=0.047078318893909454\n",
      "global_step=27600, episodic_return=41.0, surprise_reward=0.05284959450364113\n",
      "SPS: 197\n",
      "global_step=27680, episodic_return=67.0, surprise_reward=0.07866299152374268\n",
      "global_step=27696, episodic_return=49.0, surprise_reward=0.07171642780303955\n",
      "global_step=27792, episodic_return=82.0, surprise_reward=0.13793981075286865\n",
      "global_step=27808, episodic_return=14.0, surprise_reward=0.12504033744335175\n",
      "global_step=28072, episodic_return=49.0, surprise_reward=0.5693461298942566\n",
      "global_step=28080, episodic_return=84.0, surprise_reward=0.3784726858139038\n",
      "global_step=28088, episodic_return=37.0, surprise_reward=0.3489464223384857\n",
      "global_step=28152, episodic_return=101.0, surprise_reward=0.3811008334159851\n",
      "global_step=28200, episodic_return=118.0, surprise_reward=0.2047012746334076\n",
      "global_step=28256, episodic_return=56.0, surprise_reward=0.25567471981048584\n",
      "global_step=28272, episodic_return=163.0, surprise_reward=0.22220630943775177\n",
      "global_step=28328, episodic_return=22.0, surprise_reward=0.24526651203632355\n",
      "global_step=28448, episodic_return=47.0, surprise_reward=0.3162790536880493\n",
      "global_step=28624, episodic_return=68.0, surprise_reward=0.3674194812774658\n",
      "SPS: 181\n",
      "global_step=28736, episodic_return=58.0, surprise_reward=0.490121990442276\n",
      "global_step=28752, episodic_return=62.0, surprise_reward=0.47570449113845825\n",
      "global_step=28784, episodic_return=148.0, surprise_reward=0.19265170395374298\n",
      "global_step=28792, episodic_return=88.0, surprise_reward=0.06687819957733154\n",
      "global_step=28840, episodic_return=80.0, surprise_reward=0.027628807350993156\n",
      "global_step=28920, episodic_return=16.0, surprise_reward=0.02975272946059704\n",
      "global_step=29032, episodic_return=35.0, surprise_reward=0.036595337092876434\n",
      "global_step=29144, episodic_return=51.0, surprise_reward=0.08862008154392242\n",
      "global_step=29208, episodic_return=53.0, surprise_reward=0.11160125583410263\n",
      "global_step=29264, episodic_return=43.0, surprise_reward=0.09408342093229294\n",
      "global_step=29320, episodic_return=36.0, surprise_reward=0.1008618175983429\n",
      "global_step=29336, episodic_return=62.0, surprise_reward=0.07788991928100586\n",
      "global_step=29368, episodic_return=115.0, surprise_reward=0.05663272738456726\n",
      "global_step=29480, episodic_return=144.0, surprise_reward=0.043687332421541214\n",
      "global_step=29528, episodic_return=20.0, surprise_reward=0.06222473457455635\n",
      "global_step=29600, episodic_return=49.0, surprise_reward=0.05709826573729515\n",
      "SPS: 186\n",
      "global_step=29816, episodic_return=27.0, surprise_reward=0.14281970262527466\n",
      "global_step=29968, episodic_return=88.0, surprise_reward=0.27184373140335083\n",
      "global_step=29976, episodic_return=80.0, surprise_reward=0.22220680117607117\n",
      "global_step=29984, episodic_return=83.0, surprise_reward=0.12708045542240143\n",
      "global_step=30200, episodic_return=197.0, surprise_reward=0.14917397499084473\n",
      "global_step=30360, episodic_return=152.0, surprise_reward=0.24648164212703705\n",
      "global_step=30368, episodic_return=48.0, surprise_reward=0.23463693261146545\n",
      "global_step=30376, episodic_return=112.0, surprise_reward=0.06495541334152222\n",
      "global_step=30432, episodic_return=77.0, surprise_reward=0.07717371731996536\n",
      "global_step=30448, episodic_return=59.0, surprise_reward=0.0577535554766655\n",
      "global_step=30512, episodic_return=39.0, surprise_reward=0.07125258445739746\n",
      "global_step=30576, episodic_return=76.0, surprise_reward=0.05574801564216614\n",
      "global_step=30592, episodic_return=20.0, surprise_reward=0.06992727518081665\n",
      "global_step=30680, episodic_return=144.0, surprise_reward=0.0557827390730381\n",
      "SPS: 172\n",
      "global_step=30736, episodic_return=28.0, surprise_reward=0.05037130415439606\n",
      "global_step=30952, episodic_return=47.0, surprise_reward=0.14152589440345764\n",
      "global_step=31056, episodic_return=87.0, surprise_reward=0.09166564047336578\n",
      "global_step=31056, episodic_return=85.0, surprise_reward=0.09166564047336578\n",
      "global_step=31168, episodic_return=61.0, surprise_reward=0.1716330498456955\n",
      "global_step=31176, episodic_return=73.0, surprise_reward=0.07055950164794922\n",
      "global_step=31328, episodic_return=120.0, surprise_reward=0.05455593019723892\n",
      "global_step=31544, episodic_return=101.0, surprise_reward=0.08001606911420822\n",
      "global_step=31584, episodic_return=66.0, surprise_reward=0.07438787817955017\n",
      "SPS: 176\n",
      "global_step=31872, episodic_return=102.0, surprise_reward=0.2638607323169708\n",
      "global_step=32016, episodic_return=86.0, surprise_reward=0.362445592880249\n",
      "global_step=32160, episodic_return=214.0, surprise_reward=0.1697361022233963\n",
      "global_step=32184, episodic_return=126.0, surprise_reward=0.17956820130348206\n",
      "global_step=32232, episodic_return=160.0, surprise_reward=0.06896357238292694\n",
      "global_step=32464, episodic_return=38.0, surprise_reward=0.1480274796485901\n",
      "global_step=32752, episodic_return=92.0, surprise_reward=0.4582534730434418\n",
      "SPS: 165\n",
      "global_step=32776, episodic_return=113.0, surprise_reward=0.45593705773353577\n",
      "global_step=32880, episodic_return=214.0, surprise_reward=0.36839044094085693\n",
      "global_step=32904, episodic_return=165.0, surprise_reward=0.25514158606529236\n",
      "global_step=33008, episodic_return=103.0, surprise_reward=0.19947560131549835\n",
      "global_step=33240, episodic_return=61.0, surprise_reward=0.31642767786979675\n",
      "global_step=33440, episodic_return=237.0, surprise_reward=0.4925260841846466\n",
      "global_step=33456, episodic_return=72.0, surprise_reward=0.4951574206352234\n",
      "global_step=33464, episodic_return=154.0, surprise_reward=0.09325198829174042\n",
      "global_step=33480, episodic_return=127.0, surprise_reward=0.054171375930309296\n",
      "SPS: 169\n",
      "global_step=33840, episodic_return=47.0, surprise_reward=0.1430889368057251\n",
      "global_step=33880, episodic_return=53.0, surprise_reward=0.15797725319862366\n",
      "global_step=33912, episodic_return=113.0, surprise_reward=0.12794090807437897\n",
      "global_step=34048, episodic_return=159.0, surprise_reward=0.23997808992862701\n",
      "global_step=34072, episodic_return=104.0, surprise_reward=0.12966082990169525\n",
      "global_step=34264, episodic_return=27.0, surprise_reward=0.15032945573329926\n",
      "global_step=34304, episodic_return=29.0, surprise_reward=0.22543935477733612\n",
      "global_step=34328, episodic_return=178.0, surprise_reward=0.044081926345825195\n",
      "global_step=34752, episodic_return=159.0, surprise_reward=0.10463526844978333\n",
      "SPS: 159\n",
      "global_step=34824, episodic_return=173.0, surprise_reward=0.15628421306610107\n",
      "global_step=34864, episodic_return=128.0, surprise_reward=0.15162406861782074\n",
      "global_step=34904, episodic_return=128.0, surprise_reward=0.1362139880657196\n",
      "global_step=35064, episodic_return=20.0, surprise_reward=0.29603785276412964\n",
      "global_step=35080, episodic_return=32.0, surprise_reward=0.28184181451797485\n",
      "global_step=35200, episodic_return=161.0, surprise_reward=0.43216249346733093\n",
      "global_step=35216, episodic_return=119.0, surprise_reward=0.04682792350649834\n",
      "global_step=35264, episodic_return=50.0, surprise_reward=0.04447074607014656\n",
      "global_step=35296, episodic_return=124.0, surprise_reward=0.04284670948982239\n",
      "global_step=35408, episodic_return=41.0, surprise_reward=0.042350370436906815\n",
      "global_step=35720, episodic_return=53.0, surprise_reward=0.15541724860668182\n",
      "global_step=35832, episodic_return=14.0, surprise_reward=0.1997600644826889\n",
      "SPS: 163\n",
      "global_step=35912, episodic_return=89.0, surprise_reward=0.3475431203842163\n",
      "global_step=36040, episodic_return=214.0, surprise_reward=0.4404590129852295\n",
      "global_step=36048, episodic_return=98.0, surprise_reward=0.30331873893737793\n",
      "global_step=36048, episodic_return=123.0, surprise_reward=0.30331873893737793\n",
      "global_step=36072, episodic_return=83.0, surprise_reward=0.3040783405303955\n",
      "global_step=36200, episodic_return=181.0, surprise_reward=0.0577576607465744\n",
      "global_step=36360, episodic_return=143.0, surprise_reward=0.07972580939531326\n",
      "global_step=36456, episodic_return=68.0, surprise_reward=0.09053349494934082\n",
      "global_step=36480, episodic_return=54.0, surprise_reward=0.08541914075613022\n",
      "global_step=36560, episodic_return=65.0, surprise_reward=0.07405145466327667\n",
      "global_step=36608, episodic_return=70.0, surprise_reward=0.08739344775676727\n",
      "global_step=36720, episodic_return=45.0, surprise_reward=0.10995309054851532\n",
      "global_step=36840, episodic_return=35.0, surprise_reward=0.2256038933992386\n",
      "global_step=36864, episodic_return=99.0, surprise_reward=0.07578906416893005\n",
      "SPS: 153\n",
      "global_step=36896, episodic_return=52.0, surprise_reward=0.06034288555383682\n",
      "global_step=37152, episodic_return=54.0, surprise_reward=0.1634751707315445\n",
      "global_step=37208, episodic_return=172.0, surprise_reward=0.10098462551832199\n",
      "global_step=37336, episodic_return=142.0, surprise_reward=0.1078663021326065\n",
      "global_step=37360, episodic_return=62.0, surprise_reward=0.14153450727462769\n",
      "global_step=37392, episodic_return=117.0, surprise_reward=0.10691763460636139\n",
      "global_step=37424, episodic_return=66.0, surprise_reward=0.09498483687639236\n",
      "global_step=37424, episodic_return=102.0, surprise_reward=0.09498483687639236\n",
      "global_step=37600, episodic_return=30.0, surprise_reward=0.20776382088661194\n",
      "global_step=37608, episodic_return=96.0, surprise_reward=0.06390722841024399\n",
      "global_step=37640, episodic_return=61.0, surprise_reward=0.03360523656010628\n",
      "global_step=37856, episodic_return=58.0, surprise_reward=0.10832037031650543\n",
      "SPS: 157\n",
      "global_step=37896, episodic_return=59.0, surprise_reward=0.09747124463319778\n",
      "global_step=37936, episodic_return=64.0, surprise_reward=0.12983575463294983\n",
      "global_step=38104, episodic_return=112.0, surprise_reward=0.15886852145195007\n",
      "global_step=38336, episodic_return=125.0, surprise_reward=0.3367880582809448\n",
      "global_step=38376, episodic_return=92.0, surprise_reward=0.2951563000679016\n",
      "global_step=38424, episodic_return=66.0, surprise_reward=0.3483283519744873\n",
      "global_step=38544, episodic_return=118.0, surprise_reward=0.2696191072463989\n",
      "global_step=38584, episodic_return=122.0, surprise_reward=0.12375527620315552\n",
      "global_step=38696, episodic_return=45.0, surprise_reward=0.20769578218460083\n",
      "global_step=38912, episodic_return=132.0, surprise_reward=0.19642788171768188\n",
      "SPS: 147\n",
      "global_step=39000, episodic_return=72.0, surprise_reward=0.3095470368862152\n",
      "global_step=39144, episodic_return=151.0, surprise_reward=0.2514871060848236\n",
      "global_step=39224, episodic_return=106.0, surprise_reward=0.30225449800491333\n",
      "global_step=39264, episodic_return=33.0, surprise_reward=0.35248640179634094\n",
      "global_step=39376, episodic_return=85.0, surprise_reward=0.2361336350440979\n",
      "global_step=39376, episodic_return=159.0, surprise_reward=0.2361336350440979\n",
      "global_step=39384, episodic_return=105.0, surprise_reward=0.09456829726696014\n",
      "global_step=39424, episodic_return=105.0, surprise_reward=0.04593683406710625\n",
      "global_step=39544, episodic_return=79.0, surprise_reward=0.045563265681266785\n",
      "global_step=39584, episodic_return=55.0, surprise_reward=0.050508856773376465\n",
      "global_step=39592, episodic_return=46.0, surprise_reward=0.035580918192863464\n",
      "global_step=39776, episodic_return=49.0, surprise_reward=0.06665980815887451\n",
      "global_step=39816, episodic_return=55.0, surprise_reward=0.06341199576854706\n",
      "global_step=39840, episodic_return=72.0, surprise_reward=0.050185807049274445\n",
      "SPS: 150\n",
      "global_step=40016, episodic_return=53.0, surprise_reward=0.08762066066265106\n",
      "global_step=40160, episodic_return=92.0, surprise_reward=0.09442159533500671\n",
      "global_step=40216, episodic_return=84.0, surprise_reward=0.06610847264528275\n",
      "global_step=40488, episodic_return=113.0, surprise_reward=0.2513565421104431\n",
      "global_step=40504, episodic_return=86.0, surprise_reward=0.291115403175354\n",
      "global_step=40648, episodic_return=101.0, surprise_reward=0.1270340383052826\n",
      "global_step=40744, episodic_return=171.0, surprise_reward=0.3251945674419403\n",
      "global_step=40904, episodic_return=141.0, surprise_reward=0.2327663004398346\n",
      "SPS: 141\n",
      "global_step=40992, episodic_return=43.0, surprise_reward=0.3022732138633728\n",
      "global_step=41064, episodic_return=70.0, surprise_reward=0.40252190828323364\n",
      "global_step=41120, episodic_return=120.0, surprise_reward=0.1704213172197342\n",
      "global_step=41296, episodic_return=101.0, surprise_reward=0.37190812826156616\n",
      "global_step=41312, episodic_return=137.0, surprise_reward=0.04674496501684189\n",
      "global_step=41496, episodic_return=63.0, surprise_reward=0.04542694240808487\n",
      "global_step=41544, episodic_return=80.0, surprise_reward=0.07193008065223694\n",
      "global_step=41832, episodic_return=67.0, surprise_reward=0.2712162733078003\n",
      "SPS: 144\n",
      "global_step=42040, episodic_return=68.0, surprise_reward=0.6733855605125427\n",
      "global_step=42072, episodic_return=119.0, surprise_reward=0.3867015838623047\n",
      "global_step=42104, episodic_return=261.0, surprise_reward=0.23727092146873474\n",
      "global_step=42288, episodic_return=153.0, surprise_reward=0.23623298108577728\n",
      "global_step=42296, episodic_return=194.0, surprise_reward=0.2213672250509262\n",
      "global_step=42328, episodic_return=127.0, surprise_reward=0.04924672096967697\n",
      "global_step=42384, episodic_return=105.0, surprise_reward=0.06105763837695122\n",
      "global_step=42400, episodic_return=14.0, surprise_reward=0.04345198720693588\n",
      "global_step=42416, episodic_return=73.0, surprise_reward=0.036324165761470795\n",
      "global_step=42448, episodic_return=43.0, surprise_reward=0.04099487513303757\n",
      "global_step=42520, episodic_return=60.0, surprise_reward=0.02514079213142395\n",
      "global_step=42720, episodic_return=25.0, surprise_reward=0.06718336045742035\n",
      "global_step=42856, episodic_return=59.0, surprise_reward=0.15790103375911713\n",
      "global_step=42920, episodic_return=63.0, surprise_reward=0.12676884233951569\n",
      "global_step=42952, episodic_return=69.0, surprise_reward=0.09429655224084854\n",
      "global_step=43008, episodic_return=89.0, surprise_reward=0.09961386024951935\n",
      "SPS: 136\n",
      "global_step=43360, episodic_return=55.0, surprise_reward=0.2641897201538086\n",
      "global_step=43432, episodic_return=53.0, surprise_reward=0.3112899661064148\n",
      "global_step=43504, episodic_return=179.0, surprise_reward=0.2679188549518585\n",
      "global_step=43736, episodic_return=176.0, surprise_reward=0.3534027338027954\n",
      "global_step=43776, episodic_return=166.0, surprise_reward=0.09630903601646423\n",
      "global_step=43856, episodic_return=113.0, surprise_reward=0.18353238701820374\n",
      "global_step=44016, episodic_return=30.0, surprise_reward=0.24989399313926697\n",
      "SPS: 139\n",
      "global_step=44088, episodic_return=171.0, surprise_reward=0.17585903406143188\n",
      "global_step=44160, episodic_return=100.0, surprise_reward=0.23238852620124817\n",
      "global_step=44224, episodic_return=61.0, surprise_reward=0.3314339518547058\n",
      "global_step=44296, episodic_return=180.0, surprise_reward=0.12908053398132324\n",
      "global_step=44424, episodic_return=115.0, surprise_reward=0.14447715878486633\n",
      "global_step=44664, episodic_return=63.0, surprise_reward=0.3256515860557556\n",
      "global_step=44736, episodic_return=163.0, surprise_reward=0.14667417109012604\n",
      "global_step=45032, episodic_return=101.0, surprise_reward=0.39763158559799194\n",
      "global_step=45040, episodic_return=47.0, surprise_reward=0.4017208218574524\n",
      "global_step=45056, episodic_return=121.0, surprise_reward=0.14737144112586975\n",
      "SPS: 131\n",
      "global_step=45248, episodic_return=103.0, surprise_reward=0.28750845789909363\n",
      "global_step=45312, episodic_return=182.0, surprise_reward=0.06673211604356766\n",
      "global_step=45496, episodic_return=55.0, surprise_reward=0.09754613041877747\n",
      "global_step=45544, episodic_return=37.0, surprise_reward=0.13454200327396393\n",
      "global_step=45600, episodic_return=71.0, surprise_reward=0.14279639720916748\n",
      "global_step=45656, episodic_return=77.0, surprise_reward=0.16039490699768066\n",
      "global_step=45840, episodic_return=228.0, surprise_reward=0.06165353208780289\n",
      "global_step=45992, episodic_return=212.0, surprise_reward=0.1432100236415863\n",
      "SPS: 134\n",
      "global_step=46240, episodic_return=80.0, surprise_reward=0.28822726011276245\n",
      "global_step=46400, episodic_return=93.0, surprise_reward=0.48470497131347656\n",
      "global_step=46408, episodic_return=137.0, surprise_reward=0.2528461515903473\n",
      "global_step=46592, episodic_return=24.0, surprise_reward=0.5054645538330078\n",
      "global_step=46672, episodic_return=242.0, surprise_reward=0.4549531638622284\n",
      "global_step=46776, episodic_return=67.0, surprise_reward=0.5620440244674683\n",
      "global_step=46792, episodic_return=100.0, surprise_reward=0.5809130668640137\n",
      "global_step=46808, episodic_return=121.0, surprise_reward=0.34958043694496155\n",
      "global_step=47096, episodic_return=40.0, surprise_reward=0.43353933095932007\n",
      "SPS: 127\n",
      "global_step=47208, episodic_return=77.0, surprise_reward=0.5299410820007324\n",
      "global_step=47240, episodic_return=218.0, surprise_reward=0.32803308963775635\n",
      "global_step=47344, episodic_return=225.0, surprise_reward=0.2607150673866272\n",
      "global_step=47432, episodic_return=128.0, surprise_reward=0.09779457747936249\n",
      "global_step=47504, episodic_return=87.0, surprise_reward=0.10760605335235596\n",
      "global_step=47592, episodic_return=100.0, surprise_reward=0.11964759230613708\n",
      "global_step=47600, episodic_return=63.0, surprise_reward=0.0993061289191246\n",
      "global_step=47896, episodic_return=58.0, surprise_reward=0.305012583732605\n",
      "global_step=47960, episodic_return=90.0, surprise_reward=0.3823797106742859\n",
      "global_step=47960, episodic_return=45.0, surprise_reward=0.3823797106742859\n",
      "global_step=48000, episodic_return=51.0, surprise_reward=0.42633068561553955\n",
      "SPS: 130\n",
      "global_step=48176, episodic_return=104.0, surprise_reward=0.385880708694458\n",
      "global_step=48296, episodic_return=136.0, surprise_reward=0.28931933641433716\n",
      "global_step=48360, episodic_return=50.0, surprise_reward=0.2915326952934265\n",
      "global_step=48640, episodic_return=246.0, surprise_reward=0.1750851571559906\n",
      "global_step=48672, episodic_return=146.0, surprise_reward=0.12793873250484467\n",
      "global_step=48880, episodic_return=110.0, surprise_reward=0.2463206797838211\n",
      "global_step=48960, episodic_return=98.0, surprise_reward=0.2593415081501007\n",
      "global_step=48984, episodic_return=86.0, surprise_reward=0.23395586013793945\n",
      "global_step=49064, episodic_return=146.0, surprise_reward=0.04836383834481239\n",
      "SPS: 124\n",
      "global_step=49344, episodic_return=35.0, surprise_reward=0.14017707109451294\n",
      "global_step=49672, episodic_return=164.0, surprise_reward=0.3818153738975525\n",
      "global_step=49752, episodic_return=135.0, surprise_reward=0.20469553768634796\n",
      "global_step=49800, episodic_return=102.0, surprise_reward=0.216720849275589\n",
      "global_step=49824, episodic_return=118.0, surprise_reward=0.24143050611019135\n",
      "global_step=49968, episodic_return=126.0, surprise_reward=0.2066860795021057\n",
      "global_step=50040, episodic_return=46.0, surprise_reward=0.25287261605262756\n",
      "SPS: 126\n",
      "global_step=50312, episodic_return=209.0, surprise_reward=0.17510628700256348\n",
      "global_step=50600, episodic_return=79.0, surprise_reward=0.34442514181137085\n",
      "global_step=50616, episodic_return=38.0, surprise_reward=0.33222508430480957\n",
      "global_step=50640, episodic_return=75.0, surprise_reward=0.32593390345573425\n",
      "global_step=50688, episodic_return=117.0, surprise_reward=0.34372586011886597\n",
      "global_step=50816, episodic_return=357.0, surprise_reward=0.23604841530323029\n",
      "global_step=50920, episodic_return=137.0, surprise_reward=0.2535894215106964\n",
      "global_step=51024, episodic_return=210.0, surprise_reward=0.1849769651889801\n",
      "SPS: 120\n",
      "global_step=51224, episodic_return=76.0, surprise_reward=0.24924859404563904\n",
      "global_step=51560, episodic_return=115.0, surprise_reward=0.290829062461853\n",
      "global_step=51832, episodic_return=154.0, surprise_reward=0.216389462351799\n",
      "global_step=51848, episodic_return=256.0, surprise_reward=0.18835285305976868\n",
      "global_step=51880, episodic_return=107.0, surprise_reward=0.17734989523887634\n",
      "global_step=51912, episodic_return=124.0, surprise_reward=0.17817935347557068\n",
      "global_step=51992, episodic_return=147.0, surprise_reward=0.09425956010818481\n",
      "global_step=52120, episodic_return=30.0, surprise_reward=0.1383899301290512\n",
      "SPS: 116\n",
      "global_step=52368, episodic_return=143.0, surprise_reward=0.19630974531173706\n",
      "global_step=52384, episodic_return=103.0, surprise_reward=0.1736346036195755\n",
      "global_step=52488, episodic_return=82.0, surprise_reward=0.22998756170272827\n",
      "global_step=52608, episodic_return=95.0, surprise_reward=0.20019078254699707\n",
      "global_step=52880, episodic_return=274.0, surprise_reward=0.2771245241165161\n",
      "global_step=52960, episodic_return=74.0, surprise_reward=0.3637204170227051\n",
      "global_step=52968, episodic_return=106.0, surprise_reward=0.3460216522216797\n",
      "global_step=53048, episodic_return=132.0, surprise_reward=0.16104231774806976\n",
      "global_step=53112, episodic_return=18.0, surprise_reward=0.19917677342891693\n",
      "global_step=53200, episodic_return=161.0, surprise_reward=0.07422631978988647\n",
      "SPS: 118\n",
      "global_step=53312, episodic_return=116.0, surprise_reward=0.054581768810749054\n",
      "global_step=53320, episodic_return=55.0, surprise_reward=0.04515792429447174\n",
      "global_step=53432, episodic_return=29.0, surprise_reward=0.06935623288154602\n",
      "global_step=53672, episodic_return=44.0, surprise_reward=0.1027701199054718\n",
      "global_step=54016, episodic_return=191.0, surprise_reward=0.20164836943149567\n",
      "global_step=54240, episodic_return=149.0, surprise_reward=0.3428618311882019\n",
      "SPS: 113\n",
      "global_step=54312, episodic_return=169.0, surprise_reward=0.14525172114372253\n",
      "global_step=54392, episodic_return=223.0, surprise_reward=0.11450320482254028\n",
      "global_step=54552, episodic_return=110.0, surprise_reward=0.07552217692136765\n",
      "global_step=54616, episodic_return=163.0, surprise_reward=0.0907420739531517\n",
      "global_step=54800, episodic_return=171.0, surprise_reward=0.12387508153915405\n",
      "global_step=55040, episodic_return=53.0, surprise_reward=0.23008611798286438\n",
      "global_step=55248, episodic_return=126.0, surprise_reward=0.28888070583343506\n",
      "SPS: 115\n",
      "global_step=55344, episodic_return=68.0, surprise_reward=0.3184754252433777\n",
      "global_step=55352, episodic_return=280.0, surprise_reward=0.12584662437438965\n",
      "global_step=55424, episodic_return=176.0, surprise_reward=0.09012264013290405\n",
      "global_step=55512, episodic_return=150.0, surprise_reward=0.11117425560951233\n",
      "global_step=55536, episodic_return=123.0, surprise_reward=0.09133625775575638\n",
      "global_step=55552, episodic_return=64.0, surprise_reward=0.046602826565504074\n",
      "global_step=55688, episodic_return=33.0, surprise_reward=0.05547875538468361\n",
      "global_step=55976, episodic_return=58.0, surprise_reward=0.18198829889297485\n",
      "global_step=56024, episodic_return=97.0, surprise_reward=0.22385837137699127\n",
      "global_step=56216, episodic_return=83.0, surprise_reward=0.42894256114959717\n",
      "global_step=56232, episodic_return=230.0, surprise_reward=0.2798713147640228\n",
      "global_step=56304, episodic_return=41.0, surprise_reward=0.30706262588500977\n",
      "SPS: 110\n",
      "global_step=56328, episodic_return=99.0, surprise_reward=0.08952600508928299\n",
      "global_step=56520, episodic_return=36.0, surprise_reward=0.1447739601135254\n",
      "global_step=56712, episodic_return=62.0, surprise_reward=0.2881665825843811\n",
      "global_step=56736, episodic_return=174.0, surprise_reward=0.30084702372550964\n",
      "global_step=56832, episodic_return=143.0, surprise_reward=0.19242706894874573\n",
      "global_step=57168, episodic_return=227.0, surprise_reward=0.3863633871078491\n",
      "global_step=57216, episodic_return=149.0, surprise_reward=0.3605993390083313\n",
      "global_step=57232, episodic_return=113.0, surprise_reward=0.20379728078842163\n",
      "global_step=57304, episodic_return=98.0, surprise_reward=0.16937874257564545\n",
      "SPS: 112\n",
      "global_step=57440, episodic_return=88.0, surprise_reward=0.1918913871049881\n",
      "global_step=57872, episodic_return=130.0, surprise_reward=0.2540801763534546\n",
      "global_step=57928, episodic_return=89.0, surprise_reward=0.30530813336372375\n",
      "global_step=57952, episodic_return=155.0, surprise_reward=0.22511056065559387\n",
      "global_step=58168, episodic_return=233.0, surprise_reward=0.32367923855781555\n",
      "global_step=58176, episodic_return=109.0, surprise_reward=0.11662928014993668\n",
      "global_step=58208, episodic_return=32.0, surprise_reward=0.14404991269111633\n",
      "global_step=58264, episodic_return=42.0, surprise_reward=0.1666126400232315\n",
      "SPS: 109\n",
      "global_step=58432, episodic_return=150.0, surprise_reward=0.16731731593608856\n",
      "global_step=58608, episodic_return=92.0, surprise_reward=0.22842571139335632\n",
      "global_step=58920, episodic_return=94.0, surprise_reward=0.37233832478523254\n",
      "global_step=58952, episodic_return=223.0, surprise_reward=0.2526647448539734\n",
      "global_step=58960, episodic_return=190.0, surprise_reward=0.1670612096786499\n",
      "global_step=59256, episodic_return=103.0, surprise_reward=0.17682400345802307\n",
      "global_step=59368, episodic_return=95.0, surprise_reward=0.16912725567817688\n",
      "SPS: 110\n",
      "global_step=59472, episodic_return=162.0, surprise_reward=0.1343068778514862\n",
      "global_step=59720, episodic_return=189.0, surprise_reward=0.1557275950908661\n",
      "global_step=59824, episodic_return=113.0, surprise_reward=0.11220374703407288\n",
      "global_step=59832, episodic_return=110.0, surprise_reward=0.10037456452846527\n",
      "global_step=59936, episodic_return=58.0, surprise_reward=0.11270023137331009\n",
      "global_step=59992, episodic_return=78.0, surprise_reward=0.10965932905673981\n",
      "SPS: 107\n",
      "global_step=60488, episodic_return=83.0, surprise_reward=0.22747519612312317\n",
      "global_step=60512, episodic_return=281.0, surprise_reward=0.17964646220207214\n",
      "global_step=60616, episodic_return=78.0, surprise_reward=0.21403661370277405\n",
      "global_step=60664, episodic_return=104.0, surprise_reward=0.13992449641227722\n",
      "global_step=61048, episodic_return=261.0, surprise_reward=0.10570371150970459\n",
      "global_step=61072, episodic_return=227.0, surprise_reward=0.0827469527721405\n",
      "global_step=61432, episodic_return=214.0, surprise_reward=0.18270348012447357\n",
      "SPS: 109\n",
      "global_step=61616, episodic_return=125.0, surprise_reward=0.11722905933856964\n",
      "global_step=61776, episodic_return=161.0, surprise_reward=0.16029180586338043\n",
      "global_step=61864, episodic_return=241.0, surprise_reward=0.14272338151931763\n",
      "global_step=62168, episodic_return=137.0, surprise_reward=0.24634025990962982\n",
      "global_step=62184, episodic_return=51.0, surprise_reward=0.23516881465911865\n",
      "global_step=62360, episodic_return=231.0, surprise_reward=0.2661949396133423\n",
      "SPS: 105\n",
      "global_step=62520, episodic_return=184.0, surprise_reward=0.36223816871643066\n",
      "global_step=62576, episodic_return=89.0, surprise_reward=0.19122418761253357\n",
      "global_step=62576, episodic_return=143.0, surprise_reward=0.19122418761253357\n",
      "global_step=62624, episodic_return=245.0, surprise_reward=0.054901085793972015\n",
      "global_step=62792, episodic_return=76.0, surprise_reward=0.0752820298075676\n",
      "global_step=62864, episodic_return=87.0, surprise_reward=0.06899592280387878\n",
      "global_step=62888, episodic_return=159.0, surprise_reward=0.0454062819480896\n",
      "global_step=62904, episodic_return=41.0, surprise_reward=0.03757847845554352\n",
      "SPS: 106\n",
      "global_step=63616, episodic_return=124.0, surprise_reward=0.19686618447303772\n",
      "global_step=63872, episodic_return=189.0, surprise_reward=0.25106048583984375\n",
      "global_step=63888, episodic_return=128.0, surprise_reward=0.09442485123872757\n",
      "global_step=64032, episodic_return=141.0, surprise_reward=0.12638743221759796\n",
      "SPS: 103\n",
      "global_step=64560, episodic_return=221.0, surprise_reward=0.33751624822616577\n",
      "global_step=64680, episodic_return=224.0, surprise_reward=0.30426421761512756\n",
      "global_step=64800, episodic_return=114.0, surprise_reward=0.30683210492134094\n",
      "global_step=64824, episodic_return=281.0, surprise_reward=0.26995453238487244\n",
      "global_step=64968, episodic_return=306.0, surprise_reward=0.273598849773407\n",
      "global_step=65064, episodic_return=181.0, surprise_reward=0.12723316252231598\n",
      "global_step=65256, episodic_return=54.0, surprise_reward=0.32418861985206604\n",
      "global_step=65352, episodic_return=99.0, surprise_reward=0.25846976041793823\n",
      "global_step=65376, episodic_return=15.0, surprise_reward=0.2899436950683594\n",
      "global_step=65448, episodic_return=177.0, surprise_reward=0.16842696070671082\n",
      "global_step=65536, episodic_return=23.0, surprise_reward=0.2136498987674713\n",
      "SPS: 104\n",
      "global_step=65720, episodic_return=82.0, surprise_reward=0.30399033427238464\n",
      "global_step=65776, episodic_return=137.0, surprise_reward=0.09508511424064636\n",
      "global_step=65896, episodic_return=22.0, surprise_reward=0.12694710493087769\n",
      "global_step=65904, episodic_return=254.0, surprise_reward=0.12128988653421402\n",
      "global_step=66032, episodic_return=82.0, surprise_reward=0.1910824477672577\n",
      "global_step=66200, episodic_return=37.0, surprise_reward=0.25726425647735596\n",
      "global_step=66328, episodic_return=110.0, surprise_reward=0.1709146499633789\n",
      "SPS: 101\n",
      "global_step=66624, episodic_return=228.0, surprise_reward=0.23739393055438995\n",
      "global_step=66800, episodic_return=229.0, surprise_reward=0.22552916407585144\n",
      "global_step=66872, episodic_return=105.0, surprise_reward=0.1393173187971115\n",
      "global_step=67024, episodic_return=103.0, surprise_reward=0.15294606983661652\n",
      "global_step=67056, episodic_return=91.0, surprise_reward=0.143807053565979\n",
      "global_step=67080, episodic_return=193.0, surprise_reward=0.1121167466044426\n",
      "global_step=67112, episodic_return=152.0, surprise_reward=0.0845583975315094\n",
      "global_step=67120, episodic_return=31.0, surprise_reward=0.08096696436405182\n",
      "SPS: 102\n",
      "global_step=67592, episodic_return=71.0, surprise_reward=0.18338963389396667\n",
      "global_step=67688, episodic_return=71.0, surprise_reward=0.11221972107887268\n",
      "global_step=67848, episodic_return=96.0, surprise_reward=0.2091558277606964\n",
      "global_step=67880, episodic_return=24.0, surprise_reward=0.22816213965415955\n",
      "global_step=67888, episodic_return=136.0, surprise_reward=0.22290509939193726\n",
      "global_step=67896, episodic_return=159.0, surprise_reward=0.18409132957458496\n",
      "global_step=67968, episodic_return=114.0, surprise_reward=0.16199707984924316\n",
      "global_step=68296, episodic_return=315.0, surprise_reward=0.04555884003639221\n",
      "SPS: 99\n",
      "global_step=68648, episodic_return=96.0, surprise_reward=0.14411309361457825\n",
      "global_step=68800, episodic_return=114.0, surprise_reward=0.20152191817760468\n",
      "global_step=68944, episodic_return=131.0, surprise_reward=0.09358127415180206\n",
      "global_step=69304, episodic_return=167.0, surprise_reward=0.24388809502124786\n",
      "global_step=69512, episodic_return=240.0, surprise_reward=0.30316001176834106\n",
      "SPS: 101\n",
      "global_step=69760, episodic_return=239.0, surprise_reward=0.5720599293708801\n",
      "global_step=69776, episodic_return=104.0, surprise_reward=0.21546988189220428\n",
      "global_step=69776, episodic_return=333.0, surprise_reward=0.21546988189220428\n",
      "global_step=69936, episodic_return=161.0, surprise_reward=0.17447805404663086\n",
      "global_step=70024, episodic_return=64.0, surprise_reward=0.15243172645568848\n",
      "global_step=70080, episodic_return=223.0, surprise_reward=0.11420069634914398\n",
      "global_step=70184, episodic_return=173.0, surprise_reward=0.09526760131120682\n",
      "global_step=70296, episodic_return=34.0, surprise_reward=0.07617561519145966\n",
      "SPS: 98\n",
      "global_step=70704, episodic_return=51.0, surprise_reward=0.19933253526687622\n",
      "global_step=70768, episodic_return=126.0, surprise_reward=0.21182534098625183\n",
      "global_step=70872, episodic_return=137.0, surprise_reward=0.2031029313802719\n",
      "global_step=71040, episodic_return=138.0, surprise_reward=0.29695653915405273\n",
      "global_step=71160, episodic_return=173.0, surprise_reward=0.14384478330612183\n",
      "global_step=71184, episodic_return=52.0, surprise_reward=0.15390297770500183\n",
      "global_step=71336, episodic_return=254.0, surprise_reward=0.13961121439933777\n",
      "global_step=71408, episodic_return=28.0, surprise_reward=0.14551737904548645\n",
      "global_step=71552, episodic_return=27.0, surprise_reward=0.1457621455192566\n",
      "global_step=71576, episodic_return=187.0, surprise_reward=0.08729441463947296\n",
      "global_step=71576, episodic_return=109.0, surprise_reward=0.08729441463947296\n",
      "SPS: 99\n",
      "global_step=71920, episodic_return=110.0, surprise_reward=0.13251928985118866\n",
      "global_step=72080, episodic_return=63.0, surprise_reward=0.21547290682792664\n",
      "global_step=72144, episodic_return=74.0, surprise_reward=0.22064998745918274\n",
      "global_step=72200, episodic_return=252.0, surprise_reward=0.07594014704227448\n",
      "global_step=72384, episodic_return=58.0, surprise_reward=0.14434519410133362\n",
      "global_step=72448, episodic_return=161.0, surprise_reward=0.10361076891422272\n",
      "SPS: 97\n",
      "global_step=72856, episodic_return=160.0, surprise_reward=0.12569186091423035\n",
      "global_step=72928, episodic_return=257.0, surprise_reward=0.09880514442920685\n",
      "global_step=72928, episodic_return=68.0, surprise_reward=0.09880514442920685\n",
      "global_step=73208, episodic_return=225.0, surprise_reward=0.1634763777256012\n",
      "global_step=73472, episodic_return=68.0, surprise_reward=0.21591508388519287\n",
      "global_step=73600, episodic_return=84.0, surprise_reward=0.2924128472805023\n",
      "global_step=73672, episodic_return=199.0, surprise_reward=0.10094227641820908\n",
      "SPS: 98\n",
      "global_step=73800, episodic_return=200.0, surprise_reward=0.10922285914421082\n",
      "global_step=73904, episodic_return=54.0, surprise_reward=0.12342966347932816\n",
      "global_step=73984, episodic_return=97.0, surprise_reward=0.08919187635183334\n",
      "global_step=74000, episodic_return=25.0, surprise_reward=0.08009320497512817\n",
      "global_step=74072, episodic_return=241.0, surprise_reward=0.1027836874127388\n",
      "global_step=74136, episodic_return=67.0, surprise_reward=0.08714328706264496\n",
      "global_step=74472, episodic_return=100.0, surprise_reward=0.11438864469528198\n",
      "global_step=74528, episodic_return=57.0, surprise_reward=0.13477255403995514\n",
      "SPS: 95\n",
      "global_step=74768, episodic_return=98.0, surprise_reward=0.17627182602882385\n",
      "global_step=74800, episodic_return=243.0, surprise_reward=0.1300559937953949\n",
      "global_step=74880, episodic_return=110.0, surprise_reward=0.09163577854633331\n",
      "global_step=74952, episodic_return=313.0, surprise_reward=0.14417356252670288\n",
      "global_step=74984, episodic_return=64.0, surprise_reward=0.09464818984270096\n",
      "global_step=75400, episodic_return=52.0, surprise_reward=0.19060781598091125\n",
      "global_step=75512, episodic_return=172.0, surprise_reward=0.14714109897613525\n",
      "global_step=75560, episodic_return=99.0, surprise_reward=0.1620943546295166\n",
      "global_step=75720, episodic_return=227.0, surprise_reward=0.14611363410949707\n",
      "SPS: 97\n",
      "global_step=75832, episodic_return=119.0, surprise_reward=0.1615876704454422\n",
      "global_step=75904, episodic_return=172.0, surprise_reward=0.08735593408346176\n",
      "global_step=76144, episodic_return=149.0, surprise_reward=0.09594324976205826\n",
      "global_step=76248, episodic_return=106.0, surprise_reward=0.09955327957868576\n",
      "global_step=76256, episodic_return=67.0, surprise_reward=0.07372112572193146\n",
      "global_step=76280, episodic_return=96.0, surprise_reward=0.07671548426151276\n",
      "global_step=76400, episodic_return=32.0, surprise_reward=0.10846060514450073\n",
      "global_step=76480, episodic_return=29.0, surprise_reward=0.1449965238571167\n",
      "global_step=76512, episodic_return=119.0, surprise_reward=0.07166142016649246\n",
      "SPS: 94\n",
      "global_step=77120, episodic_return=290.0, surprise_reward=0.214378222823143\n",
      "global_step=77520, episodic_return=155.0, surprise_reward=0.37149450182914734\n",
      "global_step=77568, episodic_return=164.0, surprise_reward=0.3018210232257843\n",
      "global_step=77688, episodic_return=232.0, surprise_reward=0.22453081607818604\n",
      "global_step=77696, episodic_return=148.0, surprise_reward=0.11521213501691818\n",
      "SPS: 95\n",
      "global_step=78016, episodic_return=192.0, surprise_reward=0.11223148554563522\n",
      "global_step=78184, episodic_return=21.0, surprise_reward=0.13530486822128296\n",
      "global_step=78496, episodic_return=122.0, surprise_reward=0.3226436376571655\n",
      "global_step=78544, episodic_return=178.0, surprise_reward=0.3452832102775574\n",
      "global_step=78608, episodic_return=276.0, surprise_reward=0.22264543175697327\n",
      "global_step=78608, episodic_return=115.0, surprise_reward=0.22264543175697327\n",
      "global_step=78640, episodic_return=342.0, surprise_reward=0.10489839315414429\n",
      "global_step=78688, episodic_return=63.0, surprise_reward=0.1199195608496666\n",
      "SPS: 93\n",
      "global_step=78944, episodic_return=172.0, surprise_reward=0.04863910377025604\n",
      "global_step=78952, episodic_return=157.0, surprise_reward=0.0422486737370491\n",
      "global_step=78984, episodic_return=43.0, surprise_reward=0.04454852640628815\n",
      "global_step=79296, episodic_return=43.0, surprise_reward=0.12504896521568298\n",
      "global_step=79688, episodic_return=93.0, surprise_reward=0.30775031447410583\n",
      "global_step=79712, episodic_return=138.0, surprise_reward=0.1702534556388855\n",
      "global_step=79744, episodic_return=150.0, surprise_reward=0.14596405625343323\n",
      "global_step=79776, episodic_return=136.0, surprise_reward=0.0673782229423523\n",
      "global_step=79832, episodic_return=106.0, surprise_reward=0.06828561425209045\n",
      "SPS: 94\n",
      "global_step=80144, episodic_return=46.0, surprise_reward=0.1645728349685669\n",
      "global_step=80192, episodic_return=198.0, surprise_reward=0.047651030123233795\n",
      "global_step=80288, episodic_return=75.0, surprise_reward=0.05497105419635773\n",
      "global_step=80504, episodic_return=95.0, surprise_reward=0.12007957696914673\n",
      "global_step=80552, episodic_return=257.0, surprise_reward=0.10506737232208252\n",
      "global_step=80640, episodic_return=62.0, surprise_reward=0.116030253469944\n",
      "global_step=80720, episodic_return=126.0, surprise_reward=0.08695824444293976\n",
      "SPS: 92\n",
      "global_step=80936, episodic_return=81.0, surprise_reward=0.09034889191389084\n",
      "global_step=81216, episodic_return=128.0, surprise_reward=0.10051421076059341\n",
      "global_step=81216, episodic_return=240.0, surprise_reward=0.10051421076059341\n",
      "global_step=81384, episodic_return=56.0, surprise_reward=0.1280004233121872\n",
      "global_step=81576, episodic_return=24.0, surprise_reward=0.2605808973312378\n",
      "global_step=81648, episodic_return=137.0, surprise_reward=0.2836384177207947\n",
      "global_step=81760, episodic_return=157.0, surprise_reward=0.07237069308757782\n",
      "global_step=81760, episodic_return=130.0, surprise_reward=0.07237069308757782\n",
      "global_step=81920, episodic_return=34.0, surprise_reward=0.09318653494119644\n",
      "SPS: 93\n",
      "global_step=82240, episodic_return=301.0, surprise_reward=0.17470501363277435\n",
      "global_step=82264, episodic_return=63.0, surprise_reward=0.15979747474193573\n",
      "global_step=82488, episodic_return=231.0, surprise_reward=0.2610231637954712\n",
      "global_step=82736, episodic_return=122.0, surprise_reward=0.11768677830696106\n",
      "global_step=82792, episodic_return=197.0, surprise_reward=0.1307872235774994\n",
      "SPS: 91\n",
      "global_step=83024, episodic_return=67.0, surprise_reward=0.18723571300506592\n",
      "global_step=83184, episodic_return=115.0, surprise_reward=0.26814723014831543\n",
      "global_step=83248, episodic_return=57.0, surprise_reward=0.2767583131790161\n",
      "global_step=83376, episodic_return=225.0, surprise_reward=0.29632335901260376\n",
      "global_step=83424, episodic_return=276.0, surprise_reward=0.14647573232650757\n",
      "global_step=83752, episodic_return=47.0, surprise_reward=0.4953087866306305\n",
      "global_step=83768, episodic_return=191.0, surprise_reward=0.2502513825893402\n",
      "global_step=83816, episodic_return=237.0, surprise_reward=0.15259188413619995\n",
      "global_step=83832, episodic_return=73.0, surprise_reward=0.15166205167770386\n",
      "global_step=83904, episodic_return=17.0, surprise_reward=0.2089858055114746\n",
      "global_step=83936, episodic_return=94.0, surprise_reward=0.15192939341068268\n",
      "SPS: 92\n",
      "global_step=84296, episodic_return=159.0, surprise_reward=0.21059654653072357\n",
      "global_step=84360, episodic_return=117.0, surprise_reward=0.10693672299385071\n",
      "global_step=84416, episodic_return=210.0, surprise_reward=0.10279376059770584\n",
      "global_step=84544, episodic_return=80.0, surprise_reward=0.16951633989810944\n",
      "global_step=84552, episodic_return=90.0, surprise_reward=0.12656232714653015\n",
      "global_step=84688, episodic_return=49.0, surprise_reward=0.16360685229301453\n",
      "global_step=84944, episodic_return=149.0, surprise_reward=0.17418719828128815\n",
      "SPS: 90\n",
      "global_step=85024, episodic_return=136.0, surprise_reward=0.05984089523553848\n",
      "global_step=85136, episodic_return=73.0, surprise_reward=0.06140715628862381\n",
      "global_step=85560, episodic_return=150.0, surprise_reward=0.1272309422492981\n",
      "global_step=85568, episodic_return=144.0, surprise_reward=0.09829224646091461\n",
      "global_step=85728, episodic_return=239.0, surprise_reward=0.1629658192396164\n",
      "global_step=85960, episodic_return=177.0, surprise_reward=0.21635977923870087\n",
      "SPS: 91\n",
      "global_step=86120, episodic_return=137.0, surprise_reward=0.1201511099934578\n",
      "global_step=86392, episodic_return=181.0, surprise_reward=0.09343785047531128\n",
      "global_step=86456, episodic_return=91.0, surprise_reward=0.11169230192899704\n",
      "global_step=86592, episodic_return=129.0, surprise_reward=0.07595908641815186\n",
      "global_step=86688, episodic_return=71.0, surprise_reward=0.09991578757762909\n",
      "global_step=86712, episodic_return=253.0, surprise_reward=0.08170834183692932\n",
      "SPS: 89\n",
      "global_step=87096, episodic_return=88.0, surprise_reward=0.11005033552646637\n",
      "global_step=87392, episodic_return=228.0, surprise_reward=0.29827526211738586\n",
      "global_step=87528, episodic_return=105.0, surprise_reward=0.21111652255058289\n",
      "global_step=87600, episodic_return=63.0, surprise_reward=0.2307937890291214\n",
      "global_step=87768, episodic_return=132.0, surprise_reward=0.18436942994594574\n",
      "global_step=87808, episodic_return=152.0, surprise_reward=0.12171036750078201\n",
      "SPS: 89\n",
      "global_step=88080, episodic_return=39.0, surprise_reward=0.1645166575908661\n",
      "global_step=88232, episodic_return=387.0, surprise_reward=0.15656235814094543\n",
      "global_step=88424, episodic_return=103.0, surprise_reward=0.1186220571398735\n",
      "global_step=88840, episodic_return=360.0, surprise_reward=0.2542186975479126\n",
      "global_step=88888, episodic_return=304.0, surprise_reward=0.2014649659395218\n",
      "global_step=88984, episodic_return=199.0, surprise_reward=0.08386197686195374\n",
      "SPS: 88\n",
      "global_step=89304, episodic_return=110.0, surprise_reward=0.13082492351531982\n",
      "global_step=89360, episodic_return=160.0, surprise_reward=0.09328827261924744\n",
      "global_step=89712, episodic_return=109.0, surprise_reward=0.2198995053768158\n",
      "global_step=89776, episodic_return=52.0, surprise_reward=0.30371278524398804\n",
      "global_step=89800, episodic_return=249.0, surprise_reward=0.15753403306007385\n",
      "global_step=89872, episodic_return=20.0, surprise_reward=0.2050248086452484\n",
      "global_step=89976, episodic_return=306.0, surprise_reward=0.09944243729114532\n",
      "global_step=89976, episodic_return=84.0, surprise_reward=0.09944243729114532\n",
      "SPS: 89\n",
      "global_step=90288, episodic_return=163.0, surprise_reward=0.13066993653774261\n",
      "global_step=90424, episodic_return=192.0, surprise_reward=0.16496649384498596\n",
      "global_step=90480, episodic_return=63.0, surprise_reward=0.19186173379421234\n",
      "global_step=90728, episodic_return=119.0, surprise_reward=0.2227567583322525\n",
      "global_step=90800, episodic_return=125.0, surprise_reward=0.31236928701400757\n",
      "global_step=90864, episodic_return=111.0, surprise_reward=0.21985678374767303\n",
      "global_step=90880, episodic_return=57.0, surprise_reward=0.18461458384990692\n",
      "global_step=90992, episodic_return=140.0, surprise_reward=0.12291708588600159\n",
      "SPS: 87\n",
      "global_step=91152, episodic_return=108.0, surprise_reward=0.09259733557701111\n",
      "global_step=91464, episodic_return=404.0, surprise_reward=0.11919430643320084\n",
      "global_step=91464, episodic_return=123.0, surprise_reward=0.11919430643320084\n",
      "global_step=91688, episodic_return=28.0, surprise_reward=0.22130107879638672\n",
      "global_step=91728, episodic_return=92.0, surprise_reward=0.19143806397914886\n",
      "global_step=91840, episodic_return=86.0, surprise_reward=0.2702796757221222\n",
      "global_step=91872, episodic_return=124.0, surprise_reward=0.09413322806358337\n",
      "SPS: 87\n",
      "global_step=92296, episodic_return=179.0, surprise_reward=0.0799146294593811\n",
      "global_step=92792, episodic_return=258.0, surprise_reward=0.4354749917984009\n",
      "global_step=92808, episodic_return=64.0, surprise_reward=0.43763190507888794\n",
      "global_step=92824, episodic_return=142.0, surprise_reward=0.2534259855747223\n",
      "global_step=92888, episodic_return=178.0, surprise_reward=0.1733788251876831\n",
      "global_step=92920, episodic_return=131.0, surprise_reward=0.15197908878326416\n",
      "global_step=92976, episodic_return=156.0, surprise_reward=0.08372566103935242\n",
      "global_step=93072, episodic_return=31.0, surprise_reward=0.12289373576641083\n",
      "SPS: 85\n",
      "global_step=93192, episodic_return=299.0, surprise_reward=0.1398647129535675\n",
      "global_step=93328, episodic_return=65.0, surprise_reward=0.20610381662845612\n",
      "global_step=93448, episodic_return=201.0, surprise_reward=0.0740547627210617\n",
      "global_step=93776, episodic_return=107.0, surprise_reward=0.290470689535141\n",
      "global_step=93880, episodic_return=101.0, surprise_reward=0.274828165769577\n",
      "global_step=94000, episodic_return=128.0, surprise_reward=0.07718722522258759\n",
      "global_step=94000, episodic_return=151.0, surprise_reward=0.07718722522258759\n",
      "global_step=94088, episodic_return=150.0, surprise_reward=0.07588505744934082\n",
      "global_step=94144, episodic_return=119.0, surprise_reward=0.05646872520446777\n",
      "SPS: 86\n",
      "global_step=94632, episodic_return=163.0, surprise_reward=0.18176575005054474\n",
      "global_step=94832, episodic_return=86.0, surprise_reward=0.31511545181274414\n",
      "global_step=94848, episodic_return=106.0, surprise_reward=0.15766626596450806\n",
      "global_step=94912, episodic_return=103.0, surprise_reward=0.055637821555137634\n",
      "global_step=95032, episodic_return=129.0, surprise_reward=0.08455656468868256\n",
      "global_step=95168, episodic_return=215.0, surprise_reward=0.1092543974518776\n",
      "SPS: 84\n",
      "global_step=95488, episodic_return=57.0, surprise_reward=0.23748934268951416\n",
      "global_step=95616, episodic_return=123.0, surprise_reward=0.17785553634166718\n",
      "global_step=95736, episodic_return=232.0, surprise_reward=0.2811812162399292\n",
      "global_step=95776, episodic_return=250.0, surprise_reward=0.07193224132061005\n",
      "global_step=96080, episodic_return=154.0, surprise_reward=0.21208694577217102\n",
      "global_step=96104, episodic_return=149.0, surprise_reward=0.1574389934539795\n",
      "global_step=96120, episodic_return=43.0, surprise_reward=0.1452646553516388\n",
      "global_step=96248, episodic_return=135.0, surprise_reward=0.12533360719680786\n",
      "SPS: 85\n",
      "global_step=96464, episodic_return=43.0, surprise_reward=0.23036646842956543\n",
      "global_step=96688, episodic_return=28.0, surprise_reward=0.3715571165084839\n",
      "global_step=96728, episodic_return=124.0, surprise_reward=0.27887654304504395\n",
      "global_step=96784, episodic_return=162.0, surprise_reward=0.11557844281196594\n",
      "global_step=96960, episodic_return=266.0, surprise_reward=0.2245866358280182\n",
      "global_step=97200, episodic_return=64.0, surprise_reward=0.3661656379699707\n",
      "global_step=97240, episodic_return=142.0, surprise_reward=0.2456970512866974\n",
      "SPS: 83\n",
      "global_step=97424, episodic_return=58.0, surprise_reward=0.24459099769592285\n",
      "global_step=97568, episodic_return=186.0, surprise_reward=0.15083491802215576\n",
      "global_step=97568, episodic_return=165.0, surprise_reward=0.15083491802215576\n",
      "global_step=97592, episodic_return=21.0, surprise_reward=0.1703544557094574\n",
      "global_step=97600, episodic_return=248.0, surprise_reward=0.15641596913337708\n",
      "global_step=97672, episodic_return=59.0, surprise_reward=0.1363978087902069\n",
      "global_step=97800, episodic_return=26.0, surprise_reward=0.18157178163528442\n",
      "global_step=98136, episodic_return=42.0, surprise_reward=0.1842827945947647\n",
      "global_step=98160, episodic_return=172.0, surprise_reward=0.1786821335554123\n",
      "SPS: 84\n",
      "global_step=98360, episodic_return=140.0, surprise_reward=0.22983823716640472\n",
      "global_step=98392, episodic_return=208.0, surprise_reward=0.1175130233168602\n",
      "global_step=98472, episodic_return=42.0, surprise_reward=0.11963403224945068\n",
      "global_step=98496, episodic_return=103.0, surprise_reward=0.11640743166208267\n",
      "global_step=98664, episodic_return=133.0, surprise_reward=0.12579408288002014\n",
      "global_step=98752, episodic_return=45.0, surprise_reward=0.16279788315296173\n",
      "global_step=98960, episodic_return=174.0, surprise_reward=0.24256394803524017\n",
      "global_step=99232, episodic_return=109.0, surprise_reward=0.20838767290115356\n",
      "global_step=99320, episodic_return=219.0, surprise_reward=0.08216093480587006\n",
      "SPS: 82\n"
     ]
    }
   ],
   "source": [
    "batch_size = int(params[\"num_envs\"] * params[\"num_steps\"])                      # 4 * 128\n",
    "minibatch_size = int(batch_size // params[\"num_minibatches\"])\n",
    "num_iterations = params[\"total_timesteps\"] // batch_size                        # 20000000/(4*128) -> num iterations\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "next_obs = torch.Tensor(envs.reset()[0]).to(device)\n",
    "next_done = torch.zeros(params[\"num_envs\"]).to(device)\n",
    "\n",
    "results_RND = {\"global_step\":[],\n",
    "                \"return_value\":[],\n",
    "                \"intrinsic_reward\":[]}\n",
    "\n",
    "tracking_global_step = 0\n",
    "\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    if params[\"anneal_lr\"]:\n",
    "        updated_lr = (1.0 - (iteration - 1.0) / num_iterations) * params[\"learning_rate\"]\n",
    "        optimizer.param_groups[0][\"lr\"] = updated_lr\n",
    "\n",
    "    # n-step rollouts\n",
    "    for step in range(0, params[\"num_steps\"]):\n",
    "        global_step += 1 * params[\"num_envs\"]\n",
    "        obs[step] = next_obs\n",
    "        dones[step] = next_done\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value_ext, value_int = Agent.get_action_and_value(next_obs)\n",
    "        \n",
    "        ext_values[step], int_values[step] = (\n",
    "                value_ext.flatten(),\n",
    "                value_int.flatten(),\n",
    "            )\n",
    "        actions[step] = action\n",
    "        logprobs[step] = logprob.flatten()\n",
    "\n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "        done = np.logical_or(terminated, truncated)\n",
    "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
    "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
    "\n",
    "        # Normalize obs for rnd\n",
    "        rnd_next_obs = next_obs\n",
    "        \n",
    "        # Get the target F(O) and predict \\hat(F)(O) value from rnd model\n",
    "        target_next_feature, predict_next_feature = rnd_model.target(rnd_next_obs), rnd_model.predictor(rnd_next_obs)\n",
    "\n",
    "        # Calculate the surprise reward\n",
    "        surprise_rewards[step] = ((target_next_feature - predict_next_feature).pow(2).sum(1) / 2).data\n",
    "\n",
    "        if \"final_info\" in info:\n",
    "            for info in info[\"final_info\"]:\n",
    "                if info and \"episode\" in info:\n",
    "                    print(\n",
    "                    f\"global_step={global_step}, episodic_return={info['episode']['r'][0]}, surprise_reward={np.mean(surprise_rewards[step].cpu().numpy())}\"\n",
    "                        )\n",
    "                    \n",
    "        if global_step - tracking_global_step > 2000:\n",
    "                return_eval = evaluate(params[\"env_id\"], Agent, use_int_rews=True)\n",
    "                results_RND[\"global_step\"].append(global_step)\n",
    "                results_RND[\"return_value\"].append(return_eval)\n",
    "                tracking_global_step = global_step\n",
    "\n",
    "\n",
    "    # Calculate the discounted reward \n",
    "    surprise_reward_per_env = np.array(\n",
    "        [discounted_reward.update(reward_per_step) for reward_per_step in surprise_rewards.cpu().data.numpy().T]\n",
    "    )\n",
    "\n",
    "    mean, std, count = (\n",
    "        np.mean(surprise_reward_per_env),\n",
    "        np.std(surprise_reward_per_env),\n",
    "        len(surprise_reward_per_env),\n",
    "    )\n",
    "    \n",
    "    rew_runnning_mean_std.update_from_moments(mean, std**2, count)\n",
    "\n",
    "    # Normalize the curiousity_rewards based on the running_mean_std\n",
    "    surprise_rewards /= np.sqrt(rew_runnning_mean_std.var)\n",
    "\n",
    "    # Calculate value if not done\n",
    "    with torch.no_grad():\n",
    "        next_value_ext, next_value_int = Agent.get_value(next_obs)\n",
    "        next_value_ext, next_value_int = next_value_ext.reshape(1, -1), next_value_int.reshape(1, -1)   # -> get next state values external & internal\n",
    "        ext_advantages = torch.zeros_like(rewards, device=device)\n",
    "        int_advantages = torch.zeros_like(surprise_rewards, device=device)\n",
    "        ext_lastgaelam = 0\n",
    "        int_lastgaelam = 0\n",
    "        for t in reversed(range(params[\"num_steps\"])):\n",
    "            if t == params[\"num_steps\"] - 1:\n",
    "                ext_nextnonterminal = 1.0 - next_done\n",
    "                int_nextnonterminal = 1.0\n",
    "                ext_nextvalues = next_value_ext\n",
    "                int_nextvalues = next_value_int\n",
    "            else:\n",
    "                ext_nextnonterminal = 1.0 - dones[t + 1]\n",
    "                int_nextnonterminal = 1.0\n",
    "                ext_nextvalues = ext_values[t + 1]\n",
    "                int_nextvalues = int_values[t + 1]\n",
    "            ext_delta = rewards[t] + params[\"gamma\"] * ext_nextvalues * ext_nextnonterminal - ext_values[t]\n",
    "            int_delta = surprise_rewards[t] + params[\"int_gamma\"] * int_nextvalues * int_nextnonterminal - int_values[t]\n",
    "            ext_advantages[t] = ext_lastgaelam = (\n",
    "                ext_delta + params[\"gamma\"] * params[\"gae_lambda\"] * ext_nextnonterminal * ext_lastgaelam\n",
    "            )\n",
    "            int_advantages[t] = int_lastgaelam = (\n",
    "                int_delta + params[\"int_gamma\"] * params[\"gae_lambda\"] * int_nextnonterminal * int_lastgaelam\n",
    "            )\n",
    "        ext_returns = ext_advantages + ext_values\n",
    "        int_returns = int_advantages + int_values\n",
    "\n",
    "    # Collect batch data for optimization\n",
    "    b_obs = obs.reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_logprobs = logprobs.reshape(-1)\n",
    "    b_actions = actions.reshape(-1)\n",
    "    b_ext_advantages = ext_advantages.reshape(-1)\n",
    "    b_int_advantages = int_advantages.reshape(-1)\n",
    "    b_ext_returns = ext_returns.reshape(-1)\n",
    "    b_int_returns = int_returns.reshape(-1)\n",
    "    b_ext_values = ext_values.reshape(-1)\n",
    "\n",
    "    b_advantages = b_int_advantages * params[\"int_coef\"] + b_ext_advantages * params[\"ext_coef\"]\n",
    "\n",
    "    # Optimizing the policy and value network\n",
    "    b_inds = np.arange(batch_size)\n",
    "\n",
    "    rnd_next_obs = b_obs\n",
    "\n",
    "    clipfracs = []\n",
    "    for epoch in range(params[\"update_epochs\"]):\n",
    "        np.random.shuffle(b_inds)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            mb_inds = b_inds[start:end]\n",
    "\n",
    "            # Forward_loss\n",
    "            predict_next_state_feature, target_next_state_feature = rnd_model(rnd_next_obs[mb_inds])\n",
    "            forward_loss = F.mse_loss(\n",
    "                predict_next_state_feature, target_next_state_feature.detach(), reduction=\"none\"\n",
    "            ).mean(-1)\n",
    "\n",
    "            mask = torch.rand(len(forward_loss), device=device)\n",
    "            mask = (mask < params[\"update_proportion\"]).type(torch.FloatTensor).to(device)\n",
    "            forward_loss = (forward_loss * mask).sum() / torch.max(\n",
    "                mask.sum(), torch.tensor([1], device=device, dtype=torch.float32)\n",
    "            )\n",
    "            _, newlogprob, entropy, new_ext_values, new_int_values = Agent.get_action_and_value(\n",
    "                b_obs[mb_inds], b_actions.long()[mb_inds]\n",
    "            )\n",
    "            logratio = newlogprob - b_logprobs[mb_inds]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # calculate approx_kl http://joschu.net/blog/kl-approx.html\n",
    "                old_approx_kl = (-logratio).mean()\n",
    "                approx_kl = ((ratio - 1) - logratio).mean()\n",
    "                clipfracs += [((ratio - 1.0).abs() > params[\"clip_coef\"]).float().mean().item()]\n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            if params[\"norm_adv\"]:\n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - params[\"clip_coef\"], 1 + params[\"clip_coef\"])\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            new_ext_values, new_int_values = new_ext_values.view(-1), new_int_values.view(-1)\n",
    "            if params[\"clip_vloss\"]:\n",
    "                ext_value_loss_unclipped = (new_ext_values - b_ext_returns[mb_inds]) ** 2\n",
    "                ext_v_clipped = b_ext_values[mb_inds] + torch.clamp(\n",
    "                    new_ext_values - b_ext_values[mb_inds],\n",
    "                    -params[\"clip_coef\"],\n",
    "                params[\"clip_coef\"],\n",
    "                )\n",
    "                ext_value_loss_clipped = (ext_v_clipped - b_ext_returns[mb_inds]) ** 2\n",
    "                ext_value_loss_max = torch.max(ext_value_loss_unclipped, ext_value_loss_clipped)\n",
    "                ext_value_loss = 0.5 * ext_value_loss_max.mean()\n",
    "            else:\n",
    "                ext_value_loss = 0.5 * ((new_ext_values - b_ext_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            int_value_loss = 0.5 * ((new_int_values - b_int_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            value_loss = ext_value_loss + int_value_loss\n",
    "            entropy_loss = entropy.mean()\n",
    "            loss = pg_loss - params[\"ent_coef\"] * entropy_loss + value_loss * params[\"vf_coef\"] + forward_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if params[\"max_grad_norm\"]:\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    combined_parameters,\n",
    "                    params[\"max_grad_norm\"],\n",
    "                )\n",
    "            optimizer.step()\n",
    "\n",
    "        if params[\"target_kl\"] is not None:\n",
    "            if approx_kl > params[\"target_kl\"]:\n",
    "                break\n",
    "\n",
    "    print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Agent, \"pretrained_models/ppo_for_RND.pth\")\n",
    "# torch.save(rnd_model, \"pretrained_models/rnd.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from results_RND\n",
    "rnd_global_step = results_RND[\"global_step\"]\n",
    "rnd_return_value = results_RND[\"return_value\"]\n",
    "\n",
    "df_rnd = pd.DataFrame({'global_step': rnd_global_step, 'return_value': rnd_return_value})\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "df_rnd.to_csv('data/results_rnd.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Curiosity-driven Exploration by Self-supervised Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Key Points**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The architecture is a network with two tasks, which we refer to as inverse prediction task and forward prediction task. The network, firstly, encodes the state $s_{t}$ and state $s_{t+1}$ into feature vectors $\\phi(s_{t})$ and $\\phi(s_{t+1})$. The network used the two encoded vectors as input to predict action $a_t$ in the inverse prediction task. It then used the result feature vectors $\\phi(s_{t})$ and action $a_t$ as input to predict $\\phi(s_{t+1})$. \n",
    "- The loss for the inverse prediction task is a cross entropy loss between the action chosen by the architecture and the real action that the agent has taken. The loss for the forward prediction task is an MSE loss.\n",
    "- Prediction error is expected to be higher in novel state (suprise state) that the agent is not familiar with. \n",
    "- Reward and Observation Normalization.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./image/Curiousity-driven exploration.png\" alt=\"AutoEncoder forr Count Based Exploration\" width=\"420\" height=\"350\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.1 ICM Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICMModel(nn.Module):\n",
    "    def __init__(self, use_cuda=True):\n",
    "        super(ICMModel, self).__init__()\n",
    "\n",
    "        self.eta = 1.\n",
    "        self.device = device\n",
    "\n",
    "        self.feature = nn.Sequential(\n",
    "            layer_init(nn.Linear(state_space, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.ReLU(),\n",
    "            layer_init(nn.Linear(64, 64), std=1.0),\n",
    "        )\n",
    "\n",
    "        self.inverse_net = nn.Sequential(\n",
    "            nn.Linear(64 * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_space)\n",
    "        )\n",
    "\n",
    "        self.residual = [nn.Sequential(\n",
    "            nn.Linear(action_space + 512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "        ).to(self.device)] * 4\n",
    "\n",
    "        self.forward_net_1 = nn.Sequential(\n",
    "            nn.Linear(action_space + 64, 512),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.forward_net_2 = nn.Sequential(\n",
    "            nn.Linear(action_space + 512, 64),\n",
    "        )\n",
    "\n",
    "        for p in self.modules():\n",
    "            if isinstance(p, nn.Linear):\n",
    "                init.kaiming_uniform_(p.weight, a=1.0)\n",
    "                p.bias.data.zero_()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        state, next_state, action = inputs\n",
    "\n",
    "        encode_state = self.feature(state)\n",
    "        encode_next_state = self.feature(next_state)\n",
    "        # get pred action\n",
    "        pred_action = torch.cat((encode_state, encode_next_state), 1)\n",
    "        pred_action = self.inverse_net(pred_action)\n",
    "        # ---------------------\n",
    "\n",
    "        # get pred next state\n",
    "        pred_next_state_feature_orig = torch.cat((encode_state, action), 1)\n",
    "        pred_next_state_feature_orig = self.forward_net_1(pred_next_state_feature_orig)\n",
    "\n",
    "        # residual\n",
    "        for i in range(2):\n",
    "            pred_next_state_feature = self.residual[i * 2](torch.cat((pred_next_state_feature_orig, action), 1))\n",
    "            pred_next_state_feature_orig = self.residual[i * 2 + 1](\n",
    "                torch.cat((pred_next_state_feature, action), 1)) + pred_next_state_feature_orig\n",
    "\n",
    "        pred_next_state_feature = self.forward_net_2(torch.cat((pred_next_state_feature_orig, action), 1))\n",
    "\n",
    "        real_next_state_feature = encode_next_state\n",
    "        return real_next_state_feature, pred_next_state_feature, pred_action\n",
    "    \n",
    "    def compute_intrinsic_reward(self, state, next_state, action):\n",
    "        # Create 0 vector for the onehot encoded action\n",
    "        action_onehot = torch.zeros(len(action), action_space, device=self.device)\n",
    "        # Scatter the value as according to the value in action\n",
    "        action_onehot.scatter_(1, action.view(len(action), -1), 1)\n",
    "\n",
    "        real_next_state_feature, pred_next_state_feature, pred_action = self.forward([state, next_state, action_onehot])\n",
    "        intrinsic_reward = self.eta * F.mse_loss(real_next_state_feature, pred_next_state_feature, reduction='none').mean(-1)\n",
    "        return intrinsic_reward\n",
    "    \n",
    "    def inference(self, states, next_states, actions):\n",
    "        action_onehot = torch.zeros(len(actions), action_space, device=self.device)\n",
    "        action_onehot.scatter_(1, actions.view(-1, 1).long(), 1)\n",
    "\n",
    "        real_next_state_feature, pred_next_state_feature, pred_action = self.forward([states, next_states, action_onehot])\n",
    "        return real_next_state_feature, pred_next_state_feature, pred_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingSumOfReward:\n",
    "    def __init__(self, gamma):\n",
    "        self.moving_sum_of_reward = None\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def update(self, rews):\n",
    "        if self.moving_sum_of_reward is None:\n",
    "            self.moving_sum_of_reward = rews\n",
    "        else:\n",
    "            self.moving_sum_of_reward = self.moving_sum_of_reward * self.gamma + rews\n",
    "        return self.moving_sum_of_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.2 Main Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = params[\"env_id\"]\n",
    "exp_name = params[\"exp_name\"]\n",
    "seed = params[\"seed\"]\n",
    "run_name = f\"{env_id}__{exp_name}__{seed}__{int(time.time())}\"\n",
    "\n",
    "envs = gym.vector.SyncVectorEnv(\n",
    "    [make_env(env_id) for i in range(params[\"num_envs\"])],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up agent and model\n",
    "icm = ICMModel().to(device)\n",
    "Agent = PPOAgent(envs, use_int_rews=True).to(device)\n",
    "\n",
    "combined_parameters = list(Agent.parameters() ) + list(icm.parameters())\n",
    "optimizer = optim.Adam(\n",
    "    combined_parameters,\n",
    "    lr=params[\"learning_rate\"],\n",
    "    eps=1e-5,\n",
    ")\n",
    "\n",
    "rew_runnning_mean_std = RunningMeanStd()\n",
    "discounted_reward = MovingSumOfReward(params[\"int_gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = torch.zeros((params[\"num_steps\"]+1, params[\"num_envs\"]) + envs.single_observation_space.shape).to(device)  # (128, 4,, 4, 84, 84)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step=88, episodic_return=11.0, surprise_reward=0.23391497135162354\n",
      "global_step=96, episodic_return=12.0, surprise_reward=0.2231069803237915\n",
      "global_step=104, episodic_return=13.0, surprise_reward=0.16917335987091064\n",
      "global_step=112, episodic_return=14.0, surprise_reward=0.11383672058582306\n",
      "global_step=168, episodic_return=21.0, surprise_reward=0.06753683090209961\n",
      "global_step=192, episodic_return=24.0, surprise_reward=0.07088015973567963\n",
      "global_step=232, episodic_return=29.0, surprise_reward=0.1322031021118164\n",
      "global_step=256, episodic_return=11.0, surprise_reward=0.1027040109038353\n",
      "global_step=304, episodic_return=24.0, surprise_reward=0.0878736823797226\n",
      "global_step=304, episodic_return=27.0, surprise_reward=0.0878736823797226\n",
      "global_step=328, episodic_return=28.0, surprise_reward=0.1246991828083992\n",
      "global_step=368, episodic_return=17.0, surprise_reward=0.12321452796459198\n",
      "global_step=368, episodic_return=8.0, surprise_reward=0.12321452796459198\n",
      "global_step=408, episodic_return=27.0, surprise_reward=0.12834885716438293\n",
      "global_step=408, episodic_return=13.0, surprise_reward=0.12834885716438293\n",
      "global_step=440, episodic_return=14.0, surprise_reward=0.26255327463150024\n",
      "global_step=440, episodic_return=55.0, surprise_reward=0.26255327463150024\n",
      "global_step=448, episodic_return=44.0, surprise_reward=0.18875491619110107\n",
      "global_step=456, episodic_return=11.0, surprise_reward=0.09101954847574234\n",
      "global_step=480, episodic_return=28.0, surprise_reward=0.07660286128520966\n",
      "global_step=544, episodic_return=13.0, surprise_reward=0.2503666281700134\n",
      "global_step=544, episodic_return=12.0, surprise_reward=0.2503666281700134\n",
      "global_step=552, episodic_return=14.0, surprise_reward=0.15907126665115356\n",
      "global_step=568, episodic_return=20.0, surprise_reward=0.1265086829662323\n",
      "global_step=576, episodic_return=12.0, surprise_reward=0.09790848195552826\n",
      "global_step=608, episodic_return=19.0, surprise_reward=0.11903306096792221\n",
      "global_step=656, episodic_return=36.0, surprise_reward=0.17062947154045105\n",
      "global_step=656, episodic_return=10.0, surprise_reward=0.17062947154045105\n",
      "global_step=664, episodic_return=15.0, surprise_reward=0.14335036277770996\n",
      "global_step=672, episodic_return=13.0, surprise_reward=0.07585708051919937\n",
      "global_step=744, episodic_return=24.0, surprise_reward=0.16595041751861572\n",
      "global_step=744, episodic_return=11.0, surprise_reward=0.16595041751861572\n",
      "global_step=752, episodic_return=43.0, surprise_reward=0.11028513312339783\n",
      "global_step=776, episodic_return=21.0, surprise_reward=0.1341376006603241\n",
      "global_step=792, episodic_return=31.0, surprise_reward=0.11854048073291779\n",
      "global_step=816, episodic_return=19.0, surprise_reward=0.2190839946269989\n",
      "global_step=832, episodic_return=11.0, surprise_reward=0.12503615021705627\n",
      "global_step=872, episodic_return=15.0, surprise_reward=0.12856733798980713\n",
      "global_step=888, episodic_return=12.0, surprise_reward=0.12062716484069824\n",
      "global_step=896, episodic_return=28.0, surprise_reward=0.13032083213329315\n",
      "global_step=912, episodic_return=10.0, surprise_reward=0.14906999468803406\n",
      "global_step=936, episodic_return=15.0, surprise_reward=0.15469087660312653\n",
      "global_step=968, episodic_return=12.0, surprise_reward=0.09125196188688278\n",
      "global_step=976, episodic_return=40.0, surprise_reward=0.0668458640575409\n",
      "SPS: 240\n",
      "global_step=1040, episodic_return=18.0, surprise_reward=0.0710592195391655\n",
      "global_step=1056, episodic_return=21.0, surprise_reward=0.06673970818519592\n",
      "global_step=1064, episodic_return=19.0, surprise_reward=0.052141569554805756\n",
      "global_step=1072, episodic_return=12.0, surprise_reward=0.04820255562663078\n",
      "global_step=1080, episodic_return=42.0, surprise_reward=0.0379486009478569\n",
      "global_step=1096, episodic_return=40.0, surprise_reward=0.03723538666963577\n",
      "global_step=1136, episodic_return=25.0, surprise_reward=0.04068589583039284\n",
      "global_step=1152, episodic_return=14.0, surprise_reward=0.03957677632570267\n",
      "global_step=1192, episodic_return=14.0, surprise_reward=0.03319243714213371\n",
      "global_step=1208, episodic_return=14.0, surprise_reward=0.031630512326955795\n",
      "global_step=1216, episodic_return=31.0, surprise_reward=0.02801131084561348\n",
      "global_step=1216, episodic_return=18.0, surprise_reward=0.02801131084561348\n",
      "global_step=1288, episodic_return=19.0, surprise_reward=0.061190083622932434\n",
      "global_step=1304, episodic_return=14.0, surprise_reward=0.03484884649515152\n",
      "global_step=1352, episodic_return=37.0, surprise_reward=0.07821297645568848\n",
      "global_step=1360, episodic_return=19.0, surprise_reward=0.04243885353207588\n",
      "global_step=1400, episodic_return=23.0, surprise_reward=0.023988764733076096\n",
      "global_step=1464, episodic_return=22.0, surprise_reward=0.07605355978012085\n",
      "global_step=1464, episodic_return=50.0, surprise_reward=0.07605355978012085\n",
      "global_step=1504, episodic_return=25.0, surprise_reward=0.04911491274833679\n",
      "global_step=1504, episodic_return=19.0, surprise_reward=0.04911491274833679\n",
      "global_step=1568, episodic_return=13.0, surprise_reward=0.07382570952177048\n",
      "global_step=1568, episodic_return=13.0, surprise_reward=0.07382570952177048\n",
      "global_step=1568, episodic_return=52.0, surprise_reward=0.07382570952177048\n",
      "global_step=1584, episodic_return=23.0, surprise_reward=0.034949373453855515\n",
      "global_step=1632, episodic_return=52.0, surprise_reward=0.058346204459667206\n",
      "global_step=1640, episodic_return=17.0, surprise_reward=0.07180699706077576\n",
      "global_step=1672, episodic_return=13.0, surprise_reward=0.11488688737154007\n",
      "global_step=1672, episodic_return=21.0, surprise_reward=0.11488688737154007\n",
      "global_step=1680, episodic_return=14.0, surprise_reward=0.07892908900976181\n",
      "global_step=1696, episodic_return=42.0, surprise_reward=0.057110726833343506\n",
      "global_step=1704, episodic_return=17.0, surprise_reward=0.03849741071462631\n",
      "global_step=1720, episodic_return=17.0, surprise_reward=0.05839018523693085\n",
      "global_step=1752, episodic_return=15.0, surprise_reward=0.08336399495601654\n",
      "global_step=1752, episodic_return=9.0, surprise_reward=0.08336399495601654\n",
      "global_step=1784, episodic_return=11.0, surprise_reward=0.07566612958908081\n",
      "global_step=1792, episodic_return=15.0, surprise_reward=0.056411728262901306\n",
      "global_step=1800, episodic_return=12.0, surprise_reward=0.028995005413889885\n",
      "global_step=1864, episodic_return=24.0, surprise_reward=0.04901216924190521\n",
      "global_step=1880, episodic_return=30.0, surprise_reward=0.03131990134716034\n",
      "global_step=1904, episodic_return=15.0, surprise_reward=0.031020961701869965\n",
      "global_step=1912, episodic_return=24.0, surprise_reward=0.01772424206137657\n",
      "global_step=1944, episodic_return=24.0, surprise_reward=0.03604034706950188\n",
      "global_step=1968, episodic_return=27.0, surprise_reward=0.039392050355672836\n",
      "global_step=1968, episodic_return=22.0, surprise_reward=0.039392050355672836\n",
      "global_step=2024, episodic_return=14.0, surprise_reward=0.11549366265535355\n",
      "global_step=2032, episodic_return=21.0, surprise_reward=0.07447490096092224\n",
      "global_step=2048, episodic_return=13.0, surprise_reward=0.05458070710301399\n",
      "SPS: 149\n",
      "global_step=2072, episodic_return=21.0, surprise_reward=0.024614276364445686\n",
      "global_step=2112, episodic_return=11.0, surprise_reward=0.06433728337287903\n",
      "global_step=2112, episodic_return=18.0, surprise_reward=0.06433728337287903\n",
      "global_step=2144, episodic_return=43.0, surprise_reward=0.019866811111569405\n",
      "global_step=2176, episodic_return=18.0, surprise_reward=0.024472299963235855\n",
      "global_step=2216, episodic_return=13.0, surprise_reward=0.0412621945142746\n",
      "global_step=2248, episodic_return=46.0, surprise_reward=0.02701893262565136\n",
      "global_step=2264, episodic_return=37.0, surprise_reward=0.022049376741051674\n",
      "global_step=2312, episodic_return=30.0, surprise_reward=0.05234084278345108\n",
      "global_step=2328, episodic_return=19.0, surprise_reward=0.046912845224142075\n",
      "global_step=2344, episodic_return=25.0, surprise_reward=0.02451855130493641\n",
      "global_step=2376, episodic_return=20.0, surprise_reward=0.061899278312921524\n",
      "global_step=2376, episodic_return=41.0, surprise_reward=0.061899278312921524\n",
      "global_step=2384, episodic_return=17.0, surprise_reward=0.04558923840522766\n",
      "global_step=2416, episodic_return=11.0, surprise_reward=0.058216266334056854\n",
      "global_step=2432, episodic_return=11.0, surprise_reward=0.07435871660709381\n",
      "global_step=2448, episodic_return=42.0, surprise_reward=0.05869355797767639\n",
      "global_step=2456, episodic_return=24.0, surprise_reward=0.01551060937345028\n",
      "global_step=2496, episodic_return=23.0, surprise_reward=0.02430080622434616\n",
      "global_step=2504, episodic_return=16.0, surprise_reward=0.03735237568616867\n",
      "global_step=2504, episodic_return=16.0, surprise_reward=0.03735237568616867\n",
      "global_step=2536, episodic_return=19.0, surprise_reward=0.030322398990392685\n",
      "global_step=2552, episodic_return=17.0, surprise_reward=0.03727680444717407\n",
      "global_step=2608, episodic_return=20.0, surprise_reward=0.049005359411239624\n",
      "global_step=2648, episodic_return=14.0, surprise_reward=0.09795890748500824\n",
      "global_step=2648, episodic_return=12.0, surprise_reward=0.09795890748500824\n",
      "global_step=2656, episodic_return=25.0, surprise_reward=0.055034685879945755\n",
      "global_step=2664, episodic_return=20.0, surprise_reward=0.0688905268907547\n",
      "global_step=2696, episodic_return=25.0, surprise_reward=0.03571347892284393\n",
      "global_step=2704, episodic_return=12.0, surprise_reward=0.04280456155538559\n",
      "global_step=2704, episodic_return=25.0, surprise_reward=0.04280456155538559\n",
      "global_step=2744, episodic_return=39.0, surprise_reward=0.07794658839702606\n",
      "global_step=2776, episodic_return=16.0, surprise_reward=0.03925219178199768\n",
      "global_step=2808, episodic_return=13.0, surprise_reward=0.05406990274786949\n",
      "global_step=2832, episodic_return=16.0, surprise_reward=0.08611561357975006\n",
      "global_step=2856, episodic_return=10.0, surprise_reward=0.08058177679777145\n",
      "global_step=2856, episodic_return=14.0, surprise_reward=0.08058177679777145\n",
      "global_step=2880, episodic_return=28.0, surprise_reward=0.04884172976016998\n",
      "global_step=2888, episodic_return=28.0, surprise_reward=0.021155228838324547\n",
      "global_step=2936, episodic_return=30.0, surprise_reward=0.026898454874753952\n",
      "global_step=2952, episodic_return=9.0, surprise_reward=0.05718468129634857\n",
      "global_step=3008, episodic_return=15.0, surprise_reward=0.05658932030200958\n",
      "global_step=3024, episodic_return=24.0, surprise_reward=0.05371525138616562\n",
      "global_step=3032, episodic_return=12.0, surprise_reward=0.10057409107685089\n",
      "global_step=3056, episodic_return=25.0, surprise_reward=0.05848350003361702\n",
      "SPS: 189\n",
      "global_step=3088, episodic_return=35.0, surprise_reward=0.04538649320602417\n",
      "global_step=3096, episodic_return=56.0, surprise_reward=0.19709672033786774\n",
      "global_step=3096, episodic_return=11.0, surprise_reward=0.19709672033786774\n",
      "global_step=3104, episodic_return=10.0, surprise_reward=0.05241088569164276\n",
      "global_step=3192, episodic_return=11.0, surprise_reward=0.05607280880212784\n",
      "global_step=3216, episodic_return=15.0, surprise_reward=0.05484243482351303\n",
      "global_step=3224, episodic_return=21.0, surprise_reward=0.0879797413945198\n",
      "global_step=3240, episodic_return=48.0, surprise_reward=0.01785288378596306\n",
      "global_step=3248, episodic_return=27.0, surprise_reward=0.022462641820311546\n",
      "global_step=3280, episodic_return=41.0, surprise_reward=0.018108438700437546\n",
      "global_step=3360, episodic_return=10.0, surprise_reward=0.06331861019134521\n",
      "global_step=3360, episodic_return=21.0, surprise_reward=0.06331861019134521\n",
      "global_step=3408, episodic_return=24.0, surprise_reward=0.04364761337637901\n",
      "global_step=3416, episodic_return=22.0, surprise_reward=0.05321403220295906\n",
      "global_step=3424, episodic_return=41.0, surprise_reward=0.043573711067438126\n",
      "global_step=3456, episodic_return=26.0, surprise_reward=0.027021337300539017\n",
      "global_step=3472, episodic_return=31.0, surprise_reward=0.04321682080626488\n",
      "global_step=3504, episodic_return=11.0, surprise_reward=0.07307286560535431\n",
      "global_step=3520, episodic_return=12.0, surprise_reward=0.06948687136173248\n",
      "global_step=3536, episodic_return=22.0, surprise_reward=0.030890867114067078\n",
      "global_step=3544, episodic_return=57.0, surprise_reward=0.04025576636195183\n",
      "global_step=3568, episodic_return=12.0, surprise_reward=0.025099236518144608\n",
      "global_step=3624, episodic_return=27.0, surprise_reward=0.19600452482700348\n",
      "global_step=3624, episodic_return=15.0, surprise_reward=0.19600452482700348\n",
      "global_step=3624, episodic_return=11.0, surprise_reward=0.19600452482700348\n",
      "global_step=3648, episodic_return=24.0, surprise_reward=0.13778573274612427\n",
      "global_step=3680, episodic_return=14.0, surprise_reward=0.04119741916656494\n",
      "global_step=3688, episodic_return=21.0, surprise_reward=0.014586025848984718\n",
      "global_step=3720, episodic_return=12.0, surprise_reward=0.06114958971738815\n",
      "global_step=3752, episodic_return=26.0, surprise_reward=0.062426477670669556\n",
      "global_step=3808, episodic_return=56.0, surprise_reward=0.020806964486837387\n",
      "global_step=3824, episodic_return=13.0, surprise_reward=0.09337366372346878\n",
      "global_step=3896, episodic_return=31.0, surprise_reward=0.07083211839199066\n",
      "global_step=3912, episodic_return=20.0, surprise_reward=0.029745349660515785\n",
      "global_step=3920, episodic_return=29.0, surprise_reward=0.04232817143201828\n",
      "global_step=3920, episodic_return=14.0, surprise_reward=0.04232817143201828\n",
      "global_step=3928, episodic_return=13.0, surprise_reward=0.08835218846797943\n",
      "global_step=4008, episodic_return=11.0, surprise_reward=0.1134263351559639\n",
      "global_step=4008, episodic_return=12.0, surprise_reward=0.1134263351559639\n",
      "global_step=4016, episodic_return=11.0, surprise_reward=0.0525125190615654\n",
      "global_step=4040, episodic_return=15.0, surprise_reward=0.03206045553088188\n",
      "global_step=4040, episodic_return=52.0, surprise_reward=0.03206045553088188\n",
      "global_step=4064, episodic_return=21.0, surprise_reward=0.06057193502783775\n",
      "global_step=4072, episodic_return=49.0, surprise_reward=0.02390873245894909\n",
      "SPS: 150\n",
      "global_step=4120, episodic_return=14.0, surprise_reward=0.15307864546775818\n",
      "global_step=4136, episodic_return=15.0, surprise_reward=0.08077941089868546\n",
      "global_step=4136, episodic_return=64.0, surprise_reward=0.08077941089868546\n",
      "global_step=4144, episodic_return=17.0, surprise_reward=0.2154272198677063\n",
      "global_step=4144, episodic_return=13.0, surprise_reward=0.2154272198677063\n",
      "global_step=4168, episodic_return=16.0, surprise_reward=0.08482521027326584\n",
      "global_step=4184, episodic_return=15.0, surprise_reward=0.05425094813108444\n",
      "global_step=4264, episodic_return=16.0, surprise_reward=0.030375147238373756\n",
      "global_step=4272, episodic_return=17.0, surprise_reward=0.10220975428819656\n",
      "global_step=4280, episodic_return=17.0, surprise_reward=0.0395532101392746\n",
      "global_step=4288, episodic_return=15.0, surprise_reward=0.020508965477347374\n",
      "global_step=4288, episodic_return=27.0, surprise_reward=0.020508965477347374\n",
      "global_step=4312, episodic_return=16.0, surprise_reward=0.10655789077281952\n",
      "global_step=4368, episodic_return=11.0, surprise_reward=0.1505601555109024\n",
      "global_step=4408, episodic_return=15.0, surprise_reward=0.025281257927417755\n",
      "global_step=4448, episodic_return=38.0, surprise_reward=0.04501604661345482\n",
      "global_step=4480, episodic_return=24.0, surprise_reward=0.08591988682746887\n",
      "global_step=4504, episodic_return=12.0, surprise_reward=0.024035969749093056\n",
      "global_step=4512, episodic_return=31.0, surprise_reward=0.058681972324848175\n",
      "global_step=4520, episodic_return=26.0, surprise_reward=0.0902596265077591\n",
      "global_step=4520, episodic_return=19.0, surprise_reward=0.0902596265077591\n",
      "global_step=4528, episodic_return=32.0, surprise_reward=0.02179030328989029\n",
      "global_step=4584, episodic_return=17.0, surprise_reward=0.07300497591495514\n",
      "global_step=4592, episodic_return=59.0, surprise_reward=0.13629606366157532\n",
      "global_step=4616, episodic_return=13.0, surprise_reward=0.06170973181724548\n",
      "global_step=4624, episodic_return=13.0, surprise_reward=0.1551506221294403\n",
      "global_step=4632, episodic_return=16.0, surprise_reward=0.10071280598640442\n",
      "global_step=4648, episodic_return=16.0, surprise_reward=0.06622733175754547\n",
      "global_step=4680, episodic_return=12.0, surprise_reward=0.020322293043136597\n",
      "global_step=4704, episodic_return=28.0, surprise_reward=0.08927808701992035\n",
      "global_step=4744, episodic_return=15.0, surprise_reward=0.02261335402727127\n",
      "global_step=4768, episodic_return=11.0, surprise_reward=0.03197108581662178\n",
      "global_step=4784, episodic_return=24.0, surprise_reward=0.10088390111923218\n",
      "global_step=4792, episodic_return=11.0, surprise_reward=0.10937923938035965\n",
      "global_step=4792, episodic_return=22.0, surprise_reward=0.10937923938035965\n",
      "global_step=4800, episodic_return=21.0, surprise_reward=0.024918407201766968\n",
      "global_step=4816, episodic_return=9.0, surprise_reward=0.06980612128973007\n",
      "global_step=4824, episodic_return=22.0, surprise_reward=0.021596891805529594\n",
      "global_step=4840, episodic_return=39.0, surprise_reward=0.020995650440454483\n",
      "global_step=4912, episodic_return=12.0, surprise_reward=0.02598589099943638\n",
      "global_step=4944, episodic_return=20.0, surprise_reward=0.09354222565889359\n",
      "global_step=4984, episodic_return=23.0, surprise_reward=0.10122907906770706\n",
      "global_step=5008, episodic_return=21.0, surprise_reward=0.12573851644992828\n",
      "global_step=5008, episodic_return=12.0, surprise_reward=0.12573851644992828\n",
      "global_step=5016, episodic_return=28.0, surprise_reward=0.02085025981068611\n",
      "global_step=5056, episodic_return=33.0, surprise_reward=0.07877648621797562\n",
      "global_step=5064, episodic_return=15.0, surprise_reward=0.10700416564941406\n",
      "global_step=5064, episodic_return=37.0, surprise_reward=0.10700416564941406\n",
      "global_step=5072, episodic_return=31.0, surprise_reward=0.017476797103881836\n",
      "global_step=5104, episodic_return=12.0, surprise_reward=0.040484122931957245\n",
      "SPS: 169\n",
      "global_step=5128, episodic_return=9.0, surprise_reward=0.1752755045890808\n",
      "global_step=5168, episodic_return=12.0, surprise_reward=0.07114097476005554\n",
      "global_step=5184, episodic_return=21.0, surprise_reward=0.025878887623548508\n",
      "global_step=5256, episodic_return=24.0, surprise_reward=0.1500208079814911\n",
      "global_step=5328, episodic_return=25.0, surprise_reward=0.2782995402812958\n",
      "global_step=5328, episodic_return=18.0, surprise_reward=0.2782995402812958\n",
      "global_step=5328, episodic_return=43.0, surprise_reward=0.2782995402812958\n",
      "global_step=5352, episodic_return=31.0, surprise_reward=0.1736832708120346\n",
      "global_step=5360, episodic_return=44.0, surprise_reward=0.03567507863044739\n",
      "global_step=5376, episodic_return=39.0, surprise_reward=0.019419988617300987\n",
      "global_step=5408, episodic_return=10.0, surprise_reward=0.11924023926258087\n",
      "global_step=5448, episodic_return=11.0, surprise_reward=0.08721539378166199\n",
      "global_step=5456, episodic_return=16.0, surprise_reward=0.0355554074048996\n",
      "global_step=5480, episodic_return=16.0, surprise_reward=0.0726088359951973\n",
      "global_step=5488, episodic_return=40.0, surprise_reward=0.015809234231710434\n",
      "global_step=5544, episodic_return=11.0, surprise_reward=0.07925379276275635\n",
      "global_step=5584, episodic_return=17.0, surprise_reward=0.11244268715381622\n",
      "global_step=5584, episodic_return=22.0, surprise_reward=0.11244268715381622\n",
      "global_step=5664, episodic_return=23.0, surprise_reward=0.057953886687755585\n",
      "global_step=5672, episodic_return=52.0, surprise_reward=0.03972703218460083\n",
      "global_step=5680, episodic_return=12.0, surprise_reward=0.12051717936992645\n",
      "global_step=5704, episodic_return=20.0, surprise_reward=0.046507980674505234\n",
      "global_step=5792, episodic_return=15.0, surprise_reward=0.04058561846613884\n",
      "global_step=5800, episodic_return=27.0, surprise_reward=0.10763490200042725\n",
      "global_step=5824, episodic_return=62.0, surprise_reward=0.03249356895685196\n",
      "global_step=5840, episodic_return=44.0, surprise_reward=0.03539857268333435\n",
      "global_step=5856, episodic_return=19.0, surprise_reward=0.09167617559432983\n",
      "global_step=5864, episodic_return=23.0, surprise_reward=0.031575076282024384\n",
      "global_step=5904, episodic_return=10.0, surprise_reward=0.2765169143676758\n",
      "global_step=5904, episodic_return=66.0, surprise_reward=0.2765169143676758\n",
      "global_step=5920, episodic_return=16.0, surprise_reward=0.038420937955379486\n",
      "global_step=6016, episodic_return=12.0, surprise_reward=0.12127386033535004\n",
      "global_step=6064, episodic_return=33.0, surprise_reward=0.22634701430797577\n",
      "global_step=6072, episodic_return=27.0, surprise_reward=0.08834001421928406\n",
      "global_step=6088, episodic_return=28.0, surprise_reward=0.2876220941543579\n",
      "global_step=6088, episodic_return=53.0, surprise_reward=0.2876220941543579\n",
      "global_step=6120, episodic_return=27.0, surprise_reward=0.04402494430541992\n",
      "SPS: 153\n",
      "global_step=6176, episodic_return=11.0, surprise_reward=0.31619614362716675\n",
      "global_step=6176, episodic_return=20.0, surprise_reward=0.31619614362716675\n",
      "global_step=6184, episodic_return=12.0, surprise_reward=0.06601551920175552\n",
      "global_step=6264, episodic_return=10.0, surprise_reward=0.17459097504615784\n",
      "global_step=6264, episodic_return=18.0, surprise_reward=0.17459097504615784\n",
      "global_step=6264, episodic_return=11.0, surprise_reward=0.17459097504615784\n",
      "global_step=6304, episodic_return=58.0, surprise_reward=0.10158596932888031\n",
      "global_step=6360, episodic_return=12.0, surprise_reward=0.1374986469745636\n",
      "global_step=6376, episodic_return=25.0, surprise_reward=0.05529038608074188\n",
      "global_step=6464, episodic_return=20.0, surprise_reward=0.12745648622512817\n",
      "global_step=6472, episodic_return=50.0, surprise_reward=0.023516405373811722\n",
      "global_step=6504, episodic_return=30.0, surprise_reward=0.030411681160330772\n",
      "global_step=6520, episodic_return=32.0, surprise_reward=0.17576973140239716\n",
      "global_step=6528, episodic_return=21.0, surprise_reward=0.057713672518730164\n",
      "global_step=6552, episodic_return=11.0, surprise_reward=0.09673188626766205\n",
      "global_step=6616, episodic_return=12.0, surprise_reward=0.0724552646279335\n",
      "global_step=6672, episodic_return=96.0, surprise_reward=0.049462080001831055\n",
      "global_step=6704, episodic_return=19.0, surprise_reward=0.04751795530319214\n",
      "global_step=6752, episodic_return=31.0, surprise_reward=0.056934699416160583\n",
      "global_step=6768, episodic_return=49.0, surprise_reward=0.19885559380054474\n",
      "global_step=6768, episodic_return=37.0, surprise_reward=0.19885559380054474\n",
      "global_step=6784, episodic_return=32.0, surprise_reward=0.05542784929275513\n",
      "global_step=6792, episodic_return=91.0, surprise_reward=0.15020400285720825\n",
      "global_step=6792, episodic_return=11.0, surprise_reward=0.15020400285720825\n",
      "global_step=6800, episodic_return=16.0, surprise_reward=0.044291239231824875\n",
      "global_step=6816, episodic_return=25.0, surprise_reward=0.064222052693367\n",
      "global_step=6872, episodic_return=13.0, surprise_reward=0.2676447331905365\n",
      "global_step=6872, episodic_return=13.0, surprise_reward=0.2676447331905365\n",
      "global_step=6880, episodic_return=11.0, surprise_reward=0.045209188014268875\n",
      "global_step=6912, episodic_return=16.0, surprise_reward=0.0472928062081337\n",
      "global_step=6928, episodic_return=16.0, surprise_reward=0.11653192341327667\n",
      "global_step=6936, episodic_return=15.0, surprise_reward=0.026516731828451157\n",
      "global_step=6976, episodic_return=23.0, surprise_reward=0.052030209451913834\n",
      "global_step=6992, episodic_return=14.0, surprise_reward=0.03409527242183685\n",
      "global_step=7000, episodic_return=31.0, surprise_reward=0.04960276558995247\n",
      "global_step=7048, episodic_return=17.0, surprise_reward=0.03170330077409744\n",
      "global_step=7056, episodic_return=15.0, surprise_reward=0.16598060727119446\n",
      "global_step=7072, episodic_return=9.0, surprise_reward=0.24436448514461517\n",
      "global_step=7072, episodic_return=10.0, surprise_reward=0.24436448514461517\n",
      "global_step=7112, episodic_return=17.0, surprise_reward=0.17703987658023834\n",
      "global_step=7152, episodic_return=13.0, surprise_reward=0.021893693134188652\n",
      "global_step=7168, episodic_return=14.0, surprise_reward=0.10467249155044556\n",
      "global_step=7168, episodic_return=30.0, surprise_reward=0.10467249155044556\n",
      "SPS: 168\n",
      "global_step=7200, episodic_return=41.0, surprise_reward=0.03537212312221527\n",
      "global_step=7232, episodic_return=10.0, surprise_reward=0.19668176770210266\n",
      "global_step=7232, episodic_return=15.0, surprise_reward=0.19668176770210266\n",
      "global_step=7264, episodic_return=24.0, surprise_reward=0.13418710231781006\n",
      "global_step=7264, episodic_return=49.0, surprise_reward=0.13418710231781006\n",
      "global_step=7272, episodic_return=13.0, surprise_reward=0.05237002670764923\n",
      "global_step=7280, episodic_return=14.0, surprise_reward=0.08731948584318161\n",
      "global_step=7336, episodic_return=33.0, surprise_reward=0.07111421227455139\n",
      "global_step=7368, episodic_return=13.0, surprise_reward=0.05393256992101669\n",
      "global_step=7376, episodic_return=18.0, surprise_reward=0.04842114448547363\n",
      "global_step=7416, episodic_return=27.0, surprise_reward=0.050800785422325134\n",
      "global_step=7440, episodic_return=13.0, surprise_reward=0.0227980799973011\n",
      "global_step=7456, episodic_return=23.0, surprise_reward=0.06252863258123398\n",
      "global_step=7488, episodic_return=15.0, surprise_reward=0.18148276209831238\n",
      "global_step=7496, episodic_return=10.0, surprise_reward=0.07190940529108047\n",
      "global_step=7520, episodic_return=36.0, surprise_reward=0.018174348399043083\n",
      "global_step=7552, episodic_return=14.0, surprise_reward=0.03209087997674942\n",
      "global_step=7584, episodic_return=26.0, surprise_reward=0.1918303519487381\n",
      "global_step=7584, episodic_return=12.0, surprise_reward=0.1918303519487381\n",
      "global_step=7592, episodic_return=12.0, surprise_reward=0.08418530225753784\n",
      "global_step=7592, episodic_return=17.0, surprise_reward=0.08418530225753784\n",
      "global_step=7624, episodic_return=13.0, surprise_reward=0.09502897411584854\n",
      "global_step=7680, episodic_return=50.0, surprise_reward=0.041102468967437744\n",
      "global_step=7728, episodic_return=22.0, surprise_reward=0.08528423309326172\n",
      "global_step=7728, episodic_return=58.0, surprise_reward=0.08528423309326172\n",
      "global_step=7760, episodic_return=22.0, surprise_reward=0.06366802006959915\n",
      "global_step=7840, episodic_return=27.0, surprise_reward=0.03245333209633827\n",
      "global_step=7848, episodic_return=33.0, surprise_reward=0.03717854619026184\n",
      "global_step=7856, episodic_return=33.0, surprise_reward=0.041107166558504105\n",
      "global_step=7864, episodic_return=17.0, surprise_reward=0.10882510244846344\n",
      "global_step=7904, episodic_return=39.0, surprise_reward=0.05093242973089218\n",
      "global_step=7920, episodic_return=10.0, surprise_reward=0.13464029133319855\n",
      "global_step=7928, episodic_return=25.0, surprise_reward=0.05056830495595932\n",
      "global_step=7936, episodic_return=9.0, surprise_reward=0.10460212081670761\n",
      "global_step=7968, episodic_return=36.0, surprise_reward=0.02286064252257347\n",
      "global_step=7976, episodic_return=15.0, surprise_reward=0.03404834866523743\n",
      "global_step=8000, episodic_return=30.0, surprise_reward=0.07557268440723419\n",
      "global_step=8000, episodic_return=9.0, surprise_reward=0.07557268440723419\n",
      "global_step=8080, episodic_return=18.0, surprise_reward=0.037760354578495026\n",
      "global_step=8088, episodic_return=21.0, surprise_reward=0.04539918527007103\n",
      "global_step=8112, episodic_return=26.0, surprise_reward=0.0381661131978035\n",
      "global_step=8144, episodic_return=22.0, surprise_reward=0.08410602807998657\n",
      "global_step=8152, episodic_return=19.0, surprise_reward=0.02959803119301796\n",
      "global_step=8184, episodic_return=23.0, surprise_reward=0.0934775248169899\n",
      "global_step=8192, episodic_return=43.0, surprise_reward=0.08577175438404083\n",
      "SPS: 156\n",
      "global_step=8216, episodic_return=30.0, surprise_reward=0.03977569192647934\n",
      "global_step=8296, episodic_return=18.0, surprise_reward=0.10719849169254303\n",
      "global_step=8320, episodic_return=13.0, surprise_reward=0.01977245695888996\n",
      "global_step=8360, episodic_return=31.0, surprise_reward=0.023176150396466255\n",
      "global_step=8376, episodic_return=36.0, surprise_reward=0.033055584877729416\n",
      "global_step=8384, episodic_return=30.0, surprise_reward=0.13409218192100525\n",
      "global_step=8392, episodic_return=26.0, surprise_reward=0.062162984162569046\n",
      "global_step=8416, episodic_return=15.0, surprise_reward=0.049457598477602005\n",
      "global_step=8496, episodic_return=38.0, surprise_reward=0.26022738218307495\n",
      "global_step=8496, episodic_return=52.0, surprise_reward=0.26022738218307495\n",
      "global_step=8504, episodic_return=16.0, surprise_reward=0.14936292171478271\n",
      "global_step=8512, episodic_return=12.0, surprise_reward=0.06744413077831268\n",
      "global_step=8552, episodic_return=20.0, surprise_reward=0.016982655972242355\n",
      "global_step=8576, episodic_return=27.0, surprise_reward=0.01164092868566513\n",
      "global_step=8600, episodic_return=11.0, surprise_reward=0.05663250759243965\n",
      "global_step=8616, episodic_return=14.0, surprise_reward=0.09016357362270355\n",
      "global_step=8696, episodic_return=18.0, surprise_reward=0.04708695784211159\n",
      "global_step=8712, episodic_return=12.0, surprise_reward=0.05013321340084076\n",
      "global_step=8728, episodic_return=19.0, surprise_reward=0.17787855863571167\n",
      "global_step=8728, episodic_return=51.0, surprise_reward=0.17787855863571167\n",
      "global_step=8736, episodic_return=44.0, surprise_reward=0.1866120845079422\n",
      "global_step=8752, episodic_return=19.0, surprise_reward=0.12433131784200668\n",
      "global_step=8792, episodic_return=10.0, surprise_reward=0.14559568464756012\n",
      "global_step=8808, episodic_return=39.0, surprise_reward=0.014940915629267693\n",
      "global_step=8880, episodic_return=18.0, surprise_reward=0.040418870747089386\n",
      "global_step=8904, episodic_return=19.0, surprise_reward=0.024033257737755775\n",
      "global_step=8952, episodic_return=57.0, surprise_reward=0.08962856233119965\n",
      "global_step=8952, episodic_return=28.0, surprise_reward=0.08962856233119965\n",
      "global_step=8976, episodic_return=35.0, surprise_reward=0.03082158789038658\n",
      "global_step=9016, episodic_return=17.0, surprise_reward=0.024708131328225136\n",
      "global_step=9048, episodic_return=40.0, surprise_reward=0.018358727917075157\n",
      "global_step=9056, episodic_return=13.0, surprise_reward=0.10402891784906387\n",
      "global_step=9088, episodic_return=37.0, surprise_reward=0.047169893980026245\n",
      "global_step=9192, episodic_return=27.0, surprise_reward=0.21216295659542084\n",
      "global_step=9192, episodic_return=18.0, surprise_reward=0.21216295659542084\n",
      "global_step=9208, episodic_return=50.0, surprise_reward=0.2578316926956177\n",
      "global_step=9208, episodic_return=15.0, surprise_reward=0.2578316926956177\n",
      "global_step=9216, episodic_return=39.0, surprise_reward=0.08216432482004166\n",
      "SPS: 169\n",
      "global_step=9224, episodic_return=26.0, surprise_reward=0.09378086775541306\n",
      "global_step=9256, episodic_return=25.0, surprise_reward=0.16033664345741272\n",
      "global_step=9312, episodic_return=15.0, surprise_reward=0.06375520676374435\n",
      "global_step=9328, episodic_return=15.0, surprise_reward=0.18688368797302246\n",
      "global_step=9328, episodic_return=13.0, surprise_reward=0.18688368797302246\n",
      "global_step=9400, episodic_return=56.0, surprise_reward=0.13318182528018951\n",
      "global_step=9408, episodic_return=24.0, surprise_reward=0.016034463420510292\n",
      "global_step=9416, episodic_return=13.0, surprise_reward=0.026256337761878967\n",
      "global_step=9416, episodic_return=26.0, surprise_reward=0.026256337761878967\n",
      "global_step=9440, episodic_return=14.0, surprise_reward=0.012569364160299301\n",
      "global_step=9520, episodic_return=13.0, surprise_reward=0.011954497545957565\n",
      "global_step=9544, episodic_return=18.0, surprise_reward=0.26725390553474426\n",
      "global_step=9544, episodic_return=36.0, surprise_reward=0.26725390553474426\n",
      "global_step=9584, episodic_return=32.0, surprise_reward=0.044543489813804626\n",
      "global_step=9664, episodic_return=28.0, surprise_reward=0.03067190758883953\n",
      "global_step=9672, episodic_return=32.0, surprise_reward=0.06776896864175797\n",
      "global_step=9688, episodic_return=21.0, surprise_reward=0.18931645154953003\n",
      "global_step=9720, episodic_return=17.0, surprise_reward=0.028192173689603806\n",
      "global_step=9728, episodic_return=67.0, surprise_reward=0.1007501482963562\n",
      "global_step=9768, episodic_return=13.0, surprise_reward=0.059738192707300186\n",
      "global_step=9816, episodic_return=34.0, surprise_reward=0.04912397265434265\n",
      "global_step=9856, episodic_return=23.0, surprise_reward=0.09890086203813553\n",
      "global_step=9856, episodic_return=16.0, surprise_reward=0.09890086203813553\n",
      "global_step=9880, episodic_return=59.0, surprise_reward=0.11730759590864182\n",
      "global_step=9896, episodic_return=44.0, surprise_reward=0.2504173219203949\n",
      "global_step=9896, episodic_return=22.0, surprise_reward=0.2504173219203949\n",
      "global_step=9912, episodic_return=28.0, surprise_reward=0.0290195494890213\n",
      "global_step=9928, episodic_return=14.0, surprise_reward=0.07768958806991577\n",
      "global_step=10032, episodic_return=22.0, surprise_reward=0.07635102421045303\n",
      "global_step=10040, episodic_return=14.0, surprise_reward=0.02927873656153679\n",
      "global_step=10104, episodic_return=26.0, surprise_reward=0.02335299178957939\n",
      "global_step=10160, episodic_return=38.0, surprise_reward=0.0411042794585228\n",
      "global_step=10176, episodic_return=33.0, surprise_reward=0.08083393424749374\n",
      "global_step=10184, episodic_return=18.0, surprise_reward=0.24589012563228607\n",
      "global_step=10184, episodic_return=38.0, surprise_reward=0.24589012563228607\n",
      "SPS: 156\n",
      "global_step=10256, episodic_return=19.0, surprise_reward=0.16021504998207092\n",
      "global_step=10264, episodic_return=62.0, surprise_reward=0.24945774674415588\n",
      "global_step=10264, episodic_return=11.0, surprise_reward=0.24945774674415588\n",
      "global_step=10272, episodic_return=30.0, surprise_reward=0.08074839413166046\n",
      "global_step=10352, episodic_return=21.0, surprise_reward=0.11712649464607239\n",
      "global_step=10376, episodic_return=14.0, surprise_reward=0.09818670153617859\n",
      "global_step=10392, episodic_return=26.0, surprise_reward=0.018392104655504227\n",
      "global_step=10408, episodic_return=19.0, surprise_reward=0.023777499794960022\n",
      "global_step=10416, episodic_return=19.0, surprise_reward=0.026960114017128944\n",
      "global_step=10432, episodic_return=67.0, surprise_reward=0.05293922498822212\n",
      "global_step=10552, episodic_return=17.0, surprise_reward=0.2237206995487213\n",
      "global_step=10560, episodic_return=36.0, surprise_reward=0.02751133404672146\n",
      "global_step=10584, episodic_return=53.0, surprise_reward=0.10516531020402908\n",
      "global_step=10600, episodic_return=21.0, surprise_reward=0.01313505508005619\n",
      "global_step=10632, episodic_return=30.0, surprise_reward=0.11756324023008347\n",
      "global_step=10656, episodic_return=38.0, surprise_reward=0.06277398765087128\n",
      "global_step=10688, episodic_return=39.0, surprise_reward=0.01872377097606659\n",
      "global_step=10704, episodic_return=18.0, surprise_reward=0.08919765055179596\n",
      "global_step=10744, episodic_return=42.0, surprise_reward=0.014876330271363258\n",
      "global_step=10768, episodic_return=17.0, surprise_reward=0.20763632655143738\n",
      "global_step=10800, episodic_return=27.0, surprise_reward=0.015659719705581665\n",
      "global_step=10904, episodic_return=44.0, surprise_reward=0.06689687818288803\n",
      "global_step=10920, episodic_return=19.0, surprise_reward=0.21728940308094025\n",
      "global_step=10944, episodic_return=18.0, surprise_reward=0.04701513424515724\n",
      "global_step=11024, episodic_return=40.0, surprise_reward=0.1710609644651413\n",
      "global_step=11056, episodic_return=57.0, surprise_reward=0.12706585228443146\n",
      "global_step=11120, episodic_return=54.0, surprise_reward=0.09546247869729996\n",
      "global_step=11160, episodic_return=30.0, surprise_reward=0.020299691706895828\n",
      "global_step=11192, episodic_return=31.0, surprise_reward=0.1098993718624115\n",
      "global_step=11264, episodic_return=30.0, surprise_reward=0.016793709248304367\n",
      "SPS: 164\n",
      "global_step=11272, episodic_return=66.0, surprise_reward=0.02650510147213936\n",
      "global_step=11296, episodic_return=30.0, surprise_reward=0.05025872588157654\n",
      "global_step=11312, episodic_return=15.0, surprise_reward=0.07085969299077988\n",
      "global_step=11328, episodic_return=53.0, surprise_reward=0.07147620618343353\n",
      "global_step=11344, episodic_return=28.0, surprise_reward=0.10228413343429565\n",
      "global_step=11400, episodic_return=16.0, surprise_reward=0.03746660798788071\n",
      "global_step=11432, episodic_return=34.0, surprise_reward=0.04339970648288727\n",
      "global_step=11432, episodic_return=97.0, surprise_reward=0.04339970648288727\n",
      "global_step=11472, episodic_return=22.0, surprise_reward=0.04571213573217392\n",
      "global_step=11496, episodic_return=21.0, surprise_reward=0.05341217666864395\n",
      "global_step=11552, episodic_return=10.0, surprise_reward=0.038765765726566315\n",
      "global_step=11576, episodic_return=18.0, surprise_reward=0.042619988322257996\n",
      "global_step=11592, episodic_return=12.0, surprise_reward=0.12221813201904297\n",
      "global_step=11592, episodic_return=31.0, surprise_reward=0.12221813201904297\n",
      "global_step=11600, episodic_return=21.0, surprise_reward=0.012257378548383713\n",
      "global_step=11632, episodic_return=46.0, surprise_reward=0.06225857883691788\n",
      "global_step=11656, episodic_return=32.0, surprise_reward=0.0228472538292408\n",
      "global_step=11696, episodic_return=18.0, surprise_reward=0.06277777254581451\n",
      "global_step=11696, episodic_return=13.0, surprise_reward=0.06277777254581451\n",
      "global_step=11704, episodic_return=16.0, surprise_reward=0.07514581084251404\n",
      "global_step=11720, episodic_return=51.0, surprise_reward=0.11096680164337158\n",
      "global_step=11768, episodic_return=21.0, surprise_reward=0.024120869114995003\n",
      "global_step=11824, episodic_return=15.0, surprise_reward=0.0765305608510971\n",
      "global_step=11832, episodic_return=17.0, surprise_reward=0.07010342925786972\n",
      "global_step=11840, episodic_return=31.0, surprise_reward=0.0294489786028862\n",
      "global_step=11848, episodic_return=24.0, surprise_reward=0.015381928533315659\n",
      "global_step=11872, episodic_return=22.0, surprise_reward=0.07901649922132492\n",
      "global_step=11936, episodic_return=27.0, surprise_reward=0.11771780997514725\n",
      "global_step=11984, episodic_return=14.0, surprise_reward=0.09660042077302933\n",
      "global_step=12048, episodic_return=52.0, surprise_reward=0.18925470113754272\n",
      "global_step=12096, episodic_return=32.0, surprise_reward=0.054873209446668625\n",
      "global_step=12152, episodic_return=40.0, surprise_reward=0.03704589605331421\n",
      "global_step=12168, episodic_return=50.0, surprise_reward=0.03385636582970619\n",
      "global_step=12168, episodic_return=43.0, surprise_reward=0.03385636582970619\n",
      "global_step=12184, episodic_return=42.0, surprise_reward=0.07919123768806458\n",
      "global_step=12184, episodic_return=31.0, surprise_reward=0.07919123768806458\n",
      "SPS: 145\n",
      "global_step=12344, episodic_return=20.0, surprise_reward=0.0989915058016777\n",
      "global_step=12352, episodic_return=38.0, surprise_reward=0.014806520193815231\n",
      "global_step=12392, episodic_return=37.0, surprise_reward=0.01718871109187603\n",
      "global_step=12408, episodic_return=53.0, surprise_reward=0.03260231018066406\n",
      "global_step=12424, episodic_return=34.0, surprise_reward=0.06444141268730164\n",
      "global_step=12432, episodic_return=33.0, surprise_reward=0.03183240070939064\n",
      "global_step=12520, episodic_return=44.0, surprise_reward=0.011794026009738445\n",
      "global_step=12552, episodic_return=26.0, surprise_reward=0.1274767965078354\n",
      "global_step=12576, episodic_return=23.0, surprise_reward=0.2775592803955078\n",
      "global_step=12576, episodic_return=18.0, surprise_reward=0.2775592803955078\n",
      "global_step=12616, episodic_return=26.0, surprise_reward=0.12467852234840393\n",
      "global_step=12632, episodic_return=56.0, surprise_reward=0.03502926602959633\n",
      "global_step=12648, episodic_return=9.0, surprise_reward=0.06839117407798767\n",
      "global_step=12664, episodic_return=14.0, surprise_reward=0.04583076760172844\n",
      "global_step=12720, episodic_return=18.0, surprise_reward=0.02099641039967537\n",
      "global_step=12736, episodic_return=27.0, surprise_reward=0.07312461733818054\n",
      "global_step=12760, episodic_return=51.0, surprise_reward=0.05626818910241127\n",
      "global_step=12832, episodic_return=21.0, surprise_reward=0.028732609003782272\n",
      "global_step=12856, episodic_return=17.0, surprise_reward=0.06525294482707977\n",
      "global_step=12880, episodic_return=31.0, surprise_reward=0.01959052123129368\n",
      "global_step=12904, episodic_return=60.0, surprise_reward=0.14419898390769958\n",
      "global_step=12936, episodic_return=22.0, surprise_reward=0.047153569757938385\n",
      "global_step=12976, episodic_return=15.0, surprise_reward=0.06094152107834816\n",
      "global_step=13040, episodic_return=26.0, surprise_reward=0.04999294877052307\n",
      "global_step=13072, episodic_return=24.0, surprise_reward=0.0730128064751625\n",
      "global_step=13072, episodic_return=57.0, surprise_reward=0.0730128064751625\n",
      "global_step=13120, episodic_return=27.0, surprise_reward=0.06470248103141785\n",
      "global_step=13128, episodic_return=19.0, surprise_reward=0.051754921674728394\n",
      "global_step=13160, episodic_return=64.0, surprise_reward=0.04574001580476761\n",
      "global_step=13208, episodic_return=10.0, surprise_reward=0.0435694195330143\n",
      "global_step=13256, episodic_return=23.0, surprise_reward=0.051127683371305466\n",
      "global_step=13264, episodic_return=24.0, surprise_reward=0.014417075552046299\n",
      "global_step=13288, episodic_return=21.0, surprise_reward=0.06503298133611679\n",
      "SPS: 154\n",
      "global_step=13328, episodic_return=36.0, surprise_reward=0.07959777116775513\n",
      "global_step=13352, episodic_return=52.0, surprise_reward=0.17053428292274475\n",
      "global_step=13368, episodic_return=14.0, surprise_reward=0.2308838814496994\n",
      "global_step=13400, episodic_return=83.0, surprise_reward=0.12468115240335464\n",
      "global_step=13440, episodic_return=14.0, surprise_reward=0.010076452046632767\n",
      "global_step=13504, episodic_return=30.0, surprise_reward=0.024850087240338326\n",
      "global_step=13512, episodic_return=18.0, surprise_reward=0.09179599583148956\n",
      "global_step=13528, episodic_return=46.0, surprise_reward=0.02533542737364769\n",
      "global_step=13552, episodic_return=43.0, surprise_reward=0.02048317901790142\n",
      "global_step=13584, episodic_return=23.0, surprise_reward=0.07633863389492035\n",
      "global_step=13640, episodic_return=17.0, surprise_reward=0.026373550295829773\n",
      "global_step=13696, episodic_return=14.0, surprise_reward=0.09808292984962463\n",
      "global_step=13696, episodic_return=23.0, surprise_reward=0.09808292984962463\n",
      "global_step=13720, episodic_return=24.0, surprise_reward=0.2631189227104187\n",
      "global_step=13720, episodic_return=35.0, surprise_reward=0.2631189227104187\n",
      "global_step=13768, episodic_return=60.0, surprise_reward=0.04403176158666611\n",
      "global_step=13824, episodic_return=13.0, surprise_reward=0.02777831070125103\n",
      "global_step=13832, episodic_return=35.0, surprise_reward=0.016860175877809525\n",
      "global_step=13872, episodic_return=65.0, surprise_reward=0.01865820772945881\n",
      "global_step=13896, episodic_return=32.0, surprise_reward=0.05595077574253082\n",
      "global_step=13920, episodic_return=12.0, surprise_reward=0.1827702671289444\n",
      "global_step=13944, episodic_return=22.0, surprise_reward=0.013728260062634945\n",
      "global_step=14000, episodic_return=35.0, surprise_reward=0.03077387996017933\n",
      "global_step=14016, episodic_return=40.0, surprise_reward=0.0887361615896225\n",
      "global_step=14016, episodic_return=40.0, surprise_reward=0.0887361615896225\n",
      "global_step=14032, episodic_return=20.0, surprise_reward=0.014298542402684689\n",
      "global_step=14048, episodic_return=13.0, surprise_reward=0.03273718059062958\n",
      "global_step=14080, episodic_return=31.0, surprise_reward=0.0549703873693943\n",
      "global_step=14088, episodic_return=21.0, surprise_reward=0.028556330129504204\n",
      "global_step=14104, episodic_return=26.0, surprise_reward=0.15680207312107086\n",
      "global_step=14184, episodic_return=19.0, surprise_reward=0.031171269714832306\n",
      "global_step=14192, episodic_return=22.0, surprise_reward=0.03640689328312874\n",
      "global_step=14288, episodic_return=26.0, surprise_reward=0.02035997062921524\n",
      "global_step=14312, episodic_return=16.0, surprise_reward=0.1077074408531189\n",
      "SPS: 143\n",
      "global_step=14344, episodic_return=41.0, surprise_reward=0.027613703161478043\n",
      "global_step=14352, episodic_return=44.0, surprise_reward=0.01516895741224289\n",
      "global_step=14472, episodic_return=48.0, surprise_reward=0.01686805672943592\n",
      "global_step=14520, episodic_return=26.0, surprise_reward=0.03189516067504883\n",
      "global_step=14552, episodic_return=63.0, surprise_reward=0.09329061210155487\n",
      "global_step=14568, episodic_return=12.0, surprise_reward=0.05096452683210373\n",
      "global_step=14624, episodic_return=54.0, surprise_reward=0.043094344437122345\n",
      "global_step=14632, episodic_return=66.0, surprise_reward=0.09689995646476746\n",
      "global_step=14632, episodic_return=35.0, surprise_reward=0.09689995646476746\n",
      "global_step=14680, episodic_return=20.0, surprise_reward=0.020188599824905396\n",
      "global_step=14688, episodic_return=50.0, surprise_reward=0.016789380460977554\n",
      "global_step=14696, episodic_return=44.0, surprise_reward=0.01692912168800831\n",
      "global_step=14728, episodic_return=20.0, surprise_reward=0.03867587447166443\n",
      "global_step=14832, episodic_return=25.0, surprise_reward=0.027445677667856216\n",
      "global_step=14928, episodic_return=37.0, surprise_reward=0.023294834420084953\n",
      "global_step=14944, episodic_return=33.0, surprise_reward=0.015740569680929184\n",
      "global_step=15000, episodic_return=47.0, surprise_reward=0.04556103050708771\n",
      "global_step=15024, episodic_return=37.0, surprise_reward=0.018522445112466812\n",
      "global_step=15056, episodic_return=16.0, surprise_reward=0.0523805096745491\n",
      "global_step=15120, episodic_return=54.0, surprise_reward=0.05866299197077751\n",
      "global_step=15176, episodic_return=78.0, surprise_reward=0.03227140009403229\n",
      "global_step=15192, episodic_return=31.0, surprise_reward=0.035705965012311935\n",
      "global_step=15208, episodic_return=47.0, surprise_reward=0.022386932745575905\n",
      "global_step=15248, episodic_return=24.0, surprise_reward=0.05707902833819389\n",
      "global_step=15304, episodic_return=76.0, surprise_reward=0.035531289875507355\n",
      "global_step=15320, episodic_return=40.0, surprise_reward=0.024966157972812653\n",
      "SPS: 150\n",
      "global_step=15384, episodic_return=17.0, surprise_reward=0.08158116787672043\n",
      "global_step=15448, episodic_return=16.0, surprise_reward=0.04663841053843498\n",
      "global_step=15472, episodic_return=37.0, surprise_reward=0.2218916416168213\n",
      "global_step=15472, episodic_return=35.0, surprise_reward=0.2218916416168213\n",
      "global_step=15488, episodic_return=46.0, surprise_reward=0.011816359125077724\n",
      "global_step=15576, episodic_return=69.0, surprise_reward=0.05294838547706604\n",
      "global_step=15608, episodic_return=20.0, surprise_reward=0.21624766290187836\n",
      "global_step=15632, episodic_return=31.0, surprise_reward=0.018164578825235367\n",
      "global_step=15688, episodic_return=48.0, surprise_reward=0.02739046886563301\n",
      "global_step=15712, episodic_return=63.0, surprise_reward=0.023439720273017883\n",
      "global_step=15832, episodic_return=25.0, surprise_reward=0.010119318030774593\n",
      "global_step=15888, episodic_return=22.0, surprise_reward=0.022712208330631256\n",
      "global_step=15896, episodic_return=36.0, surprise_reward=0.019172130152583122\n",
      "global_step=15944, episodic_return=14.0, surprise_reward=0.06617967784404755\n",
      "global_step=15952, episodic_return=58.0, surprise_reward=0.023098109290003777\n",
      "global_step=15976, episodic_return=50.0, surprise_reward=0.039128366857767105\n",
      "global_step=15984, episodic_return=64.0, surprise_reward=0.04290478676557541\n",
      "global_step=16056, episodic_return=21.0, surprise_reward=0.018432103097438812\n",
      "global_step=16080, episodic_return=13.0, surprise_reward=0.03119293972849846\n",
      "global_step=16096, episodic_return=51.0, surprise_reward=0.022374097257852554\n",
      "global_step=16168, episodic_return=11.0, surprise_reward=0.17133067548274994\n",
      "global_step=16176, episodic_return=28.0, surprise_reward=0.0831637755036354\n",
      "global_step=16200, episodic_return=18.0, surprise_reward=0.2546510398387909\n",
      "global_step=16256, episodic_return=39.0, surprise_reward=0.029062680900096893\n",
      "global_step=16264, episodic_return=21.0, surprise_reward=0.015416895970702171\n",
      "global_step=16288, episodic_return=15.0, surprise_reward=0.07647368311882019\n",
      "global_step=16360, episodic_return=47.0, surprise_reward=0.10682946443557739\n",
      "global_step=16360, episodic_return=23.0, surprise_reward=0.10682946443557739\n",
      "global_step=16368, episodic_return=112.0, surprise_reward=0.029796123504638672\n",
      "SPS: 128\n",
      "global_step=16416, episodic_return=65.0, surprise_reward=0.03665170818567276\n",
      "global_step=16432, episodic_return=21.0, surprise_reward=0.029288120567798615\n",
      "global_step=16496, episodic_return=26.0, surprise_reward=0.014502791687846184\n",
      "global_step=16528, episodic_return=41.0, surprise_reward=0.015287511050701141\n",
      "global_step=16576, episodic_return=18.0, surprise_reward=0.012961355969309807\n",
      "global_step=16592, episodic_return=29.0, surprise_reward=0.032365281134843826\n",
      "global_step=16624, episodic_return=32.0, surprise_reward=0.014285970479249954\n",
      "global_step=16664, episodic_return=51.0, surprise_reward=0.03003093972802162\n",
      "global_step=16672, episodic_return=32.0, surprise_reward=0.013964027166366577\n",
      "global_step=16688, episodic_return=14.0, surprise_reward=0.04606984183192253\n",
      "global_step=16776, episodic_return=19.0, surprise_reward=0.1565679907798767\n",
      "global_step=16776, episodic_return=31.0, surprise_reward=0.1565679907798767\n",
      "global_step=16840, episodic_return=43.0, surprise_reward=0.04977264255285263\n",
      "global_step=16896, episodic_return=67.0, surprise_reward=0.042638108134269714\n",
      "global_step=16920, episodic_return=18.0, surprise_reward=0.11466297507286072\n",
      "global_step=16936, episodic_return=34.0, surprise_reward=0.03991622477769852\n",
      "global_step=16952, episodic_return=33.0, surprise_reward=0.023993544280529022\n",
      "global_step=16976, episodic_return=48.0, surprise_reward=0.13824477791786194\n",
      "global_step=17008, episodic_return=21.0, surprise_reward=0.03885258734226227\n",
      "global_step=17064, episodic_return=36.0, surprise_reward=0.06481987237930298\n",
      "global_step=17072, episodic_return=22.0, surprise_reward=0.05251123756170273\n",
      "global_step=17144, episodic_return=26.0, surprise_reward=0.030199656262993813\n",
      "global_step=17160, episodic_return=61.0, surprise_reward=0.0273864958435297\n",
      "global_step=17176, episodic_return=32.0, surprise_reward=0.020088473334908485\n",
      "global_step=17208, episodic_return=17.0, surprise_reward=0.03952594846487045\n",
      "global_step=17208, episodic_return=32.0, surprise_reward=0.03952594846487045\n",
      "global_step=17248, episodic_return=13.0, surprise_reward=0.11184170842170715\n",
      "global_step=17248, episodic_return=34.0, surprise_reward=0.11184170842170715\n",
      "global_step=17320, episodic_return=20.0, surprise_reward=0.05320214480161667\n",
      "global_step=17344, episodic_return=35.0, surprise_reward=0.045798059552907944\n",
      "global_step=17352, episodic_return=43.0, surprise_reward=0.13168136775493622\n",
      "global_step=17352, episodic_return=18.0, surprise_reward=0.13168136775493622\n",
      "global_step=17408, episodic_return=29.0, surprise_reward=0.12008777260780334\n",
      "SPS: 132\n",
      "global_step=17528, episodic_return=15.0, surprise_reward=0.020665490999817848\n",
      "global_step=17576, episodic_return=41.0, surprise_reward=0.13394130766391754\n",
      "global_step=17584, episodic_return=42.0, surprise_reward=0.03427156060934067\n",
      "global_step=17600, episodic_return=32.0, surprise_reward=0.010374079458415508\n",
      "global_step=17624, episodic_return=52.0, surprise_reward=0.016794627532362938\n",
      "global_step=17688, episodic_return=42.0, surprise_reward=0.029077619314193726\n",
      "global_step=17720, episodic_return=46.0, surprise_reward=0.03137735277414322\n",
      "global_step=17728, episodic_return=16.0, surprise_reward=0.38630709052085876\n",
      "global_step=17736, episodic_return=20.0, surprise_reward=0.2466694414615631\n",
      "global_step=17752, episodic_return=28.0, surprise_reward=0.0330590084195137\n",
      "global_step=17768, episodic_return=23.0, surprise_reward=0.032551005482673645\n",
      "global_step=17872, episodic_return=19.0, surprise_reward=0.025768352672457695\n",
      "global_step=17904, episodic_return=21.0, surprise_reward=0.12108667194843292\n",
      "global_step=17960, episodic_return=42.0, surprise_reward=0.03156139701604843\n",
      "global_step=17960, episodic_return=29.0, surprise_reward=0.03156139701604843\n",
      "global_step=17960, episodic_return=24.0, surprise_reward=0.03156139701604843\n",
      "global_step=18088, episodic_return=16.0, surprise_reward=0.0469328835606575\n",
      "global_step=18136, episodic_return=56.0, surprise_reward=0.035098008811473846\n",
      "global_step=18208, episodic_return=57.0, surprise_reward=0.06841015070676804\n",
      "global_step=18328, episodic_return=24.0, surprise_reward=0.0552060566842556\n",
      "global_step=18336, episodic_return=127.0, surprise_reward=0.08830169588327408\n",
      "global_step=18344, episodic_return=48.0, surprise_reward=0.041621457785367966\n",
      "global_step=18360, episodic_return=57.0, surprise_reward=0.053238045424222946\n",
      "global_step=18408, episodic_return=67.0, surprise_reward=0.021313123404979706\n",
      "global_step=18424, episodic_return=58.0, surprise_reward=0.018682461231946945\n",
      "SPS: 117\n",
      "global_step=18512, episodic_return=11.0, surprise_reward=0.1080436185002327\n",
      "global_step=18528, episodic_return=21.0, surprise_reward=0.031755849719047546\n",
      "global_step=18544, episodic_return=57.0, surprise_reward=0.020308494567871094\n",
      "global_step=18560, episodic_return=19.0, surprise_reward=0.09878037869930267\n",
      "global_step=18616, episodic_return=51.0, surprise_reward=0.012626999989151955\n",
      "global_step=18648, episodic_return=17.0, surprise_reward=0.06976339221000671\n",
      "global_step=18696, episodic_return=17.0, surprise_reward=0.04483279213309288\n",
      "global_step=18704, episodic_return=47.0, surprise_reward=0.055334772914648056\n",
      "global_step=18744, episodic_return=50.0, surprise_reward=0.08455739915370941\n",
      "global_step=18744, episodic_return=16.0, surprise_reward=0.08455739915370941\n",
      "global_step=18784, episodic_return=11.0, surprise_reward=0.09919539093971252\n",
      "global_step=18896, episodic_return=70.0, surprise_reward=0.025414301082491875\n",
      "global_step=19000, episodic_return=59.0, surprise_reward=0.028007522225379944\n",
      "global_step=19024, episodic_return=35.0, surprise_reward=0.08583247661590576\n",
      "global_step=19048, episodic_return=50.0, surprise_reward=0.019749242812395096\n",
      "global_step=19104, episodic_return=45.0, surprise_reward=0.01757393591105938\n",
      "global_step=19144, episodic_return=45.0, surprise_reward=0.1272537261247635\n",
      "global_step=19168, episodic_return=78.0, surprise_reward=0.01993866078555584\n",
      "global_step=19176, episodic_return=19.0, surprise_reward=0.03205091878771782\n",
      "global_step=19232, episodic_return=11.0, surprise_reward=0.17357894778251648\n",
      "global_step=19232, episodic_return=23.0, surprise_reward=0.17357894778251648\n",
      "global_step=19248, episodic_return=68.0, surprise_reward=0.10527193546295166\n",
      "global_step=19320, episodic_return=18.0, surprise_reward=0.013629505410790443\n",
      "global_step=19392, episodic_return=28.0, surprise_reward=0.016132641583681107\n",
      "global_step=19424, episodic_return=53.0, surprise_reward=0.028024345636367798\n",
      "global_step=19448, episodic_return=43.0, surprise_reward=0.05785830318927765\n",
      "SPS: 120\n",
      "global_step=19472, episodic_return=72.0, surprise_reward=0.036422185599803925\n",
      "global_step=19600, episodic_return=22.0, surprise_reward=0.02993732877075672\n",
      "global_step=19616, episodic_return=48.0, surprise_reward=0.03644102066755295\n",
      "global_step=19760, episodic_return=20.0, surprise_reward=0.22456614673137665\n",
      "global_step=19808, episodic_return=52.0, surprise_reward=0.03655353933572769\n",
      "global_step=19888, episodic_return=71.0, surprise_reward=0.06171524524688721\n",
      "global_step=19960, episodic_return=61.0, surprise_reward=0.07018249481916428\n",
      "global_step=19968, episodic_return=90.0, surprise_reward=0.1895461529493332\n",
      "global_step=19976, episodic_return=45.0, surprise_reward=0.028017835691571236\n",
      "global_step=19984, episodic_return=28.0, surprise_reward=0.04089002311229706\n",
      "global_step=20000, episodic_return=96.0, surprise_reward=0.0896834135055542\n",
      "global_step=20064, episodic_return=77.0, surprise_reward=0.1334126740694046\n",
      "global_step=20144, episodic_return=22.0, surprise_reward=0.0312919095158577\n",
      "global_step=20168, episodic_return=13.0, surprise_reward=0.13014590740203857\n",
      "global_step=20192, episodic_return=27.0, surprise_reward=0.04462656378746033\n",
      "global_step=20296, episodic_return=51.0, surprise_reward=0.042166803032159805\n",
      "global_step=20304, episodic_return=62.0, surprise_reward=0.08049241453409195\n",
      "global_step=20416, episodic_return=57.0, surprise_reward=0.04046303778886795\n",
      "global_step=20456, episodic_return=39.0, surprise_reward=0.036778949201107025\n",
      "SPS: 97\n",
      "global_step=20488, episodic_return=24.0, surprise_reward=0.08694280683994293\n",
      "global_step=20504, episodic_return=39.0, surprise_reward=0.040548235177993774\n",
      "global_step=20616, episodic_return=16.0, surprise_reward=0.07343454658985138\n",
      "global_step=20632, episodic_return=81.0, surprise_reward=0.04672234505414963\n",
      "global_step=20680, episodic_return=64.0, surprise_reward=0.02896196022629738\n",
      "global_step=20696, episodic_return=87.0, surprise_reward=0.05130370706319809\n",
      "global_step=20728, episodic_return=28.0, surprise_reward=0.01256859116256237\n",
      "global_step=20760, episodic_return=57.0, surprise_reward=0.06782599538564682\n",
      "global_step=20896, episodic_return=27.0, surprise_reward=0.027984291315078735\n",
      "global_step=21000, episodic_return=46.0, surprise_reward=0.05151889845728874\n",
      "global_step=21008, episodic_return=31.0, surprise_reward=0.09402412921190262\n",
      "global_step=21024, episodic_return=51.0, surprise_reward=0.01571313850581646\n",
      "global_step=21080, episodic_return=48.0, surprise_reward=0.016684215515851974\n",
      "global_step=21144, episodic_return=86.0, surprise_reward=0.08355087041854858\n",
      "global_step=21160, episodic_return=93.0, surprise_reward=0.044246427714824677\n",
      "global_step=21200, episodic_return=24.0, surprise_reward=0.0682072788476944\n",
      "global_step=21264, episodic_return=46.0, surprise_reward=0.05035891756415367\n",
      "global_step=21264, episodic_return=23.0, surprise_reward=0.05035891756415367\n",
      "global_step=21336, episodic_return=76.0, surprise_reward=0.025349289178848267\n",
      "global_step=21336, episodic_return=24.0, surprise_reward=0.025349289178848267\n",
      "global_step=21352, episodic_return=41.0, surprise_reward=0.03235073387622833\n",
      "global_step=21368, episodic_return=26.0, surprise_reward=0.05068547651171684\n",
      "global_step=21400, episodic_return=17.0, surprise_reward=0.03166716918349266\n",
      "global_step=21456, episodic_return=15.0, surprise_reward=0.009612631052732468\n",
      "global_step=21464, episodic_return=58.0, surprise_reward=0.021063152700662613\n",
      "SPS: 101\n",
      "global_step=21512, episodic_return=18.0, surprise_reward=0.020204756408929825\n",
      "global_step=21600, episodic_return=33.0, surprise_reward=0.014396069571375847\n",
      "global_step=21624, episodic_return=34.0, surprise_reward=0.014029238373041153\n",
      "global_step=21632, episodic_return=46.0, surprise_reward=0.01263880729675293\n",
      "global_step=21736, episodic_return=28.0, surprise_reward=0.028237927705049515\n",
      "global_step=21744, episodic_return=18.0, surprise_reward=0.05180508643388748\n",
      "global_step=21784, episodic_return=73.0, surprise_reward=0.06829597800970078\n",
      "global_step=21800, episodic_return=42.0, surprise_reward=0.05525648966431618\n",
      "global_step=21816, episodic_return=45.0, surprise_reward=0.020417094230651855\n",
      "global_step=21928, episodic_return=16.0, surprise_reward=0.05002175271511078\n",
      "global_step=22024, episodic_return=36.0, surprise_reward=0.06949833035469055\n",
      "global_step=22024, episodic_return=49.0, surprise_reward=0.06949833035469055\n",
      "global_step=22120, episodic_return=62.0, surprise_reward=0.016679054126143456\n",
      "global_step=22184, episodic_return=32.0, surprise_reward=0.03365208953619003\n",
      "global_step=22216, episodic_return=50.0, surprise_reward=0.044971734285354614\n",
      "global_step=22264, episodic_return=18.0, surprise_reward=0.09674103558063507\n",
      "global_step=22328, episodic_return=73.0, surprise_reward=0.10723087191581726\n",
      "global_step=22352, episodic_return=41.0, surprise_reward=0.043184421956539154\n",
      "global_step=22360, episodic_return=22.0, surprise_reward=0.023952508345246315\n",
      "global_step=22400, episodic_return=47.0, surprise_reward=0.040345437824726105\n",
      "global_step=22424, episodic_return=26.0, surprise_reward=0.06253816187381744\n",
      "SPS: 95\n",
      "global_step=22552, episodic_return=19.0, surprise_reward=0.033864498138427734\n",
      "global_step=22680, episodic_return=52.0, surprise_reward=0.02796170860528946\n",
      "global_step=22704, episodic_return=44.0, surprise_reward=0.041470661759376526\n",
      "global_step=22808, episodic_return=48.0, surprise_reward=0.02366955764591694\n",
      "global_step=22824, episodic_return=130.0, surprise_reward=0.04531761258840561\n",
      "global_step=22888, episodic_return=23.0, surprise_reward=0.05839959532022476\n",
      "global_step=22888, episodic_return=42.0, surprise_reward=0.05839959532022476\n",
      "global_step=22896, episodic_return=27.0, surprise_reward=0.028346851468086243\n",
      "global_step=22896, episodic_return=187.0, surprise_reward=0.028346851468086243\n",
      "global_step=22928, episodic_return=71.0, surprise_reward=0.023955773562192917\n",
      "global_step=22936, episodic_return=76.0, surprise_reward=0.031192854046821594\n",
      "global_step=23056, episodic_return=21.0, surprise_reward=0.06110028550028801\n",
      "global_step=23120, episodic_return=37.0, surprise_reward=0.020709583535790443\n",
      "global_step=23208, episodic_return=50.0, surprise_reward=0.019240878522396088\n",
      "global_step=23224, episodic_return=36.0, surprise_reward=0.10408975183963776\n",
      "global_step=23272, episodic_return=48.0, surprise_reward=0.021155688911676407\n",
      "global_step=23288, episodic_return=45.0, surprise_reward=0.013235149905085564\n",
      "global_step=23368, episodic_return=31.0, surprise_reward=0.018337836489081383\n",
      "global_step=23424, episodic_return=46.0, surprise_reward=0.01722380891442299\n",
      "global_step=23464, episodic_return=71.0, surprise_reward=0.01659882254898548\n",
      "global_step=23488, episodic_return=74.0, surprise_reward=0.016582118347287178\n",
      "SPS: 99\n",
      "global_step=23712, episodic_return=63.0, surprise_reward=0.030916286632418633\n",
      "global_step=23736, episodic_return=39.0, surprise_reward=0.029971526935696602\n",
      "global_step=23768, episodic_return=60.0, surprise_reward=0.053774066269397736\n",
      "global_step=23896, episodic_return=84.0, surprise_reward=0.06701185554265976\n",
      "global_step=23928, episodic_return=20.0, surprise_reward=0.01762002892792225\n",
      "global_step=23992, episodic_return=32.0, surprise_reward=0.02830345183610916\n",
      "global_step=24008, episodic_return=65.0, surprise_reward=0.031069163233041763\n",
      "global_step=24016, episodic_return=81.0, surprise_reward=0.11926507949829102\n",
      "global_step=24096, episodic_return=13.0, surprise_reward=0.025241054594516754\n",
      "global_step=24144, episodic_return=54.0, surprise_reward=0.030921228229999542\n",
      "global_step=24160, episodic_return=111.0, surprise_reward=0.04555300623178482\n",
      "global_step=24240, episodic_return=18.0, surprise_reward=0.021230727434158325\n",
      "global_step=24248, episodic_return=29.0, surprise_reward=0.04133008420467377\n",
      "global_step=24272, episodic_return=47.0, surprise_reward=0.12979431450366974\n",
      "global_step=24272, episodic_return=16.0, surprise_reward=0.12979431450366974\n",
      "global_step=24336, episodic_return=51.0, surprise_reward=0.039230212569236755\n",
      "global_step=24464, episodic_return=57.0, surprise_reward=0.08963469415903091\n",
      "global_step=24528, episodic_return=133.0, surprise_reward=0.02673138678073883\n",
      "SPS: 97\n",
      "global_step=24872, episodic_return=89.0, surprise_reward=0.03475922718644142\n",
      "global_step=24888, episodic_return=45.0, surprise_reward=0.06953777372837067\n",
      "global_step=24888, episodic_return=77.0, surprise_reward=0.06953777372837067\n",
      "global_step=24952, episodic_return=85.0, surprise_reward=0.061690911650657654\n",
      "global_step=24992, episodic_return=15.0, surprise_reward=0.035673588514328\n",
      "global_step=25016, episodic_return=96.0, surprise_reward=0.08775049448013306\n",
      "global_step=25080, episodic_return=24.0, surprise_reward=0.042892180383205414\n",
      "global_step=25184, episodic_return=90.0, surprise_reward=0.022784950211644173\n",
      "global_step=25368, episodic_return=52.0, surprise_reward=0.058285877108573914\n",
      "global_step=25384, episodic_return=49.0, surprise_reward=0.07981713861227036\n",
      "global_step=25392, episodic_return=39.0, surprise_reward=0.1921747922897339\n",
      "global_step=25504, episodic_return=146.0, surprise_reward=0.05641799047589302\n",
      "global_step=25552, episodic_return=46.0, surprise_reward=0.06631757318973541\n",
      "SPS: 100\n",
      "global_step=25696, episodic_return=182.0, surprise_reward=0.035090766847133636\n",
      "global_step=25880, episodic_return=64.0, surprise_reward=0.048160966485738754\n",
      "global_step=25952, episodic_return=133.0, surprise_reward=0.18127372860908508\n",
      "global_step=25952, episodic_return=71.0, surprise_reward=0.18127372860908508\n",
      "global_step=25960, episodic_return=51.0, surprise_reward=0.027448203414678574\n",
      "global_step=25992, episodic_return=122.0, surprise_reward=0.037253476679325104\n",
      "global_step=26072, episodic_return=47.0, surprise_reward=0.033086903393268585\n",
      "global_step=26184, episodic_return=29.0, surprise_reward=0.03767099604010582\n",
      "global_step=26272, episodic_return=40.0, surprise_reward=0.022652791813015938\n",
      "global_step=26280, episodic_return=40.0, surprise_reward=0.023126613348722458\n",
      "global_step=26296, episodic_return=99.0, surprise_reward=0.016179662197828293\n",
      "global_step=26504, episodic_return=64.0, surprise_reward=0.047233447432518005\n",
      "global_step=26600, episodic_return=40.0, surprise_reward=0.03093877248466015\n",
      "SPS: 97\n",
      "global_step=26744, episodic_return=108.0, surprise_reward=0.02647722139954567\n",
      "global_step=26800, episodic_return=63.0, surprise_reward=0.09578334540128708\n",
      "global_step=26808, episodic_return=92.0, surprise_reward=0.048417799174785614\n",
      "global_step=27064, episodic_return=110.0, surprise_reward=0.051785144954919815\n",
      "global_step=27096, episodic_return=213.0, surprise_reward=0.1120697483420372\n",
      "global_step=27176, episodic_return=47.0, surprise_reward=0.04688116908073425\n",
      "global_step=27272, episodic_return=125.0, surprise_reward=0.15304093062877655\n",
      "global_step=27328, episodic_return=19.0, surprise_reward=0.15940476953983307\n",
      "global_step=27336, episodic_return=74.0, surprise_reward=0.055532120168209076\n",
      "global_step=27336, episodic_return=34.0, surprise_reward=0.055532120168209076\n",
      "global_step=27448, episodic_return=22.0, surprise_reward=0.02802443504333496\n",
      "global_step=27480, episodic_return=18.0, surprise_reward=0.011401512660086155\n",
      "global_step=27608, episodic_return=100.0, surprise_reward=0.02115049585700035\n",
      "global_step=27624, episodic_return=140.0, surprise_reward=0.1107703447341919\n",
      "SPS: 100\n",
      "global_step=27744, episodic_return=51.0, surprise_reward=0.016606099903583527\n",
      "global_step=27752, episodic_return=82.0, surprise_reward=0.06397078931331635\n",
      "global_step=27912, episodic_return=21.0, surprise_reward=0.02703862078487873\n",
      "global_step=27936, episodic_return=76.0, surprise_reward=0.02973797172307968\n",
      "global_step=27952, episodic_return=41.0, surprise_reward=0.018845872953534126\n",
      "global_step=28096, episodic_return=61.0, surprise_reward=0.036533236503601074\n",
      "global_step=28144, episodic_return=24.0, surprise_reward=0.02268638089299202\n",
      "global_step=28296, episodic_return=212.0, surprise_reward=0.0333690270781517\n",
      "global_step=28448, episodic_return=125.0, surprise_reward=0.13270117342472076\n",
      "global_step=28496, episodic_return=127.0, surprise_reward=0.018396781757473946\n",
      "global_step=28528, episodic_return=48.0, surprise_reward=0.014722838997840881\n",
      "global_step=28560, episodic_return=81.0, surprise_reward=0.05801841616630554\n",
      "global_step=28624, episodic_return=109.0, surprise_reward=0.030781488865613937\n",
      "SPS: 100\n",
      "global_step=28696, episodic_return=50.0, surprise_reward=0.03150301054120064\n",
      "global_step=28720, episodic_return=78.0, surprise_reward=0.01371507067233324\n",
      "global_step=28768, episodic_return=34.0, surprise_reward=0.05682289972901344\n",
      "global_step=28880, episodic_return=20.0, surprise_reward=0.016804393380880356\n",
      "global_step=28928, episodic_return=20.0, surprise_reward=0.020774902775883675\n",
      "global_step=28960, episodic_return=33.0, surprise_reward=0.03511989116668701\n",
      "global_step=29008, episodic_return=48.0, surprise_reward=0.03386833146214485\n",
      "global_step=29112, episodic_return=147.0, surprise_reward=0.23464985191822052\n",
      "global_step=29112, episodic_return=23.0, surprise_reward=0.23464985191822052\n",
      "global_step=29112, episodic_return=73.0, surprise_reward=0.23464985191822052\n",
      "global_step=29240, episodic_return=16.0, surprise_reward=0.019749734550714493\n",
      "global_step=29264, episodic_return=19.0, surprise_reward=0.018542643636465073\n",
      "global_step=29344, episodic_return=112.0, surprise_reward=0.09091141819953918\n",
      "global_step=29504, episodic_return=20.0, surprise_reward=0.16945040225982666\n",
      "global_step=29544, episodic_return=83.0, surprise_reward=0.028611138463020325\n",
      "global_step=29640, episodic_return=17.0, surprise_reward=0.05847102776169777\n",
      "SPS: 103\n",
      "global_step=29768, episodic_return=151.0, surprise_reward=0.16384874284267426\n",
      "global_step=29808, episodic_return=106.0, surprise_reward=0.042096372693777084\n",
      "global_step=29816, episodic_return=101.0, surprise_reward=0.08558832108974457\n",
      "global_step=29832, episodic_return=74.0, surprise_reward=0.06836006790399551\n",
      "global_step=29872, episodic_return=29.0, surprise_reward=0.02059132233262062\n",
      "global_step=29920, episodic_return=101.0, surprise_reward=0.12809763848781586\n",
      "global_step=29952, episodic_return=51.0, surprise_reward=0.014468994922935963\n",
      "global_step=30112, episodic_return=30.0, surprise_reward=0.018271436914801598\n",
      "global_step=30136, episodic_return=41.0, surprise_reward=0.04396510496735573\n",
      "global_step=30160, episodic_return=112.0, surprise_reward=0.13415853679180145\n",
      "global_step=30168, episodic_return=27.0, surprise_reward=0.033460814505815506\n",
      "global_step=30256, episodic_return=61.0, surprise_reward=0.0307760089635849\n",
      "SPS: 102\n",
      "global_step=30768, episodic_return=106.0, surprise_reward=0.3063507676124573\n",
      "global_step=30944, episodic_return=98.0, surprise_reward=0.17402516305446625\n",
      "global_step=30944, episodic_return=104.0, surprise_reward=0.17402516305446625\n",
      "global_step=31008, episodic_return=109.0, surprise_reward=0.012800736352801323\n",
      "global_step=31080, episodic_return=156.0, surprise_reward=0.040061354637145996\n",
      "global_step=31224, episodic_return=121.0, surprise_reward=0.03920425847172737\n",
      "global_step=31240, episodic_return=178.0, surprise_reward=0.049607448279857635\n",
      "global_step=31464, episodic_return=57.0, surprise_reward=0.014816184528172016\n",
      "global_step=31600, episodic_return=82.0, surprise_reward=0.03951592743396759\n",
      "global_step=31696, episodic_return=116.0, surprise_reward=0.046340182423591614\n",
      "global_step=31704, episodic_return=60.0, surprise_reward=0.05871696025133133\n",
      "SPS: 105\n",
      "global_step=31856, episodic_return=20.0, surprise_reward=0.02249838411808014\n",
      "global_step=31960, episodic_return=110.0, surprise_reward=0.045131832361221313\n",
      "global_step=32000, episodic_return=95.0, surprise_reward=0.030411742627620697\n",
      "global_step=32120, episodic_return=82.0, surprise_reward=0.07903896272182465\n",
      "global_step=32176, episodic_return=27.0, surprise_reward=0.02478460595011711\n",
      "global_step=32256, episodic_return=69.0, surprise_reward=0.06427305936813354\n",
      "global_step=32272, episodic_return=34.0, surprise_reward=0.045846208930015564\n",
      "global_step=32360, episodic_return=63.0, surprise_reward=0.03082835115492344\n",
      "global_step=32408, episodic_return=183.0, surprise_reward=0.15944355726242065\n",
      "global_step=32736, episodic_return=77.0, surprise_reward=0.0632883608341217\n",
      "global_step=32768, episodic_return=325.0, surprise_reward=0.09335359185934067\n",
      "SPS: 104\n",
      "global_step=32776, episodic_return=46.0, surprise_reward=0.03450290486216545\n",
      "global_step=32992, episodic_return=27.0, surprise_reward=0.021557267755270004\n",
      "global_step=33088, episodic_return=114.0, surprise_reward=0.0573975145816803\n",
      "global_step=33224, episodic_return=203.0, surprise_reward=0.1553407609462738\n",
      "global_step=33224, episodic_return=119.0, surprise_reward=0.1553407609462738\n",
      "global_step=33344, episodic_return=32.0, surprise_reward=0.022061731666326523\n",
      "global_step=33376, episodic_return=127.0, surprise_reward=0.07652802020311356\n",
      "global_step=33560, episodic_return=99.0, surprise_reward=0.025418363511562347\n",
      "global_step=33696, episodic_return=88.0, surprise_reward=0.4230055510997772\n",
      "global_step=33728, episodic_return=63.0, surprise_reward=0.12903974950313568\n",
      "global_step=33728, episodic_return=124.0, surprise_reward=0.12903974950313568\n",
      "global_step=33776, episodic_return=190.0, surprise_reward=0.013287749141454697\n",
      "SPS: 107\n",
      "global_step=33856, episodic_return=79.0, surprise_reward=0.04201486334204674\n",
      "global_step=34008, episodic_return=39.0, surprise_reward=0.02928353287279606\n",
      "global_step=34096, episodic_return=90.0, surprise_reward=0.1365671157836914\n",
      "global_step=34288, episodic_return=64.0, surprise_reward=0.08427590131759644\n",
      "global_step=34424, episodic_return=52.0, surprise_reward=0.022385481745004654\n",
      "global_step=34464, episodic_return=22.0, surprise_reward=0.020280776545405388\n",
      "global_step=34552, episodic_return=103.0, surprise_reward=0.021607238799333572\n",
      "global_step=34640, episodic_return=114.0, surprise_reward=0.048701170831918716\n",
      "global_step=34648, episodic_return=99.0, surprise_reward=0.18008588254451752\n",
      "SPS: 104\n",
      "global_step=34824, episodic_return=45.0, surprise_reward=0.03555544838309288\n",
      "global_step=34848, episodic_return=94.0, surprise_reward=0.021547310054302216\n",
      "global_step=34904, episodic_return=168.0, surprise_reward=0.0726732686161995\n",
      "global_step=35040, episodic_return=212.0, surprise_reward=0.383451372385025\n",
      "global_step=35104, episodic_return=69.0, surprise_reward=0.03377359360456467\n",
      "global_step=35120, episodic_return=60.0, surprise_reward=0.038763031363487244\n",
      "global_step=35408, episodic_return=36.0, surprise_reward=0.1340387463569641\n",
      "global_step=35424, episodic_return=75.0, surprise_reward=0.037607207894325256\n",
      "global_step=35472, episodic_return=54.0, surprise_reward=0.0973920226097107\n",
      "global_step=35472, episodic_return=103.0, surprise_reward=0.0973920226097107\n",
      "global_step=35720, episodic_return=162.0, surprise_reward=0.04020790010690689\n",
      "global_step=35744, episodic_return=105.0, surprise_reward=0.028053905814886093\n",
      "global_step=35808, episodic_return=48.0, surprise_reward=0.03783927857875824\n",
      "SPS: 107\n",
      "global_step=35960, episodic_return=139.0, surprise_reward=0.09829545766115189\n",
      "global_step=35984, episodic_return=30.0, surprise_reward=0.010441654361784458\n",
      "global_step=36176, episodic_return=88.0, surprise_reward=0.022732503712177277\n",
      "global_step=36208, episodic_return=61.0, surprise_reward=0.08991986513137817\n",
      "global_step=36208, episodic_return=92.0, surprise_reward=0.08991986513137817\n",
      "global_step=36240, episodic_return=142.0, surprise_reward=0.06003507226705551\n",
      "global_step=36384, episodic_return=122.0, surprise_reward=0.032764874398708344\n",
      "global_step=36400, episodic_return=55.0, surprise_reward=0.03374695032835007\n",
      "global_step=36472, episodic_return=33.0, surprise_reward=0.034833308309316635\n",
      "global_step=36520, episodic_return=67.0, surprise_reward=0.01826338842511177\n",
      "global_step=36696, episodic_return=65.0, surprise_reward=0.016181735321879387\n",
      "global_step=36840, episodic_return=79.0, surprise_reward=0.10017646104097366\n",
      "SPS: 106\n",
      "global_step=36984, episodic_return=36.0, surprise_reward=0.03252926841378212\n",
      "global_step=37168, episodic_return=87.0, surprise_reward=0.086647629737854\n",
      "global_step=37256, episodic_return=109.0, surprise_reward=0.043315283954143524\n",
      "global_step=37264, episodic_return=182.0, surprise_reward=0.2705579996109009\n",
      "global_step=37272, episodic_return=109.0, surprise_reward=0.067581906914711\n",
      "global_step=37520, episodic_return=85.0, surprise_reward=0.10271263867616653\n",
      "global_step=37544, episodic_return=128.0, surprise_reward=0.2526474595069885\n",
      "global_step=37576, episodic_return=51.0, surprise_reward=0.069607675075531\n",
      "global_step=37664, episodic_return=51.0, surprise_reward=0.027117423713207245\n",
      "global_step=37688, episodic_return=53.0, surprise_reward=0.02397746406495571\n",
      "global_step=37736, episodic_return=94.0, surprise_reward=0.1604582518339157\n",
      "global_step=37776, episodic_return=25.0, surprise_reward=0.01694277673959732\n",
      "global_step=37832, episodic_return=21.0, surprise_reward=0.031234314665198326\n",
      "SPS: 108\n",
      "global_step=37928, episodic_return=30.0, surprise_reward=0.022882850840687752\n",
      "global_step=38192, episodic_return=57.0, surprise_reward=0.04325789213180542\n",
      "global_step=38336, episodic_return=133.0, surprise_reward=0.3390004634857178\n",
      "global_step=38440, episodic_return=76.0, surprise_reward=0.0631820484995842\n",
      "global_step=38560, episodic_return=290.0, surprise_reward=0.07715670019388199\n",
      "global_step=38576, episodic_return=17.0, surprise_reward=0.1205545961856842\n",
      "global_step=38672, episodic_return=93.0, surprise_reward=0.039201103150844574\n",
      "global_step=38720, episodic_return=20.0, surprise_reward=0.013704386539757252\n",
      "global_step=38752, episodic_return=70.0, surprise_reward=0.02984478883445263\n",
      "global_step=38912, episodic_return=142.0, surprise_reward=0.29055511951446533\n",
      "global_step=38912, episodic_return=174.0, surprise_reward=0.29055511951446533\n",
      "SPS: 105\n",
      "global_step=39040, episodic_return=58.0, surprise_reward=0.04609563946723938\n",
      "global_step=39480, episodic_return=91.0, surprise_reward=0.2944372296333313\n",
      "global_step=39504, episodic_return=245.0, surprise_reward=0.17579714953899384\n",
      "global_step=39520, episodic_return=148.0, surprise_reward=0.08918312191963196\n",
      "global_step=39576, episodic_return=107.0, surprise_reward=0.05562218651175499\n",
      "global_step=39648, episodic_return=92.0, surprise_reward=0.10625504702329636\n",
      "global_step=39688, episodic_return=127.0, surprise_reward=0.14611241221427917\n",
      "global_step=39840, episodic_return=33.0, surprise_reward=0.040694016963243484\n",
      "global_step=39904, episodic_return=48.0, surprise_reward=0.018202781677246094\n",
      "SPS: 107\n",
      "global_step=40080, episodic_return=146.0, surprise_reward=0.1424456536769867\n",
      "global_step=40088, episodic_return=76.0, surprise_reward=0.12812848389148712\n",
      "global_step=40120, episodic_return=54.0, surprise_reward=0.04511626064777374\n",
      "global_step=40200, episodic_return=87.0, surprise_reward=0.12077377736568451\n",
      "global_step=40200, episodic_return=145.0, surprise_reward=0.12077377736568451\n",
      "global_step=40552, episodic_return=44.0, surprise_reward=0.020732469856739044\n",
      "global_step=40576, episodic_return=61.0, surprise_reward=0.012022929266095161\n",
      "global_step=40696, episodic_return=131.0, surprise_reward=0.2231547236442566\n",
      "global_step=40728, episodic_return=22.0, surprise_reward=0.012652368284761906\n",
      "global_step=40864, episodic_return=120.0, surprise_reward=0.12505985796451569\n",
      "SPS: 105\n",
      "global_step=41096, episodic_return=157.0, surprise_reward=0.06971575319766998\n",
      "global_step=41128, episodic_return=69.0, surprise_reward=0.07528331130743027\n",
      "global_step=41208, episodic_return=141.0, surprise_reward=0.02971530519425869\n",
      "global_step=41232, episodic_return=17.0, surprise_reward=0.030020620673894882\n",
      "global_step=41264, episodic_return=133.0, surprise_reward=0.28283581137657166\n",
      "global_step=41392, episodic_return=23.0, surprise_reward=0.012527750805020332\n",
      "global_step=41592, episodic_return=184.0, surprise_reward=0.06263288855552673\n",
      "global_step=41640, episodic_return=114.0, surprise_reward=0.09044241905212402\n",
      "global_step=41784, episodic_return=69.0, surprise_reward=0.04977960139513016\n",
      "global_step=41848, episodic_return=90.0, surprise_reward=0.14389872550964355\n",
      "SPS: 107\n",
      "global_step=42008, episodic_return=93.0, surprise_reward=0.04497930407524109\n",
      "global_step=42200, episodic_return=188.0, surprise_reward=0.060740627348423004\n",
      "global_step=42480, episodic_return=202.0, surprise_reward=0.15099698305130005\n",
      "global_step=42576, episodic_return=99.0, surprise_reward=0.25937318801879883\n",
      "global_step=42624, episodic_return=97.0, surprise_reward=0.05182372033596039\n",
      "global_step=42752, episodic_return=93.0, surprise_reward=0.3012172281742096\n",
      "global_step=42760, episodic_return=171.0, surprise_reward=0.07394973933696747\n",
      "global_step=42784, episodic_return=73.0, surprise_reward=0.016552137210965157\n",
      "SPS: 106\n",
      "global_step=43040, episodic_return=181.0, surprise_reward=0.2148950845003128\n",
      "global_step=43080, episodic_return=57.0, surprise_reward=0.06586791574954987\n",
      "global_step=43080, episodic_return=75.0, surprise_reward=0.06586791574954987\n",
      "global_step=43120, episodic_return=185.0, surprise_reward=0.17678478360176086\n",
      "global_step=43160, episodic_return=47.0, surprise_reward=0.0715683326125145\n",
      "global_step=43216, episodic_return=58.0, surprise_reward=0.04976757615804672\n",
      "global_step=43224, episodic_return=23.0, surprise_reward=0.009212086908519268\n",
      "global_step=43272, episodic_return=87.0, surprise_reward=0.04188985005021095\n",
      "global_step=43448, episodic_return=29.0, surprise_reward=0.019717302173376083\n",
      "global_step=43496, episodic_return=42.0, surprise_reward=0.013244163244962692\n",
      "global_step=43728, episodic_return=121.0, surprise_reward=0.031395427882671356\n",
      "global_step=43944, episodic_return=90.0, surprise_reward=0.2391316145658493\n",
      "SPS: 108\n",
      "global_step=44072, episodic_return=100.0, surprise_reward=0.2187625765800476\n",
      "global_step=44184, episodic_return=133.0, surprise_reward=0.26102694869041443\n",
      "global_step=44488, episodic_return=176.0, surprise_reward=0.013960405252873898\n",
      "global_step=44504, episodic_return=132.0, surprise_reward=0.02643452398478985\n",
      "global_step=44880, episodic_return=117.0, surprise_reward=0.3245922923088074\n",
      "global_step=44880, episodic_return=101.0, surprise_reward=0.3245922923088074\n",
      "global_step=44984, episodic_return=100.0, surprise_reward=0.02303292788565159\n",
      "SPS: 106\n",
      "global_step=45144, episodic_return=258.0, surprise_reward=0.14633296430110931\n",
      "global_step=45216, episodic_return=89.0, surprise_reward=0.056329935789108276\n",
      "global_step=45256, episodic_return=34.0, surprise_reward=0.03754580393433571\n",
      "global_step=45408, episodic_return=33.0, surprise_reward=0.025420915335416794\n",
      "global_step=45432, episodic_return=242.0, surprise_reward=0.2501845955848694\n",
      "global_step=45440, episodic_return=214.0, surprise_reward=0.30612292885780334\n",
      "global_step=45488, episodic_return=125.0, surprise_reward=0.13013778626918793\n",
      "global_step=45536, episodic_return=82.0, surprise_reward=0.04940999299287796\n",
      "global_step=45760, episodic_return=110.0, surprise_reward=0.09856880456209183\n",
      "SPS: 108\n",
      "global_step=46208, episodic_return=90.0, surprise_reward=0.07093804329633713\n",
      "global_step=46288, episodic_return=106.0, surprise_reward=0.08521731197834015\n",
      "global_step=46440, episodic_return=129.0, surprise_reward=0.0965302512049675\n",
      "global_step=46504, episodic_return=134.0, surprise_reward=0.13221585750579834\n",
      "global_step=46640, episodic_return=110.0, surprise_reward=0.07489796727895737\n",
      "global_step=46800, episodic_return=37.0, surprise_reward=0.07654660195112228\n",
      "global_step=46904, episodic_return=58.0, surprise_reward=0.07971247285604477\n",
      "global_step=46936, episodic_return=215.0, surprise_reward=0.10590832680463791\n",
      "global_step=47064, episodic_return=226.0, surprise_reward=0.22551555931568146\n",
      "SPS: 106\n",
      "global_step=47296, episodic_return=82.0, surprise_reward=0.03021996095776558\n",
      "global_step=47400, episodic_return=149.0, surprise_reward=0.39023667573928833\n",
      "global_step=47440, episodic_return=67.0, surprise_reward=0.020567413419485092\n",
      "global_step=47480, episodic_return=149.0, surprise_reward=0.013664756901562214\n",
      "global_step=47528, episodic_return=58.0, surprise_reward=0.02870161458849907\n",
      "global_step=47696, episodic_return=21.0, surprise_reward=0.15297773480415344\n",
      "global_step=47696, episodic_return=270.0, surprise_reward=0.15297773480415344\n",
      "global_step=47712, episodic_return=39.0, surprise_reward=0.036748919636011124\n",
      "SPS: 108\n",
      "global_step=48176, episodic_return=155.0, surprise_reward=0.0353374145925045\n",
      "global_step=48200, episodic_return=63.0, surprise_reward=0.02341116964817047\n",
      "global_step=48344, episodic_return=113.0, surprise_reward=0.05360471084713936\n",
      "global_step=48440, episodic_return=205.0, surprise_reward=0.018096858635544777\n",
      "global_step=48552, episodic_return=134.0, surprise_reward=0.07692311704158783\n",
      "global_step=48592, episodic_return=112.0, surprise_reward=0.36137163639068604\n",
      "global_step=48848, episodic_return=84.0, surprise_reward=0.028189275413751602\n",
      "global_step=48936, episodic_return=62.0, surprise_reward=0.040134720504283905\n",
      "SPS: 105\n",
      "global_step=49168, episodic_return=182.0, surprise_reward=0.30865001678466797\n",
      "global_step=49344, episodic_return=256.0, surprise_reward=0.6350496411323547\n",
      "global_step=49408, episodic_return=107.0, surprise_reward=0.16234788298606873\n",
      "global_step=49424, episodic_return=153.0, surprise_reward=0.07207795232534409\n",
      "global_step=49512, episodic_return=72.0, surprise_reward=0.01785651221871376\n",
      "global_step=49760, episodic_return=177.0, surprise_reward=0.40541136264801025\n",
      "global_step=49816, episodic_return=81.0, surprise_reward=0.019378796219825745\n",
      "global_step=49864, episodic_return=65.0, surprise_reward=0.20376692712306976\n",
      "global_step=49968, episodic_return=172.0, surprise_reward=0.07416575402021408\n",
      "SPS: 107\n",
      "global_step=50296, episodic_return=181.0, surprise_reward=0.051209188997745514\n",
      "global_step=50320, episodic_return=101.0, surprise_reward=0.058841243386268616\n",
      "global_step=50408, episodic_return=123.0, surprise_reward=0.23270642757415771\n",
      "global_step=50456, episodic_return=131.0, surprise_reward=0.2753743827342987\n",
      "global_step=50648, episodic_return=98.0, surprise_reward=0.028969038277864456\n",
      "global_step=50768, episodic_return=126.0, surprise_reward=0.0294780470430851\n",
      "global_step=51128, episodic_return=60.0, surprise_reward=0.014791809022426605\n",
      "SPS: 104\n",
      "global_step=51208, episodic_return=111.0, surprise_reward=0.10900868475437164\n",
      "global_step=51224, episodic_return=176.0, surprise_reward=0.023320907726883888\n",
      "global_step=51248, episodic_return=15.0, surprise_reward=0.12247893959283829\n",
      "global_step=51296, episodic_return=166.0, surprise_reward=0.09399966150522232\n",
      "global_step=51416, episodic_return=26.0, surprise_reward=0.01770133525133133\n",
      "global_step=51888, episodic_return=179.0, surprise_reward=0.2509855031967163\n",
      "global_step=51912, episodic_return=188.0, surprise_reward=0.2754908502101898\n",
      "global_step=52000, episodic_return=88.0, surprise_reward=0.13671711087226868\n",
      "global_step=52088, episodic_return=224.0, surprise_reward=0.06481403857469559\n",
      "SPS: 100\n",
      "global_step=52368, episodic_return=200.0, surprise_reward=0.46520712971687317\n",
      "global_step=52520, episodic_return=65.0, surprise_reward=0.11230934411287308\n",
      "global_step=52608, episodic_return=173.0, surprise_reward=0.4114789366722107\n",
      "global_step=52624, episodic_return=151.0, surprise_reward=0.2131071388721466\n",
      "global_step=52656, episodic_return=176.0, surprise_reward=0.1160888820886612\n",
      "global_step=52680, episodic_return=39.0, surprise_reward=0.008128732442855835\n",
      "global_step=52808, episodic_return=90.0, surprise_reward=0.029586363583803177\n",
      "global_step=52936, episodic_return=32.0, surprise_reward=0.012528173625469208\n",
      "global_step=53056, episodic_return=67.0, surprise_reward=0.013823329471051693\n",
      "global_step=53176, episodic_return=71.0, surprise_reward=0.0541476346552372\n",
      "SPS: 101\n",
      "global_step=53280, episodic_return=28.0, surprise_reward=0.21384818851947784\n",
      "global_step=53584, episodic_return=51.0, surprise_reward=0.02801872417330742\n",
      "global_step=53592, episodic_return=39.0, surprise_reward=0.02526809647679329\n",
      "global_step=53600, episodic_return=99.0, surprise_reward=0.23391908407211304\n",
      "global_step=53672, episodic_return=220.0, surprise_reward=0.02456100657582283\n",
      "global_step=53712, episodic_return=97.0, surprise_reward=0.04904375970363617\n",
      "global_step=53760, episodic_return=20.0, surprise_reward=0.014614728279411793\n",
      "global_step=54032, episodic_return=176.0, surprise_reward=0.06319934129714966\n",
      "global_step=54096, episodic_return=48.0, surprise_reward=0.014268722385168076\n",
      "global_step=54208, episodic_return=77.0, surprise_reward=0.06165706366300583\n",
      "SPS: 97\n",
      "global_step=54376, episodic_return=88.0, surprise_reward=0.02644910290837288\n",
      "global_step=54504, episodic_return=37.0, surprise_reward=0.020735902711749077\n",
      "global_step=54544, episodic_return=332.0, surprise_reward=0.1201123297214508\n",
      "global_step=54680, episodic_return=137.0, surprise_reward=0.3432796597480774\n",
      "global_step=54872, episodic_return=277.0, surprise_reward=0.14706091582775116\n",
      "global_step=55104, episodic_return=91.0, surprise_reward=0.018239472061395645\n",
      "SPS: 99\n",
      "global_step=55304, episodic_return=159.0, surprise_reward=0.23656123876571655\n",
      "global_step=55400, episodic_return=112.0, surprise_reward=0.2283344864845276\n",
      "global_step=55400, episodic_return=107.0, surprise_reward=0.2283344864845276\n",
      "global_step=55568, episodic_return=184.0, surprise_reward=0.020952189341187477\n",
      "global_step=55888, episodic_return=98.0, surprise_reward=0.5333273410797119\n",
      "global_step=55912, episodic_return=269.0, surprise_reward=0.03528711199760437\n",
      "global_step=55928, episodic_return=66.0, surprise_reward=0.28694698214530945\n",
      "global_step=55992, episodic_return=140.0, surprise_reward=0.6088040471076965\n",
      "global_step=56176, episodic_return=97.0, surprise_reward=0.026405349373817444\n",
      "global_step=56216, episodic_return=36.0, surprise_reward=0.03586985170841217\n",
      "global_step=56304, episodic_return=92.0, surprise_reward=0.04280669242143631\n",
      "SPS: 97\n",
      "global_step=56328, episodic_return=206.0, surprise_reward=0.12029647082090378\n",
      "global_step=56520, episodic_return=43.0, surprise_reward=0.011485941708087921\n",
      "global_step=56536, episodic_return=40.0, surprise_reward=0.07306275516748428\n",
      "global_step=56592, episodic_return=88.0, surprise_reward=0.014004584401845932\n",
      "global_step=56920, episodic_return=41.0, surprise_reward=0.03536102920770645\n",
      "global_step=56960, episodic_return=207.0, surprise_reward=0.3018636703491211\n",
      "global_step=57264, episodic_return=93.0, surprise_reward=0.020879337564110756\n",
      "SPS: 98\n",
      "global_step=57408, episodic_return=109.0, surprise_reward=0.028454158455133438\n",
      "global_step=57456, episodic_return=141.0, surprise_reward=0.2609042227268219\n",
      "global_step=57560, episodic_return=37.0, surprise_reward=0.050309233367443085\n",
      "global_step=57576, episodic_return=198.0, surprise_reward=0.274465948343277\n",
      "global_step=57632, episodic_return=215.0, surprise_reward=0.1675087809562683\n",
      "global_step=57656, episodic_return=169.0, surprise_reward=0.230032816529274\n",
      "global_step=57984, episodic_return=41.0, surprise_reward=0.020200904458761215\n",
      "global_step=58232, episodic_return=164.0, surprise_reward=0.051152657717466354\n",
      "global_step=58304, episodic_return=168.0, surprise_reward=0.05159590393304825\n",
      "global_step=58312, episodic_return=113.0, surprise_reward=0.11684253811836243\n",
      "SPS: 97\n",
      "global_step=58776, episodic_return=143.0, surprise_reward=0.020245587453246117\n",
      "global_step=59040, episodic_return=33.0, surprise_reward=0.030808230862021446\n",
      "global_step=59216, episodic_return=154.0, surprise_reward=0.1669178307056427\n",
      "SPS: 99\n",
      "global_step=59480, episodic_return=253.0, surprise_reward=0.23418663442134857\n",
      "global_step=59592, episodic_return=252.0, surprise_reward=0.18030624091625214\n",
      "global_step=59680, episodic_return=265.0, surprise_reward=0.27879998087882996\n",
      "global_step=59712, episodic_return=175.0, surprise_reward=0.3350682556629181\n",
      "global_step=59912, episodic_return=40.0, surprise_reward=0.02862040512263775\n",
      "global_step=59952, episodic_return=215.0, surprise_reward=0.3028043508529663\n",
      "global_step=60144, episodic_return=54.0, surprise_reward=0.018691744655370712\n",
      "global_step=60232, episodic_return=69.0, surprise_reward=0.01548772118985653\n",
      "SPS: 97\n",
      "global_step=60432, episodic_return=60.0, surprise_reward=0.12342770397663116\n",
      "global_step=60496, episodic_return=160.0, surprise_reward=0.17909972369670868\n",
      "global_step=60528, episodic_return=278.0, surprise_reward=0.05027356743812561\n",
      "global_step=60632, episodic_return=144.0, surprise_reward=0.07080978900194168\n",
      "global_step=60904, episodic_return=233.0, surprise_reward=0.034819915890693665\n",
      "global_step=60976, episodic_return=68.0, surprise_reward=0.07671801000833511\n",
      "global_step=61256, episodic_return=95.0, surprise_reward=0.19233305752277374\n",
      "global_step=61304, episodic_return=84.0, surprise_reward=0.052475038915872574\n",
      "global_step=61360, episodic_return=141.0, surprise_reward=0.079246886074543\n",
      "SPS: 98\n",
      "global_step=61632, episodic_return=138.0, surprise_reward=0.1686115711927414\n",
      "global_step=61752, episodic_return=230.0, surprise_reward=0.09283635020256042\n",
      "global_step=61768, episodic_return=64.0, surprise_reward=0.02219577506184578\n",
      "global_step=62000, episodic_return=87.0, surprise_reward=0.017475061118602753\n",
      "global_step=62112, episodic_return=60.0, surprise_reward=0.04334153234958649\n",
      "global_step=62240, episodic_return=158.0, surprise_reward=0.02127532660961151\n",
      "global_step=62296, episodic_return=117.0, surprise_reward=0.032756101340055466\n",
      "global_step=62456, episodic_return=289.0, surprise_reward=0.20684844255447388\n",
      "SPS: 97\n",
      "global_step=62760, episodic_return=124.0, surprise_reward=0.297156423330307\n",
      "global_step=62792, episodic_return=85.0, surprise_reward=0.04838915541768074\n",
      "global_step=62928, episodic_return=116.0, surprise_reward=0.029076946899294853\n",
      "global_step=63008, episodic_return=96.0, surprise_reward=0.028936589136719704\n",
      "global_step=63400, episodic_return=76.0, surprise_reward=0.07730323821306229\n",
      "global_step=63488, episodic_return=149.0, surprise_reward=0.06412921845912933\n",
      "SPS: 98\n",
      "global_step=63552, episodic_return=99.0, surprise_reward=0.028723742812871933\n",
      "global_step=63624, episodic_return=340.0, surprise_reward=0.07279235124588013\n",
      "global_step=63808, episodic_return=257.0, surprise_reward=0.13879534602165222\n",
      "global_step=63944, episodic_return=186.0, surprise_reward=0.029392501339316368\n",
      "global_step=64008, episodic_return=65.0, surprise_reward=0.00961258914321661\n",
      "global_step=64024, episodic_return=137.0, surprise_reward=0.1577005833387375\n",
      "global_step=64064, episodic_return=132.0, surprise_reward=0.05063043534755707\n",
      "global_step=64512, episodic_return=63.0, surprise_reward=0.022653527557849884\n",
      "SPS: 95\n",
      "global_step=64552, episodic_return=93.0, surprise_reward=0.08532527089118958\n",
      "global_step=64584, episodic_return=129.0, surprise_reward=0.019370561465620995\n",
      "global_step=65056, episodic_return=129.0, surprise_reward=0.4475313127040863\n",
      "global_step=65136, episodic_return=149.0, surprise_reward=0.11172648519277573\n",
      "global_step=65184, episodic_return=195.0, surprise_reward=0.4737143814563751\n",
      "global_step=65224, episodic_return=145.0, surprise_reward=0.30088669061660767\n",
      "global_step=65248, episodic_return=83.0, surprise_reward=0.025074508041143417\n",
      "global_step=65280, episodic_return=235.0, surprise_reward=0.2340952754020691\n",
      "SPS: 97\n",
      "global_step=65592, episodic_return=67.0, surprise_reward=0.09666793793439865\n",
      "global_step=65752, episodic_return=71.0, surprise_reward=0.14833641052246094\n",
      "global_step=65800, episodic_return=161.0, surprise_reward=0.4078018069267273\n",
      "global_step=65864, episodic_return=77.0, surprise_reward=0.03402239829301834\n",
      "global_step=65904, episodic_return=96.0, surprise_reward=0.022564318031072617\n",
      "global_step=66344, episodic_return=140.0, surprise_reward=0.02945440635085106\n",
      "global_step=66408, episodic_return=232.0, surprise_reward=0.0234840027987957\n",
      "global_step=66440, episodic_return=72.0, surprise_reward=0.030924556776881218\n",
      "global_step=66488, episodic_return=151.0, surprise_reward=0.11999358981847763\n",
      "SPS: 95\n",
      "global_step=66640, episodic_return=131.0, surprise_reward=0.08044701814651489\n",
      "global_step=67080, episodic_return=166.0, surprise_reward=0.013934257440268993\n",
      "global_step=67216, episodic_return=17.0, surprise_reward=0.03996244817972183\n",
      "global_step=67272, episodic_return=98.0, surprise_reward=0.07393016666173935\n",
      "global_step=67472, episodic_return=141.0, surprise_reward=0.44977396726608276\n",
      "global_step=67560, episodic_return=144.0, surprise_reward=0.11623779684305191\n",
      "SPS: 96\n",
      "global_step=67600, episodic_return=48.0, surprise_reward=0.0498422309756279\n",
      "global_step=67680, episodic_return=155.0, surprise_reward=0.4545639455318451\n",
      "global_step=67752, episodic_return=231.0, surprise_reward=0.025000914931297302\n",
      "global_step=68240, episodic_return=85.0, surprise_reward=0.03021872229874134\n",
      "global_step=68280, episodic_return=310.0, surprise_reward=0.02728745900094509\n",
      "SPS: 94\n",
      "global_step=68616, episodic_return=247.0, surprise_reward=0.31331324577331543\n",
      "global_step=68680, episodic_return=151.0, surprise_reward=0.23819546401500702\n",
      "global_step=68712, episodic_return=180.0, surprise_reward=0.07146470993757248\n",
      "global_step=68864, episodic_return=148.0, surprise_reward=0.16479602456092834\n",
      "global_step=68880, episodic_return=160.0, surprise_reward=0.18866854906082153\n",
      "global_step=69040, episodic_return=100.0, surprise_reward=0.015304438769817352\n",
      "global_step=69320, episodic_return=35.0, surprise_reward=0.019067654386162758\n",
      "global_step=69552, episodic_return=159.0, surprise_reward=0.21302711963653564\n",
      "global_step=69624, episodic_return=126.0, surprise_reward=0.10534824430942535\n",
      "SPS: 95\n",
      "global_step=69760, episodic_return=135.0, surprise_reward=0.2569063901901245\n",
      "global_step=69936, episodic_return=22.0, surprise_reward=0.02609882690012455\n",
      "global_step=69944, episodic_return=274.0, surprise_reward=0.08292404562234879\n",
      "global_step=70064, episodic_return=150.0, surprise_reward=0.16103318333625793\n",
      "global_step=70344, episodic_return=90.0, surprise_reward=0.035506561398506165\n",
      "global_step=70360, episodic_return=206.0, surprise_reward=0.14195731282234192\n",
      "global_step=70368, episodic_return=131.0, surprise_reward=0.5338419675827026\n",
      "global_step=70392, episodic_return=189.0, surprise_reward=0.06381964683532715\n",
      "SPS: 94\n",
      "global_step=70744, episodic_return=149.0, surprise_reward=0.35081011056900024\n",
      "global_step=71200, episodic_return=157.0, surprise_reward=0.19151043891906738\n",
      "global_step=71208, episodic_return=106.0, surprise_reward=0.09023226797580719\n",
      "global_step=71432, episodic_return=133.0, surprise_reward=0.13545309007167816\n",
      "global_step=71520, episodic_return=198.0, surprise_reward=0.2700008749961853\n",
      "SPS: 95\n",
      "global_step=71704, episodic_return=164.0, surprise_reward=0.04224193096160889\n",
      "global_step=71808, episodic_return=183.0, surprise_reward=0.036041732877492905\n",
      "global_step=71880, episodic_return=227.0, surprise_reward=0.13149181008338928\n",
      "global_step=72016, episodic_return=39.0, surprise_reward=0.02279851771891117\n",
      "global_step=72072, episodic_return=108.0, surprise_reward=0.012856392189860344\n",
      "global_step=72128, episodic_return=173.0, surprise_reward=0.18241477012634277\n",
      "global_step=72192, episodic_return=124.0, surprise_reward=0.3006937801837921\n",
      "global_step=72440, episodic_return=126.0, surprise_reward=0.038046471774578094\n",
      "global_step=72528, episodic_return=81.0, surprise_reward=0.04363935813307762\n",
      "global_step=72576, episodic_return=132.0, surprise_reward=0.22162853181362152\n",
      "global_step=72584, episodic_return=64.0, surprise_reward=0.14296892285346985\n",
      "SPS: 93\n",
      "global_step=72832, episodic_return=128.0, surprise_reward=0.30675727128982544\n",
      "global_step=72992, episodic_return=108.0, surprise_reward=0.33411192893981934\n",
      "global_step=73008, episodic_return=71.0, surprise_reward=0.037970684468746185\n",
      "global_step=73280, episodic_return=94.0, surprise_reward=0.048271868377923965\n",
      "global_step=73456, episodic_return=109.0, surprise_reward=0.0647716075181961\n",
      "global_step=73720, episodic_return=143.0, surprise_reward=0.11446555703878403\n",
      "SPS: 95\n",
      "global_step=73920, episodic_return=238.0, surprise_reward=0.11050938814878464\n",
      "global_step=73992, episodic_return=145.0, surprise_reward=0.02708355523645878\n",
      "global_step=74160, episodic_return=146.0, surprise_reward=0.04508140683174133\n",
      "global_step=74352, episodic_return=168.0, surprise_reward=0.05939169600605965\n",
      "global_step=74408, episodic_return=31.0, surprise_reward=0.03839883580803871\n",
      "global_step=74488, episodic_return=287.0, surprise_reward=0.518291175365448\n",
      "global_step=74584, episodic_return=108.0, surprise_reward=0.22111478447914124\n",
      "SPS: 93\n",
      "global_step=74800, episodic_return=110.0, surprise_reward=0.032855067402124405\n",
      "global_step=74896, episodic_return=180.0, surprise_reward=0.05267951637506485\n",
      "global_step=75032, episodic_return=130.0, surprise_reward=0.09917034208774567\n",
      "global_step=75064, episodic_return=223.0, surprise_reward=0.04169195145368576\n",
      "global_step=75088, episodic_return=63.0, surprise_reward=0.020546890795230865\n",
      "global_step=75320, episodic_return=121.0, surprise_reward=0.012327700853347778\n",
      "global_step=75536, episodic_return=63.0, surprise_reward=0.021692901849746704\n",
      "global_step=75680, episodic_return=110.0, surprise_reward=0.07551103830337524\n",
      "global_step=75704, episodic_return=152.0, surprise_reward=0.04050365090370178\n",
      "SPS: 94\n",
      "global_step=75904, episodic_return=187.0, surprise_reward=0.22715915739536285\n",
      "global_step=75944, episodic_return=107.0, surprise_reward=0.08301322907209396\n",
      "global_step=75984, episodic_return=136.0, surprise_reward=0.38725289702415466\n",
      "global_step=76152, episodic_return=56.0, surprise_reward=0.012129178270697594\n",
      "global_step=76160, episodic_return=137.0, surprise_reward=0.4387817680835724\n",
      "global_step=76688, episodic_return=66.0, surprise_reward=0.09290943294763565\n",
      "global_step=76776, episodic_return=78.0, surprise_reward=0.18848204612731934\n",
      "global_step=76792, episodic_return=157.0, surprise_reward=0.12285920977592468\n",
      "SPS: 93\n",
      "global_step=76896, episodic_return=152.0, surprise_reward=0.5271286368370056\n",
      "global_step=77112, episodic_return=146.0, surprise_reward=0.07488947361707687\n",
      "global_step=77440, episodic_return=68.0, surprise_reward=0.07462437450885773\n",
      "global_step=77584, episodic_return=210.0, surprise_reward=0.09468553960323334\n",
      "global_step=77648, episodic_return=67.0, surprise_reward=0.018857019022107124\n",
      "global_step=77784, episodic_return=225.0, surprise_reward=0.2132449895143509\n",
      "SPS: 94\n",
      "global_step=77968, episodic_return=160.0, surprise_reward=0.25465723872184753\n",
      "global_step=77984, episodic_return=149.0, surprise_reward=0.03803853318095207\n",
      "global_step=78192, episodic_return=94.0, surprise_reward=0.37773188948631287\n",
      "global_step=78368, episodic_return=73.0, surprise_reward=0.09076755493879318\n",
      "global_step=78416, episodic_return=104.0, surprise_reward=0.03334258496761322\n",
      "global_step=78480, episodic_return=104.0, surprise_reward=0.20894023776054382\n",
      "global_step=78552, episodic_return=404.0, surprise_reward=0.5696629881858826\n",
      "global_step=78712, episodic_return=242.0, surprise_reward=0.2268841713666916\n",
      "SPS: 93\n",
      "global_step=78920, episodic_return=119.0, surprise_reward=0.04042349010705948\n",
      "global_step=78952, episodic_return=67.0, surprise_reward=0.01562357135117054\n",
      "global_step=79256, episodic_return=97.0, surprise_reward=0.2711399495601654\n",
      "global_step=79456, episodic_return=113.0, surprise_reward=0.05233972147107124\n",
      "global_step=79480, episodic_return=139.0, surprise_reward=0.0716942548751831\n",
      "global_step=79600, episodic_return=176.0, surprise_reward=0.304364949464798\n",
      "global_step=79704, episodic_return=98.0, surprise_reward=0.09157560765743256\n",
      "SPS: 94\n",
      "global_step=80024, episodic_return=134.0, surprise_reward=0.24245619773864746\n",
      "global_step=80032, episodic_return=69.0, surprise_reward=0.016372909769415855\n",
      "global_step=80232, episodic_return=190.0, surprise_reward=0.08445265144109726\n",
      "global_step=80464, episodic_return=151.0, surprise_reward=0.5723243951797485\n",
      "global_step=80512, episodic_return=132.0, surprise_reward=0.20866182446479797\n",
      "global_step=80600, episodic_return=327.0, surprise_reward=0.330752432346344\n",
      "global_step=80752, episodic_return=90.0, surprise_reward=0.16922010481357574\n",
      "SPS: 93\n",
      "global_step=81040, episodic_return=127.0, surprise_reward=0.12288247048854828\n",
      "global_step=81216, episodic_return=202.0, surprise_reward=0.22986622154712677\n",
      "global_step=81248, episodic_return=127.0, surprise_reward=0.024362243711948395\n",
      "global_step=81328, episodic_return=108.0, surprise_reward=0.5974422693252563\n",
      "global_step=81424, episodic_return=103.0, surprise_reward=0.037546899169683456\n",
      "global_step=81496, episodic_return=123.0, surprise_reward=0.24293434619903564\n",
      "global_step=81760, episodic_return=90.0, surprise_reward=0.15192046761512756\n",
      "SPS: 94\n",
      "global_step=81936, episodic_return=76.0, surprise_reward=0.01437627337872982\n",
      "global_step=81960, episodic_return=282.0, surprise_reward=0.24164170026779175\n",
      "global_step=81976, episodic_return=69.0, surprise_reward=0.013958767987787724\n",
      "global_step=82088, episodic_return=167.0, surprise_reward=0.2597077786922455\n",
      "global_step=82272, episodic_return=132.0, surprise_reward=0.23998305201530457\n",
      "global_step=82624, episodic_return=172.0, surprise_reward=0.10698628425598145\n",
      "global_step=82728, episodic_return=154.0, surprise_reward=0.05314749851822853\n",
      "global_step=82904, episodic_return=102.0, surprise_reward=0.15200665593147278\n",
      "SPS: 92\n",
      "global_step=83000, episodic_return=133.0, surprise_reward=0.37263941764831543\n",
      "global_step=83040, episodic_return=135.0, surprise_reward=0.36230263113975525\n",
      "global_step=83272, episodic_return=189.0, surprise_reward=0.2248408943414688\n",
      "global_step=83368, episodic_return=137.0, surprise_reward=0.17657440900802612\n",
      "global_step=83712, episodic_return=89.0, surprise_reward=0.31545040011405945\n",
      "global_step=83888, episodic_return=239.0, surprise_reward=0.24998527765274048\n",
      "SPS: 93\n",
      "global_step=84000, episodic_return=137.0, surprise_reward=0.2431916892528534\n",
      "global_step=84016, episodic_return=38.0, surprise_reward=0.013525713235139847\n",
      "global_step=84056, episodic_return=86.0, surprise_reward=0.05756711587309837\n",
      "global_step=84120, episodic_return=135.0, surprise_reward=0.3005255460739136\n",
      "global_step=84176, episodic_return=194.0, surprise_reward=0.06446884572505951\n",
      "global_step=84240, episodic_return=189.0, surprise_reward=0.048190001398324966\n",
      "global_step=84560, episodic_return=70.0, surprise_reward=0.01756107434630394\n",
      "global_step=84936, episodic_return=47.0, surprise_reward=0.0474381148815155\n",
      "SPS: 92\n",
      "global_step=85128, episodic_return=134.0, surprise_reward=0.10483556985855103\n",
      "global_step=85200, episodic_return=33.0, surprise_reward=0.018971508368849754\n",
      "global_step=85304, episodic_return=148.0, surprise_reward=0.2098265439271927\n",
      "global_step=85528, episodic_return=169.0, surprise_reward=0.37537097930908203\n",
      "global_step=85544, episodic_return=191.0, surprise_reward=0.10139348357915878\n",
      "global_step=85792, episodic_return=315.0, surprise_reward=0.22605249285697937\n",
      "global_step=85808, episodic_return=33.0, surprise_reward=0.01580464094877243\n",
      "SPS: 93\n",
      "global_step=86280, episodic_return=255.0, surprise_reward=0.07181154191493988\n",
      "global_step=86424, episodic_return=153.0, surprise_reward=0.5694655776023865\n",
      "global_step=86680, episodic_return=50.0, surprise_reward=0.027268044650554657\n",
      "global_step=86696, episodic_return=196.0, surprise_reward=0.33122292160987854\n",
      "global_step=86984, episodic_return=147.0, surprise_reward=0.16249389946460724\n",
      "SPS: 92\n",
      "global_step=87184, episodic_return=63.0, surprise_reward=0.02360623888671398\n",
      "global_step=87360, episodic_return=434.0, surprise_reward=0.03996710479259491\n",
      "global_step=87432, episodic_return=126.0, surprise_reward=0.051953982561826706\n",
      "global_step=87584, episodic_return=75.0, surprise_reward=0.11089882999658585\n",
      "global_step=87680, episodic_return=123.0, surprise_reward=0.22949109971523285\n",
      "global_step=87896, episodic_return=296.0, surprise_reward=0.10120037943124771\n",
      "global_step=88032, episodic_return=84.0, surprise_reward=0.14802534878253937\n",
      "global_step=88032, episodic_return=17.0, surprise_reward=0.14802534878253937\n",
      "SPS: 93\n",
      "global_step=88184, episodic_return=360.0, surprise_reward=0.0570542998611927\n",
      "global_step=88224, episodic_return=24.0, surprise_reward=0.029510904103517532\n",
      "global_step=88240, episodic_return=306.0, surprise_reward=0.301920086145401\n",
      "global_step=88440, episodic_return=126.0, surprise_reward=0.16636624932289124\n",
      "global_step=88672, episodic_return=80.0, surprise_reward=0.030423838645219803\n",
      "global_step=88712, episodic_return=61.0, surprise_reward=0.025354020297527313\n",
      "global_step=88744, episodic_return=145.0, surprise_reward=0.290696382522583\n",
      "global_step=88840, episodic_return=207.0, surprise_reward=0.045637745410203934\n",
      "SPS: 92\n",
      "global_step=89640, episodic_return=182.0, surprise_reward=0.2075905203819275\n",
      "global_step=89704, episodic_return=183.0, surprise_reward=0.18340438604354858\n",
      "global_step=89712, episodic_return=125.0, surprise_reward=0.33202245831489563\n",
      "global_step=89808, episodic_return=142.0, surprise_reward=0.04133796691894531\n",
      "global_step=89904, episodic_return=183.0, surprise_reward=0.012468630447983742\n",
      "global_step=89984, episodic_return=288.0, surprise_reward=0.12617605924606323\n",
      "SPS: 93\n",
      "global_step=90224, episodic_return=173.0, surprise_reward=0.026172738522291183\n",
      "global_step=90424, episodic_return=90.0, surprise_reward=0.024698367342352867\n",
      "global_step=90432, episodic_return=66.0, surprise_reward=0.01435111090540886\n",
      "global_step=90768, episodic_return=68.0, surprise_reward=0.0312771312892437\n",
      "global_step=90832, episodic_return=106.0, surprise_reward=0.04367554932832718\n",
      "SPS: 91\n",
      "global_step=91144, episodic_return=89.0, surprise_reward=0.10687005519866943\n",
      "global_step=91168, episodic_return=42.0, surprise_reward=0.04030986502766609\n",
      "global_step=91320, episodic_return=69.0, surprise_reward=0.13395796716213226\n",
      "global_step=91400, episodic_return=332.0, surprise_reward=0.20219625532627106\n",
      "global_step=91400, episodic_return=220.0, surprise_reward=0.20219625532627106\n",
      "global_step=91536, episodic_return=17.0, surprise_reward=0.13880032300949097\n",
      "global_step=91664, episodic_return=232.0, surprise_reward=0.09024504572153091\n",
      "global_step=91712, episodic_return=250.0, surprise_reward=0.0707106739282608\n",
      "global_step=91928, episodic_return=76.0, surprise_reward=0.04014423117041588\n",
      "SPS: 92\n",
      "global_step=92184, episodic_return=220.0, surprise_reward=0.1942390501499176\n",
      "global_step=92280, episodic_return=77.0, surprise_reward=0.02825087495148182\n",
      "global_step=92320, episodic_return=49.0, surprise_reward=0.02077675238251686\n",
      "global_step=92376, episodic_return=151.0, surprise_reward=0.08176480233669281\n",
      "global_step=92432, episodic_return=129.0, surprise_reward=0.5186119079589844\n",
      "global_step=92544, episodic_return=175.0, surprise_reward=0.1286872774362564\n",
      "global_step=92904, episodic_return=78.0, surprise_reward=0.07318469136953354\n",
      "SPS: 91\n",
      "global_step=93192, episodic_return=95.0, surprise_reward=0.05120057612657547\n",
      "global_step=93208, episodic_return=104.0, surprise_reward=0.027670331299304962\n",
      "global_step=93448, episodic_return=217.0, surprise_reward=0.012154782190918922\n",
      "global_step=93776, episodic_return=73.0, surprise_reward=0.03199271857738495\n",
      "global_step=93808, episodic_return=186.0, surprise_reward=0.04098126292228699\n",
      "global_step=93880, episodic_return=122.0, surprise_reward=0.06558817625045776\n",
      "global_step=94040, episodic_return=74.0, surprise_reward=0.04600560665130615\n",
      "global_step=94128, episodic_return=198.0, surprise_reward=0.22849366068840027\n",
      "SPS: 92\n",
      "global_step=94256, episodic_return=131.0, surprise_reward=0.31685227155685425\n",
      "global_step=94280, episodic_return=262.0, surprise_reward=0.2118503600358963\n",
      "global_step=94512, episodic_return=372.0, surprise_reward=0.1621246337890625\n",
      "global_step=94968, episodic_return=136.0, surprise_reward=0.41264450550079346\n",
      "global_step=95024, episodic_return=152.0, surprise_reward=0.027216708287596703\n",
      "global_step=95192, episodic_return=117.0, surprise_reward=0.05823127180337906\n",
      "SPS: 91\n",
      "global_step=95256, episodic_return=185.0, surprise_reward=0.03141550347208977\n",
      "global_step=95648, episodic_return=78.0, surprise_reward=0.03878294676542282\n",
      "global_step=95712, episodic_return=179.0, surprise_reward=0.01319698616862297\n",
      "global_step=95776, episodic_return=217.0, surprise_reward=0.376067191362381\n",
      "global_step=95896, episodic_return=116.0, surprise_reward=0.23152534663677216\n",
      "SPS: 92\n",
      "global_step=96304, episodic_return=74.0, surprise_reward=0.01986764930188656\n",
      "global_step=96432, episodic_return=147.0, surprise_reward=0.38079386949539185\n",
      "global_step=96680, episodic_return=271.0, surprise_reward=0.07168334722518921\n",
      "global_step=96816, episodic_return=203.0, surprise_reward=0.049285031855106354\n",
      "global_step=96880, episodic_return=56.0, surprise_reward=0.0908179059624672\n",
      "global_step=97072, episodic_return=147.0, surprise_reward=0.0380282998085022\n",
      "SPS: 90\n",
      "global_step=97376, episodic_return=134.0, surprise_reward=0.04649003595113754\n",
      "global_step=97456, episodic_return=48.0, surprise_reward=0.04859647899866104\n",
      "global_step=97520, episodic_return=218.0, surprise_reward=0.19094586372375488\n",
      "global_step=97632, episodic_return=14.0, surprise_reward=0.1596771478652954\n",
      "global_step=97632, episodic_return=248.0, surprise_reward=0.1596771478652954\n",
      "global_step=97768, episodic_return=111.0, surprise_reward=0.4004185199737549\n",
      "global_step=97808, episodic_return=54.0, surprise_reward=0.012178843840956688\n",
      "global_step=97880, episodic_return=53.0, surprise_reward=0.023843463510274887\n",
      "global_step=97984, episodic_return=44.0, surprise_reward=0.01269887387752533\n",
      "global_step=98128, episodic_return=500.0, surprise_reward=0.03744055703282356\n",
      "global_step=98200, episodic_return=54.0, surprise_reward=0.01737113483250141\n",
      "global_step=98280, episodic_return=183.0, surprise_reward=0.07209452986717224\n",
      "SPS: 91\n",
      "global_step=98344, episodic_return=208.0, surprise_reward=0.17247720062732697\n",
      "global_step=98608, episodic_return=91.0, surprise_reward=0.1828453689813614\n",
      "global_step=98760, episodic_return=52.0, surprise_reward=0.05577866733074188\n",
      "global_step=98784, episodic_return=82.0, surprise_reward=0.053901370614767075\n",
      "global_step=98888, episodic_return=35.0, surprise_reward=0.013424379751086235\n",
      "global_step=99160, episodic_return=169.0, surprise_reward=0.18101255595684052\n",
      "global_step=99168, episodic_return=148.0, surprise_reward=0.254239946603775\n",
      "global_step=99312, episodic_return=53.0, surprise_reward=0.024043019860982895\n",
      "SPS: 90\n"
     ]
    }
   ],
   "source": [
    "batch_size = int(params[\"num_envs\"] * params[\"num_steps\"])                      # 4 * 128\n",
    "minibatch_size = int(batch_size // params[\"num_minibatches\"])\n",
    "num_iterations = params[\"total_timesteps\"] // batch_size                        # 20000000/(4*128) -> num iterations\n",
    "global_step = 0\n",
    "tracking_global_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "next_obs = torch.Tensor(envs.reset()[0]).to(device)\n",
    "next_done = torch.zeros(params[\"num_envs\"]).to(device)\n",
    "\n",
    "results_ICM = {\"global_step\":[],\n",
    "                \"return_value\":[],\n",
    "                \"intrinsic_reward\":[]}\n",
    "\n",
    "for iteration in range(1, num_iterations + 1):\n",
    "    actions = torch.zeros((params[\"num_steps\"], params[\"num_envs\"]) + envs.single_action_space.shape).to(device)   \n",
    "    logprobs = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "    rewards = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "    surprise_rewards = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "    dones = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "    ext_values = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "    int_values = torch.zeros((params[\"num_steps\"], params[\"num_envs\"])).to(device)\n",
    "\n",
    "    # Calculate the new learning rate as according to the annealing rate if needed.\n",
    "    if params[\"anneal_lr\"]:\n",
    "        updated_lr = (1.0 - (iteration - 1.0) / num_iterations) * params[\"learning_rate\"]\n",
    "        optimizer.param_groups[0][\"lr\"] = updated_lr\n",
    "\n",
    "    for step in range(0, params[\"num_steps\"]):\n",
    "        global_step += 1 * params[\"num_envs\"]\n",
    "        obs[step] = next_obs\n",
    "        dones[step] = next_done\n",
    "\n",
    "        with torch.no_grad():\n",
    "            action, logprob, _, value_ext, value_int = Agent.get_action_and_value(obs[step])\n",
    "        \n",
    "        ext_values[step], int_values[step] = (\n",
    "                value_ext.flatten(),\n",
    "                value_int.flatten(),\n",
    "            )       \n",
    "        actions[step] = action\n",
    "        logprobs[step] = logprob.flatten()        \n",
    "        next_obs, reward, terminated, truncated, info = envs.step(action.cpu().numpy())\n",
    "        done = np.logical_or(terminated, truncated)\n",
    "        rewards[step] = torch.tensor(reward).to(device).view(-1)\n",
    "        next_obs, next_done = torch.Tensor(next_obs).to(device), torch.Tensor(done).to(device)\n",
    "        # next_obs_b[step] = next_obs\n",
    "\n",
    "        icm_obs = obs[step]\n",
    "        icm_next_obs = next_obs\n",
    "        \n",
    "        surprise_rewards[step] = icm.compute_intrinsic_reward(icm_obs.to(device), icm_next_obs.to(device), actions[step].long())\n",
    "        \n",
    "        if \"final_info\" in info:\n",
    "            for info in info[\"final_info\"]:\n",
    "                if info and \"episode\" in info:\n",
    "                    print(\n",
    "                    f\"global_step={global_step}, episodic_return={info['episode']['r'][0]}, surprise_reward={np.mean(surprise_rewards[step].data.cpu().numpy())}\"\n",
    "                        )\n",
    "                    \n",
    "        if global_step - tracking_global_step > 2000:\n",
    "                return_eval = evaluate(params[\"env_id\"], Agent, use_int_rews=True)\n",
    "                results_ICM[\"global_step\"].append(global_step)\n",
    "                results_ICM[\"return_value\"].append(return_eval)\n",
    "                tracking_global_step = global_step\n",
    "            \n",
    "    obs[-1] = next_obs\n",
    "\n",
    "    # Calculate the discounted reward \n",
    "    surprise_reward_per_env = np.array(\n",
    "        [discounted_reward.update(reward_per_step) for reward_per_step in surprise_rewards.cpu().data.numpy().T]\n",
    "    )\n",
    "\n",
    "    mean, std, count = (\n",
    "        np.mean(surprise_reward_per_env),\n",
    "        np.std(surprise_reward_per_env),\n",
    "        len(surprise_reward_per_env),\n",
    "    )\n",
    "    \n",
    "    rew_runnning_mean_std.update_from_moments(mean, std**2, count)\n",
    "\n",
    "    # Normalize the curiousity_rewards based on the running_mean_std\n",
    "    surprise_rewards /= np.sqrt(rew_runnning_mean_std.var)\n",
    "\n",
    "    # Calculate value if not done\n",
    "    with torch.no_grad():\n",
    "        next_value_ext, next_value_int = Agent.get_value(next_obs)\n",
    "        next_value_ext, next_value_int = next_value_ext.reshape(1, -1), next_value_int.reshape(1, -1)   \n",
    "        ext_advantages = torch.zeros_like(rewards, device=device)\n",
    "        int_advantages = torch.zeros_like(surprise_rewards, device=device)\n",
    "        ext_lastgaelam = 0\n",
    "        int_lastgaelam = 0\n",
    "        for t in reversed(range(params[\"num_steps\"])):\n",
    "            if t == params[\"num_steps\"] - 1:\n",
    "                ext_nextnonterminal = 1.0 - next_done\n",
    "                int_nextnonterminal = 1.0\n",
    "                ext_nextvalues = next_value_ext\n",
    "                int_nextvalues = next_value_int\n",
    "            else:\n",
    "                ext_nextnonterminal = 1.0 - dones[t + 1]\n",
    "                int_nextnonterminal = 1.0\n",
    "                ext_nextvalues = ext_values[t + 1]\n",
    "                int_nextvalues = int_values[t + 1]\n",
    "            ext_delta = rewards[t] + params[\"gamma\"] * ext_nextvalues * ext_nextnonterminal - ext_values[t]\n",
    "            int_delta = surprise_rewards[t] + params[\"int_gamma\"] * int_nextvalues * int_nextnonterminal - int_values[t]\n",
    "            ext_advantages[t] = ext_lastgaelam = (\n",
    "                ext_delta + params[\"gamma\"] * params[\"gae_lambda\"] * ext_nextnonterminal * ext_lastgaelam\n",
    "            )\n",
    "            int_advantages[t] = int_lastgaelam = (\n",
    "                int_delta + params[\"int_gamma\"] * params[\"gae_lambda\"] * int_nextnonterminal * int_lastgaelam\n",
    "            )\n",
    "        ext_returns = ext_advantages + ext_values\n",
    "        int_returns = int_advantages + int_values\n",
    "    \n",
    "    # Collect batch data for optimization\n",
    "    b_obs = obs[:-1].reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_next_obs = obs[1:].reshape((-1,) + envs.single_observation_space.shape)\n",
    "    b_logprobs = logprobs.reshape(-1)\n",
    "    b_actions = actions.reshape(-1)\n",
    "    b_ext_advantages = ext_advantages.reshape(-1)\n",
    "    b_int_advantages = int_advantages.reshape(-1)\n",
    "    b_ext_returns = ext_returns.reshape(-1)\n",
    "    b_int_returns = int_returns.reshape(-1)\n",
    "    b_ext_values = ext_values.reshape(-1)\n",
    "\n",
    "    b_advantages = b_int_advantages * params[\"int_coef\"] + b_ext_advantages * params[\"ext_coef\"]\n",
    "\n",
    "    # Optimizing the policy and value network\n",
    "    b_inds = np.arange(batch_size)\n",
    "    icm_obs = b_obs\n",
    "    icm_next_obs = b_next_obs\n",
    "\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    forward_mse = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(params[\"update_epochs\"]):\n",
    "        np.random.shuffle(b_inds)\n",
    "        for start in range(0, batch_size, minibatch_size):\n",
    "            end = start + minibatch_size\n",
    "            mb_inds = b_inds[start:end]\n",
    "\n",
    "            real_next_state_feature, pred_next_state_feature, pred_action = icm.inference(icm_obs[mb_inds].to(device), icm_next_obs[mb_inds].to(device), b_actions[mb_inds])\n",
    "\n",
    "            inverse_loss = ce(\n",
    "                    pred_action, b_actions[mb_inds].long())\n",
    "\n",
    "            forward_loss = forward_mse(\n",
    "                    pred_next_state_feature, real_next_state_feature.detach())\n",
    "\n",
    "            _, newlogprob, entropy, new_ext_values, new_int_values = Agent.get_action_and_value(\n",
    "                b_obs[mb_inds], b_actions.long()[mb_inds]\n",
    "            )\n",
    "            \n",
    "            logratio = newlogprob - b_logprobs[mb_inds]\n",
    "            ratio = logratio.exp()\n",
    "\n",
    "            mb_advantages = b_advantages[mb_inds]\n",
    "            if params[\"norm_adv\"]:\n",
    "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
    "\n",
    "            # Policy loss\n",
    "            pg_loss1 = -mb_advantages * ratio\n",
    "            pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - params[\"clip_coef\"], 1 + params[\"clip_coef\"])\n",
    "            pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
    "\n",
    "            # Value loss\n",
    "            new_ext_values, new_int_values = new_ext_values.view(-1), new_int_values.view(-1)\n",
    "            if params[\"clip_vloss\"]:\n",
    "                ext_value_loss_unclipped = (new_ext_values - b_ext_returns[mb_inds]) ** 2\n",
    "                ext_v_clipped = b_ext_values[mb_inds] + torch.clamp(\n",
    "                    new_ext_values - b_ext_values[mb_inds],\n",
    "                    -params[\"clip_coef\"],\n",
    "                params[\"clip_coef\"],\n",
    "                )\n",
    "                ext_value_loss_clipped = (ext_v_clipped - b_ext_returns[mb_inds]) ** 2\n",
    "                ext_value_loss_max = torch.max(ext_value_loss_unclipped, ext_value_loss_clipped)\n",
    "                ext_value_loss = 0.5 * ext_value_loss_max.mean()\n",
    "            else:\n",
    "                ext_value_loss = 0.5 * ((new_ext_values - b_ext_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            int_value_loss = 0.5 * ((new_int_values - b_int_returns[mb_inds]) ** 2).mean()\n",
    "\n",
    "            value_loss = ext_value_loss + int_value_loss\n",
    "            entropy_loss = entropy.mean()\n",
    "\n",
    "            loss = pg_loss - params[\"ent_coef\"] * entropy_loss + value_loss * params[\"vf_coef\"] + forward_loss + inverse_loss\n",
    "        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if params[\"max_grad_norm\"]:\n",
    "                nn.utils.clip_grad_norm_(\n",
    "                    combined_parameters,\n",
    "                    params[\"max_grad_norm\"],\n",
    "                )\n",
    "            optimizer.step()\n",
    "\n",
    "    print(\"SPS:\", int(global_step / (time.time() - start_time)))\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Agent, \"pretrained_models/ppo_for_ICM.pth\")\n",
    "# torch.save(icm, \"pretrained_models/icm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from results_RND\n",
    "icm_global_step = results_ICM[\"global_step\"]\n",
    "icm_return_value = results_ICM[\"return_value\"]\n",
    "icm_intrinsic_reward = results_ICM[\"intrinsic_reward\"]\n",
    "\n",
    "df_icm = pd.DataFrame({'global_step': icm_global_step, 'return_value': icm_return_value})\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "df_icm.to_csv('data/results_icm.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Results Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_PPO = pd.read_csv('data/results_simple_ppo.csv')\n",
    "df_rnd = pd.read_csv('data/results_rnd.csv')\n",
    "df_icm = pd.read_csv('data/results_icm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_simple_PPO, df_rnd, df_icm]\n",
    "\n",
    "for df in dfs:\n",
    "    df[\"return_value_smoothed\"] = df[\"return_value\"].ewm(alpha=1-0.9).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "plt.plot(df_simple_PPO[\"global_step\"], df_simple_PPO[\"return_value_smoothed\"], label='Simple PPO')\n",
    "plt.plot(df_rnd[\"global_step\"], df_rnd[\"return_value_smoothed\"], label='RND')\n",
    "plt.plot(df_icm[\"global_step\"], df_icm[\"return_value_smoothed\"], label='ICM')\n",
    "plt.xlabel('Global Step')\n",
    "plt.ylabel('Return Value')\n",
    "plt.title('Return of 1 run  (Evaluate over 50 episodes)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
