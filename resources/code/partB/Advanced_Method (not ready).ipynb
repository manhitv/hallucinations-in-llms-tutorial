{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from stable_baselines3 import HerReplayBuffer, DDPG, DQN, SAC, TD3\n",
    "from stable_baselines3.her.goal_selection_strategy import GoalSelectionStrategy\n",
    "from gymnasium.core import Wrapper\n",
    "from callbacks.Eval_Callback import Eval_Callback\n",
    "\n",
    "random.seed(1)                                                 \n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/anaconda3/envs/causal_RL/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.compute_reward to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.compute_reward` for environment variables or `env.get_wrapper_attr('compute_reward')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -45      |\n",
      "|    success_rate    | 0.1      |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 500      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.89     |\n",
      "|    critic_loss     | 0.199    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 350      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -45      |\n",
      "|    success_rate    | 0.1      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 19       |\n",
      "|    time_elapsed    | 51       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.64     |\n",
      "|    critic_loss     | 0.0842   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 850      |\n",
      "---------------------------------\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 50         |\n",
      "|    ep_rew_mean     | -46.7      |\n",
      "|    success_rate    | 0.06666667 |\n",
      "| time/              |            |\n",
      "|    episodes        | 30         |\n",
      "|    fps             | 19         |\n",
      "|    time_elapsed    | 75         |\n",
      "|    total_timesteps | 1500       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.91       |\n",
      "|    critic_loss     | 0.189      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 1350       |\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 97       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.6      |\n",
      "|    critic_loss     | 0.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -46      |\n",
      "|    success_rate    | 0.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 120      |\n",
      "|    total_timesteps | 2500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.45     |\n",
      "|    critic_loss     | 0.192    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2350     |\n",
      "---------------------------------\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 50         |\n",
      "|    ep_rew_mean     | -46.7      |\n",
      "|    success_rate    | 0.06666667 |\n",
      "| time/              |            |\n",
      "|    episodes        | 60         |\n",
      "|    fps             | 20         |\n",
      "|    time_elapsed    | 143        |\n",
      "|    total_timesteps | 3000       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.74       |\n",
      "|    critic_loss     | 0.183      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 2850       |\n",
      "-----------------------------------\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 50          |\n",
      "|    ep_rew_mean     | -47.1       |\n",
      "|    success_rate    | 0.057142857 |\n",
      "| time/              |             |\n",
      "|    episodes        | 70          |\n",
      "|    fps             | 21          |\n",
      "|    time_elapsed    | 165         |\n",
      "|    total_timesteps | 3500        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 2.13        |\n",
      "|    critic_loss     | 0.3         |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3350        |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -46.2    |\n",
      "|    success_rate    | 0.075    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 189      |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.88     |\n",
      "|    critic_loss     | 0.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3850     |\n",
      "---------------------------------\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 50         |\n",
      "|    ep_rew_mean     | -46.7      |\n",
      "|    success_rate    | 0.06666667 |\n",
      "| time/              |            |\n",
      "|    episodes        | 90         |\n",
      "|    fps             | 21         |\n",
      "|    time_elapsed    | 212        |\n",
      "|    total_timesteps | 4500       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 2.43       |\n",
      "|    critic_loss     | 0.232      |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 4350       |\n",
      "-----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47      |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.09     |\n",
      "|    critic_loss     | 0.563    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47      |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 110      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 267      |\n",
      "|    total_timesteps | 5500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.83     |\n",
      "|    critic_loss     | 0.188    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47      |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 294      |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.58     |\n",
      "|    critic_loss     | 0.182    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -46.5    |\n",
      "|    success_rate    | 0.07     |\n",
      "| time/              |          |\n",
      "|    episodes        | 130      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 317      |\n",
      "|    total_timesteps | 6500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.05     |\n",
      "|    critic_loss     | 0.285    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -46.5    |\n",
      "|    success_rate    | 0.07     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.23     |\n",
      "|    critic_loss     | 0.403    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 150      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 364      |\n",
      "|    total_timesteps | 7500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.16     |\n",
      "|    critic_loss     | 0.291    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 387      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.6      |\n",
      "|    critic_loss     | 0.266    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 170      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 410      |\n",
      "|    total_timesteps | 8500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.07     |\n",
      "|    critic_loss     | 0.223    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.1      |\n",
      "|    critic_loss     | 0.177    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 190      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 457      |\n",
      "|    total_timesteps | 9500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.54     |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 480      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.84     |\n",
      "|    critic_loss     | 0.169    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 210      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 504      |\n",
      "|    total_timesteps | 10500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.28     |\n",
      "|    critic_loss     | 0.197    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -49      |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 20       |\n",
      "|    time_elapsed    | 527      |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.99     |\n",
      "|    critic_loss     | 0.166    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -49.5    |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 230      |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 546      |\n",
      "|    total_timesteps | 11500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.9      |\n",
      "|    critic_loss     | 9.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -49.5    |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 21       |\n",
      "|    time_elapsed    | 567      |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 8.52     |\n",
      "|    critic_loss     | 0.432    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11850    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env\u001b[38;5;241m=\u001b[39menv, tau\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.95\u001b[39m,   policy_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(n_critics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, net_arch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m]), replay_buffer_class\u001b[38;5;241m=\u001b[39mHerReplayBuffer, replay_buffer_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(n_sampled_goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, goal_selection_strategy\u001b[38;5;241m=\u001b[39mgoal_selection_strategy,),verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/ddpg/ddpg.py:123\u001b[0m, in \u001b[0;36mDDPG.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDDPG,\n\u001b[1;32m    116\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDDPG:\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:222\u001b[0m, in \u001b[0;36mTD3.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfTD3,\n\u001b[1;32m    215\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    221\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfTD3:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:331\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/td3/td3.py:202\u001b[0m, in \u001b[0;36mTD3.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    199\u001b[0m actor_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 202\u001b[0m \u001b[43mpolyak_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m polyak_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_target\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtau)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# Copy running stats, see GH issue #996\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/common/utils.py:469\u001b[0m, in \u001b[0;36mpolyak_update\u001b[0;34m(params, target_params, tau)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03mPerform a Polyak average update on ``target_params`` using ``params``:\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mtarget parameters are slowly updated towards the main parameters.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m:param tau: the soft update coefficient (\"Polyak update\", between 0 and 1)\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# zip does not raise an exception if length of parameters does not match.\u001b[39;00m\n\u001b[0;32m--> 469\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param, target_param \u001b[38;5;129;01min\u001b[39;00m zip_strict(params, target_params):\n\u001b[1;32m    470\u001b[0m         target_param\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m tau)\n\u001b[1;32m    471\u001b[0m         th\u001b[38;5;241m.\u001b[39madd(target_param\u001b[38;5;241m.\u001b[39mdata, param\u001b[38;5;241m.\u001b[39mdata, alpha\u001b[38;5;241m=\u001b[39mtau, out\u001b[38;5;241m=\u001b[39mtarget_param\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/anaconda3/envs/causal_RL/lib/python3.10/site-packages/stable_baselines3/common/utils.py:442\u001b[0m, in \u001b[0;36mzip_strict\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    440\u001b[0m sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m()\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m combo \u001b[38;5;129;01min\u001b[39;00m zip_longest(\u001b[38;5;241m*\u001b[39miterables, fillvalue\u001b[38;5;241m=\u001b[39msentinel):\n\u001b[0;32m--> 442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sentinel \u001b[38;5;129;01min\u001b[39;00m combo:\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterables have different lengths\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m combo\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FetchPickAndPlace-v2\", render_mode=\"rgb_array\")\n",
    "\n",
    "model_class = DDPG  # works also with SAC, DDPG and TD3\n",
    "\n",
    "eval_callback = Eval_Callback(eval_env=env, eval_freq=50000, n_eval_episodes=10)\n",
    "\n",
    "# Available strategies (cf paper): future, final, episode\n",
    "goal_selection_strategy = \"future\" # equivalent to GoalSelectionStrategy.FUTURE\n",
    "\n",
    "# Initialize the model\n",
    "model = model_class(\"MultiInputPolicy\", env=env, tau=0.05, batch_size=1024, learning_rate=0.001, gamma=0.95,   policy_kwargs=dict(n_critics=2, net_arch=[256, 256, 256]), replay_buffer_class=HerReplayBuffer, replay_buffer_kwargs=dict(n_sampled_goal=4, goal_selection_strategy=goal_selection_strategy,),verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=500000, log_interval=10, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)                # Initialize layer weights according to orthogonal method.\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)             # Set the bias of the layer.\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticModel(nn.Module):\n",
    "    def __init__(self, input_size, initial_var=1, min_var=1e-8, max_var=100,\n",
    "                 mean_scale=1, var_scale=1,\n",
    "                 use_spectral_norm_mean=False,\n",
    "                 use_spectral_norm_var=False):\n",
    "        super(ProbabilisticModel, self).__init__()\n",
    "\n",
    "        self.min_var = min_var\n",
    "        self.max_var = max_var\n",
    "        self.init_var_offset = np.log(np.exp(initial_var - min_var) - 1)\n",
    "\n",
    "        self.mean_scale = mean_scale\n",
    "        self.var_scale = var_scale\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            layer_init(nn.Linear(input_size, 256)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(256, 256)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(256, 256)))\n",
    "        \n",
    "        if use_spectral_norm_mean:\n",
    "            self.mean = nn.utils.spectral_norm(nn.Linear(256, 1))\n",
    "        else:\n",
    "            self.mean = nn.Linear(256, 3)\n",
    "\n",
    "        if use_spectral_norm_var:\n",
    "            self.var = nn.utils.spectral_norm(nn.Linear(256, 1))\n",
    "        else:\n",
    "            self.var = nn.Linear(256, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp(x)\n",
    "        mean = self.mean(x) * self.mean_scale\n",
    "        var = self.var(x) * self.var_scale\n",
    "\n",
    "        var = F.softplus(var + self.init_var_offset) + self.min_var\n",
    "        var = torch.clamp(var, self.min_var, self.max_var)                                                                  # Ensure std is positive\n",
    "        return mean, var\n",
    "    \n",
    "_LOG_2PI = math.log(2 * math.pi)\n",
    "\n",
    "# Define gaussian negative log likelihood\n",
    "def gaussian_log_likelihood_loss(pred, target, with_logvar=True,\n",
    "                                 fixed_variance=None, detach_mean=False,\n",
    "                                 detach_var=False):\n",
    "    mean = pred[0]\n",
    "    if detach_mean:\n",
    "        mean = mean.detach()\n",
    "\n",
    "    if with_logvar:\n",
    "        logvar = pred[1]\n",
    "        if detach_var:\n",
    "            logvar = logvar.detach()\n",
    "\n",
    "        if fixed_variance is not None:\n",
    "            logvar = torch.ones_like(mean) * math.log(fixed_variance)\n",
    "        ll = -0.5 * ((target - mean)**2 * (-logvar).exp() + logvar + _LOG_2PI)\n",
    "    else:\n",
    "        var = pred[1]\n",
    "        if detach_var:\n",
    "            var = var.detach()\n",
    "\n",
    "        if fixed_variance is not None:\n",
    "            var = torch.ones_like(mean) * fixed_variance\n",
    "        ll = -0.5 * ((target - mean)**2 / var + torch.log(var) + _LOG_2PI)\n",
    "\n",
    "    return -torch.sum(ll, axis=-1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIDWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.based_bonus = 0.001\n",
    "        self.eps = []\n",
    "                             \n",
    "        self.cid_model = ProbabilisticModel(input_size=29).to(device)\n",
    "        self.optimizer = optim.Adam(self.cid_model.parameters(), lr=1e-4)\n",
    "        self.criterion = gaussian_log_likelihood_loss\n",
    "        self.model_trained = False\n",
    "        self.batch_size = 500\n",
    "        self.step_retrained_model = 0    \n",
    "        self.tracking_step = 0   \n",
    "\n",
    "        self.history = deque(maxlen=50)\n",
    "        self.record_obs = None\n",
    "        self.lambda_params = 0.2\n",
    "        self.maximum_bonus = 10\n",
    "        self.K = 64\n",
    "\n",
    "    def kl_div(self, m1, v1, m2, v2):\n",
    "        \"\"\"KL divergence between two Gaussians\"\"\"\n",
    "        d = m1.shape[-1]\n",
    "        return (0.5 * (-d + ((v1 + (m2 - m1)**2) / v2 + torch.log(v2) - torch.log(v1)).sum(dim=-1)))\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.record_obs = obs[0]\n",
    "        return obs\n",
    "        \n",
    "    def step(self, action):\n",
    "        self.eps.append([self.record_obs,action])\n",
    "\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        self.record_obs = obs\n",
    " \n",
    "        if terminated or truncated: \n",
    "            self.history.append(self.eps.copy())\n",
    "            self.eps = []\n",
    "\n",
    "        # Train r_model\n",
    "        self.step_retrained_model += 1\n",
    "        self.tracking_step += 1\n",
    "        if self.step_retrained_model == 10000 and len(self.history) != 0:\n",
    "            X, y = self.create_training_data()\n",
    "            self.train_cid_model(X, y)\n",
    "            self.step_retrained_model = 0\n",
    "            self.model_trained = True\n",
    "\n",
    "        if self.model_trained:\n",
    "            bonus = 0\n",
    "\n",
    "            for k in range(self.K):\n",
    "                scoring_step = np.concatenate((obs[\"observation\"], action))\n",
    "                scoring_step_t = torch.tensor(scoring_step, dtype=torch.float32).to(device)\n",
    "                scoring_mean, scoring_var = self.cid_model(scoring_step_t)\n",
    "                scoring_mean, scoring_var = scoring_mean.detach(), scoring_var.detach()\n",
    "\n",
    "                sampled_actions = [np.random.uniform(low=-1.0, high=1.0, size=(4,)) for _ in range(10)]\n",
    "                sampled_obs_action = [np.concatenate((obs[\"observation\"], sampled_action)) for sampled_action in sampled_actions]\n",
    "                sampled_obs_action_t = [torch.tensor(obs_action, dtype=torch.float32).to(device) for obs_action in sampled_obs_action]\n",
    "                sampled_mean_var = [self.cid_model(obs_action_t) for obs_action_t in sampled_obs_action_t]\n",
    "                sampled_mean_var = [[mean_var[0].detach(), mean_var[1].detach()] for mean_var in sampled_mean_var]\n",
    "                mean_tensors = [mean_var[0] for mean_var in sampled_mean_var]\n",
    "                var_tensors = [mean_var[1] for mean_var in sampled_mean_var]\n",
    "                sampled_mean, sampled_var = torch.mean(torch.stack(mean_tensors)), torch.mean(torch.stack(var_tensors))\n",
    "\n",
    "                bonus += self.kl_div(scoring_mean, scoring_var, sampled_mean, sampled_var)\n",
    "            \n",
    "            bonus /= self.K\n",
    "            \n",
    "            if bonus > self.maximum_bonus:\n",
    "                bonus = self.maximum_bonus\n",
    "            \n",
    "            reward += bonus * self.lambda_params\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def create_training_data(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        for episode in self.history:\n",
    "            for i in range(len(episode)-1):\n",
    "                observation, action = episode[i][0][\"observation\"], episode[i][1]\n",
    "                input = np.concatenate((observation, action))\n",
    "                target = episode[i+1][0][\"achieved_goal\"] \n",
    "                X.append(input)\n",
    "                y.append(target)\n",
    "\n",
    "        return X, y\n",
    " \n",
    "\n",
    "    def train_cid_model(self, X, y):\n",
    "        if self.tracking_step <= 10000:\n",
    "            training_epochs = 100\n",
    "        elif 10000 < self.tracking_step <= 250000:\n",
    "            training_epochs = 50\n",
    "        elif 25000 < self.tracking_step <= 500000:\n",
    "            training_epochs = 20\n",
    "        else:\n",
    "            return\n",
    "        for _ in tqdm(range(training_epochs)):\n",
    "            shuffle_list = list(zip(X, y))\n",
    "            random.shuffle(shuffle_list)\n",
    "            X_shuffle, y_shuffle = zip(*shuffle_list)\n",
    "            for input_sequence, target_output in zip(X_shuffle[:self.batch_size], y_shuffle[:self.batch_size]):\n",
    "                input_sequence_t = torch.tensor(input_sequence, dtype=torch.float32).to(device)\n",
    "                target_output_t = torch.tensor(target_output, dtype=torch.float32).to(device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                mean, var = self.cid_model(input_sequence_t)\n",
    "                predict = [mean, var]\n",
    "                loss = self.criterion(predict, target_output_t)\n",
    "                # print(loss)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -50      |\n",
      "|    success_rate    | 0.0      |\n",
      "| time/              |          |\n",
      "|    episodes        | 10       |\n",
      "|    fps             | 43       |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 500      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.35     |\n",
      "|    critic_loss     | 0.158    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 350      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -50      |\n",
      "|    success_rate    | 0.0      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 37       |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 1000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.54     |\n",
      "|    critic_loss     | 0.148    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 850      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -50      |\n",
      "|    success_rate    | 0.0      |\n",
      "| time/              |          |\n",
      "|    episodes        | 30       |\n",
      "|    fps             | 36       |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 1500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.4      |\n",
      "|    critic_loss     | 0.135    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 35       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 2000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.71     |\n",
      "|    critic_loss     | 0.0967   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.1    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 50       |\n",
      "|    fps             | 34       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 2500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.81     |\n",
      "|    critic_loss     | 0.0567   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2350     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 50          |\n",
      "|    ep_rew_mean     | -47.6       |\n",
      "|    success_rate    | 0.033333335 |\n",
      "| time/              |             |\n",
      "|    episodes        | 60          |\n",
      "|    fps             | 34          |\n",
      "|    time_elapsed    | 87          |\n",
      "|    total_timesteps | 3000        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 6.81        |\n",
      "|    critic_loss     | 0.186       |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 2850        |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 50          |\n",
      "|    ep_rew_mean     | -47.9       |\n",
      "|    success_rate    | 0.028571429 |\n",
      "| time/              |             |\n",
      "|    episodes        | 70          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 103         |\n",
      "|    total_timesteps | 3500        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 10.7        |\n",
      "|    critic_loss     | 54.8        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 3350        |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.2    |\n",
      "|    success_rate    | 0.025    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 118      |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 10.4     |\n",
      "|    critic_loss     | 113      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3850     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/           |             |\n",
      "|    ep_len_mean     | 50          |\n",
      "|    ep_rew_mean     | -48.4       |\n",
      "|    success_rate    | 0.022222223 |\n",
      "| time/              |             |\n",
      "|    episodes        | 90          |\n",
      "|    fps             | 33          |\n",
      "|    time_elapsed    | 134         |\n",
      "|    total_timesteps | 4500        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 9.32        |\n",
      "|    critic_loss     | 1.79        |\n",
      "|    learning_rate   | 0.001       |\n",
      "|    n_updates       | 4350        |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 149      |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.86     |\n",
      "|    critic_loss     | 0.704    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48      |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 110      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 165      |\n",
      "|    total_timesteps | 5500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.97     |\n",
      "|    critic_loss     | 0.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.52     |\n",
      "|    critic_loss     | 0.356    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 130      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 6500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.77     |\n",
      "|    critic_loss     | 0.357    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 33       |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.15     |\n",
      "|    critic_loss     | 0.483    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -48.5    |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 150      |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 229      |\n",
      "|    total_timesteps | 7500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.65     |\n",
      "|    critic_loss     | 0.547    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.9    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 32       |\n",
      "|    time_elapsed    | 247      |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.44     |\n",
      "|    critic_loss     | 0.492    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 170      |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 8500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.94     |\n",
      "|    critic_loss     | 0.484    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8350     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 31       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.72     |\n",
      "|    critic_loss     | 0.559    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.5    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 190      |\n",
      "|    fps             | 30       |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 9500     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.02     |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9350     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:57<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -47.4    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 17       |\n",
      "|    time_elapsed    | 569      |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.34     |\n",
      "|    critic_loss     | 0.361    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9850     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -37.9    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 210      |\n",
      "|    fps             | 9        |\n",
      "|    time_elapsed    | 1088     |\n",
      "|    total_timesteps | 10500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 3.58     |\n",
      "|    critic_loss     | 0.375    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -27.9    |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 6        |\n",
      "|    time_elapsed    | 1611     |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 1.24     |\n",
      "|    critic_loss     | 0.411    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -17.4    |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 230      |\n",
      "|    fps             | 5        |\n",
      "|    time_elapsed    | 2132     |\n",
      "|    total_timesteps | 11500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.0989   |\n",
      "|    critic_loss     | 0.363    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | -6.94    |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 4        |\n",
      "|    time_elapsed    | 2655     |\n",
      "|    total_timesteps | 12000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.73    |\n",
      "|    critic_loss     | 0.347    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 2.56     |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 250      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 3177     |\n",
      "|    total_timesteps | 12500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.06    |\n",
      "|    critic_loss     | 0.308    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 12       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 3699     |\n",
      "|    total_timesteps | 13000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.29    |\n",
      "|    critic_loss     | 0.306    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 21.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 270      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 4159     |\n",
      "|    total_timesteps | 13500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.21    |\n",
      "|    critic_loss     | 0.256    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 3        |\n",
      "|    time_elapsed    | 4551     |\n",
      "|    total_timesteps | 14000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.55    |\n",
      "|    critic_loss     | 0.296    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 41.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 290      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 4943     |\n",
      "|    total_timesteps | 14500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.82    |\n",
      "|    critic_loss     | 0.299    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 5332     |\n",
      "|    total_timesteps | 15000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.43    |\n",
      "|    critic_loss     | 0.332    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 310      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 5727     |\n",
      "|    total_timesteps | 15500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.97    |\n",
      "|    critic_loss     | 0.234    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 6115     |\n",
      "|    total_timesteps | 16000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.48    |\n",
      "|    critic_loss     | 0.219    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 330      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 6504     |\n",
      "|    total_timesteps | 16500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.24    |\n",
      "|    critic_loss     | 0.364    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52.5     |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 6893     |\n",
      "|    total_timesteps | 17000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.36    |\n",
      "|    critic_loss     | 0.317    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52.5     |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 350      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 7248     |\n",
      "|    total_timesteps | 17500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.31    |\n",
      "|    critic_loss     | 0.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52.5     |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 7579     |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.76    |\n",
      "|    critic_loss     | 0.242    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53       |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 370      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 7907     |\n",
      "|    total_timesteps | 18500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.06    |\n",
      "|    critic_loss     | 0.217    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53       |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 8235     |\n",
      "|    total_timesteps | 19000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.42    |\n",
      "|    critic_loss     | 0.248    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53       |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 390      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 8564     |\n",
      "|    total_timesteps | 19500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.51    |\n",
      "|    critic_loss     | 0.25     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19350    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:21<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53       |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 8976     |\n",
      "|    total_timesteps | 20000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.18    |\n",
      "|    critic_loss     | 0.221    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53.5     |\n",
      "|    success_rate    | 0.07     |\n",
      "| time/              |          |\n",
      "|    episodes        | 410      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 9310     |\n",
      "|    total_timesteps | 20500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.21    |\n",
      "|    critic_loss     | 0.203    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 53       |\n",
      "|    success_rate    | 0.06     |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 9644     |\n",
      "|    total_timesteps | 21000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.12    |\n",
      "|    critic_loss     | 0.238    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 430      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 9977     |\n",
      "|    total_timesteps | 21500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.4     |\n",
      "|    critic_loss     | 0.183    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 10308    |\n",
      "|    total_timesteps | 22000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.619   |\n",
      "|    critic_loss     | 0.277    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 450      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 10643    |\n",
      "|    total_timesteps | 22500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.31    |\n",
      "|    critic_loss     | 0.196    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 10972    |\n",
      "|    total_timesteps | 23000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.88    |\n",
      "|    critic_loss     | 0.135    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 470      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 11300    |\n",
      "|    total_timesteps | 23500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.348   |\n",
      "|    critic_loss     | 0.175    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 11633    |\n",
      "|    total_timesteps | 24000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.65    |\n",
      "|    critic_loss     | 0.178    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 490      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 11964    |\n",
      "|    total_timesteps | 24500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.98    |\n",
      "|    critic_loss     | 0.173    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 12295    |\n",
      "|    total_timesteps | 25000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.11    |\n",
      "|    critic_loss     | 0.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 510      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 12626    |\n",
      "|    total_timesteps | 25500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.45    |\n",
      "|    critic_loss     | 0.152    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 2        |\n",
      "|    time_elapsed    | 12957    |\n",
      "|    total_timesteps | 26000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.08    |\n",
      "|    critic_loss     | 0.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 530      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 13288    |\n",
      "|    total_timesteps | 26500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.89    |\n",
      "|    critic_loss     | 0.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 13620    |\n",
      "|    total_timesteps | 27000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.93    |\n",
      "|    critic_loss     | 0.198    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 550      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 13952    |\n",
      "|    total_timesteps | 27500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.73    |\n",
      "|    critic_loss     | 0.15     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 14282    |\n",
      "|    total_timesteps | 28000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.44    |\n",
      "|    critic_loss     | 0.182    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 570      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 14612    |\n",
      "|    total_timesteps | 28500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.74    |\n",
      "|    critic_loss     | 0.216    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 14943    |\n",
      "|    total_timesteps | 29000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.45    |\n",
      "|    critic_loss     | 0.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 590      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 15275    |\n",
      "|    total_timesteps | 29500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.46    |\n",
      "|    critic_loss     | 0.344    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29350    |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:20<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 15686    |\n",
      "|    total_timesteps | 30000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.46    |\n",
      "|    critic_loss     | 0.289    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 610      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 16023    |\n",
      "|    total_timesteps | 30500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.65    |\n",
      "|    critic_loss     | 0.582    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 16362    |\n",
      "|    total_timesteps | 31000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.34    |\n",
      "|    critic_loss     | 2.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52       |\n",
      "|    success_rate    | 0.04     |\n",
      "| time/              |          |\n",
      "|    episodes        | 630      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 16696    |\n",
      "|    total_timesteps | 31500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.13    |\n",
      "|    critic_loss     | 0.2      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 17031    |\n",
      "|    total_timesteps | 32000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.49    |\n",
      "|    critic_loss     | 0.213    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 650      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 17369    |\n",
      "|    total_timesteps | 32500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.772    |\n",
      "|    critic_loss     | 0.256    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 17710    |\n",
      "|    total_timesteps | 33000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.14    |\n",
      "|    critic_loss     | 0.225    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 670      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 18045    |\n",
      "|    total_timesteps | 33500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.14    |\n",
      "|    critic_loss     | 0.207    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 18382    |\n",
      "|    total_timesteps | 34000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.42    |\n",
      "|    critic_loss     | 0.192    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 690      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 18721    |\n",
      "|    total_timesteps | 34500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.57    |\n",
      "|    critic_loss     | 0.208    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 50.5     |\n",
      "|    success_rate    | 0.01     |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 19063    |\n",
      "|    total_timesteps | 35000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.8     |\n",
      "|    critic_loss     | 0.167    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 710      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 19404    |\n",
      "|    total_timesteps | 35500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.66    |\n",
      "|    critic_loss     | 0.185    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 19745    |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.38    |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 730      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 20087    |\n",
      "|    total_timesteps | 36500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.97    |\n",
      "|    critic_loss     | 0.162    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 20567    |\n",
      "|    total_timesteps | 37000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.9     |\n",
      "|    critic_loss     | 0.139    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51       |\n",
      "|    success_rate    | 0.02     |\n",
      "| time/              |          |\n",
      "|    episodes        | 750      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 21046    |\n",
      "|    total_timesteps | 37500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.26    |\n",
      "|    critic_loss     | 0.159    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 21523    |\n",
      "|    total_timesteps | 38000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.56    |\n",
      "|    critic_loss     | 0.162    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 770      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 22002    |\n",
      "|    total_timesteps | 38500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.57    |\n",
      "|    critic_loss     | 12       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38350    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 51.5     |\n",
      "|    success_rate    | 0.03     |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 22481    |\n",
      "|    total_timesteps | 39000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.3     |\n",
      "|    critic_loss     | 0.273    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38850    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50       |\n",
      "|    ep_rew_mean     | 52.5     |\n",
      "|    success_rate    | 0.05     |\n",
      "| time/              |          |\n",
      "|    episodes        | 790      |\n",
      "|    fps             | 1        |\n",
      "|    time_elapsed    | 23118    |\n",
      "|    total_timesteps | 39500    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.43    |\n",
      "|    critic_loss     | 0.256    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39350    |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FetchPickAndPlace-v2\", render_mode=\"rgb_array\")\n",
    "train_env = CIDWrapper(env)\n",
    "\n",
    "model_class = DDPG  # works also with SAC, DDPG and TD3\n",
    "\n",
    "eval_callback = Eval_Callback(eval_env=env, eval_freq=50000, n_eval_episodes=10)\n",
    "\n",
    "# Available strategies (cf paper): future, final, episode\n",
    "goal_selection_strategy = \"future\" # equivalent to GoalSelectionStrategy.FUTURE\n",
    "\n",
    "# Initialize the model\n",
    "model = model_class(\"MultiInputPolicy\", env=train_env, tau=0.05, batch_size=1024, learning_rate=0.001, gamma=0.95,   policy_kwargs=dict(n_critics=2, net_arch=[256, 256, 256]), replay_buffer_class=HerReplayBuffer, replay_buffer_kwargs=dict(n_sampled_goal=4, goal_selection_strategy=goal_selection_strategy,),verbose=1)\n",
    "\n",
    "model.learn(total_timesteps=500000, log_interval=10, callback=eval_callback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
