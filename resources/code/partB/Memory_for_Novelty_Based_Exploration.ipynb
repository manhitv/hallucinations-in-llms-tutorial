{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<center>Notebook: Memory for Novelty Based Exploration</center>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**\n",
    "1. Savinov, N., Raichuk, A., Marinier, R., Vincent, D., Pollefeys, M., Lillicrap, T., & Gelly, S. (2018). Episodic curiosity through reachability. arXiv preprint arXiv:1810.02274.\n",
    "2. Tang, H., Houthooft, R., Foote, D., Stooke, A., Xi Chen, O., Duan, Y., ... & Abbeel, P. (2017). # exploration: A study of count-based exploration for deep reinforcement learning. Advances in neural information processing systems, 30.\n",
    "3. Raffin, A., Hill, A., Gleave, A., Kanervisto, A., Ernestus, M., & Dormann, N. (2021). Stable-baselines3: Reliable reinforcement learning implementations. Journal of Machine Learning Research, 22(268), 1-8.\n",
    "4. Chevalier-Boisvert, M., Dai, B., Towers, M., Perez-Vicente, R., Willems, L., Lahlou, S., ... & Terry, J. (2024). Minigrid & miniworld: Modular & customizable reinforcement learning environments for goal-oriented tasks. Advances in Neural Information Processing Systems, 36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Setting up the libraries** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run these commands from the terminal to install related libraries and set up the working environment\n",
    "# pip install gymnasium # Install the gymnasium library with RL environments\n",
    "# pip install minigrid # Install the Minigrid library contains simple and easily configurable grid world environments for RL. \n",
    "# pip install stable-baselines3 # Install the Stable Baselines 3 library contains RL Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries and check if they are working\n",
    "import random, copy\n",
    "from collections import deque\n",
    "\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "import minigrid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from gymnasium.core import Wrapper\n",
    "from minigrid.wrappers import ImgObsWrapper # Convert the observation space into an image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import get_policy_kwargs\n",
    "from callbacks.Eval_Callback import Eval_Callback\n",
    "\n",
    "# Set seed.\n",
    "np.random.seed(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Introducing the Minigrid Environment**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will start with the introduction of the Minigrid environments.\n",
    "- In this tutorial, we will use the empty 16x16 environment, wherein the task of the agent is to reach the goal (the green square). However, there are other environments with lower and higher levels of difficulty available in the Minigrid package  (https://minigrid.farama.org/). 🎮 They also allow customization to suit your needs. 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"MiniGrid-Empty-16x16-v0\", render_mode=\"rgb_array\")\n",
    "env = ImgObsWrapper(env)\n",
    "\n",
    "ob, _ = env.reset()\n",
    "img = env.render()\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Minigrid Environment Information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Minigrid environments, there are typically 7 actions available.\n",
    "- However, in this specific environment, we will only utilize the first 3 moving actions. 🚶‍♂️🚶‍♀️🚶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\" font-weight:bold;\">Action Space</span>\n",
    "| Num   | Name | Action |\n",
    "|--------|-----|--------|\n",
    "| 0  | left  | Turn left |\n",
    "| 1    | right  | Turn right  |\n",
    "| 2| forward | Move forward |\n",
    "| 3  | pickup  | Unused|\n",
    "| 4    | drop  | Unused  |\n",
    "| 5| toggle  | Unused|\n",
    "| 6| done  | Unused   |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(7)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space) # The action space includes 7 actions as stated above, however, the last action is not used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold;\">Observation Space</span>\n",
    "\n",
    "- Here we use the observation space, which is an image of shape (7,7,3).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (7, 7, 3), uint8)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight:bold;\">Reward</span>\n",
    "\n",
    "- The agent will be given a reward of $1 - 0.9 * (step\\_count / max\\_steps)$ is given for success, and $0$ for failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Simple PPO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we will test a simple PPO algorithm on this Minigrid environment. 🕹️\n",
    "- Here, we use the implementation of PPO from Stable Baselines 3. 📊\n",
    "- The result of this algorithm will be presented at the end of the notebook. 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.1 Train PPO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MiniGrid-Empty-16x16-v0\", render_mode=\"rgb_array\")\n",
    "env = ImgObsWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f770210ea10> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f7708f8ab90>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 97       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012271672 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -5.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    value_loss           | 1.11e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009193243 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -2.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00764     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 1.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008158363 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    value_loss           | 5.44e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012940778 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -1.86       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0423     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 2.12e-05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032790754 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -1.36       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000985    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 9.64e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013751088 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -4.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00103     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 4.94e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 956       |\n",
      "|    ep_rew_mean          | 0.124     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 68        |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 237       |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0288534 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.87     |\n",
      "|    explained_variance   | -5.31     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00196  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -0.0195   |\n",
      "|    value_loss           | 1.71e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 834        |\n",
      "|    ep_rew_mean          | 0.24       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 70         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 260        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01371859 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | 0.00881    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0313    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 0.00545    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 20000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01481979 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.85      |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.00885   |\n",
      "|    value_loss           | 0.00724    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 725      |\n",
      "|    ep_rew_mean     | 0.349    |\n",
      "| time/              |          |\n",
      "|    fps             | 58       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 658        |\n",
      "|    ep_rew_mean          | 0.41       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 369        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158176 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.81      |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.000328  |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00895   |\n",
      "|    value_loss           | 0.0101     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 570         |\n",
      "|    ep_rew_mean          | 0.49        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014216721 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -8.28e-05   |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 0.00747     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 472         |\n",
      "|    ep_rew_mean          | 0.578       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011146206 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | 0.65        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 435         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010265419 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00148    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 0.0157      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013961489 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0245      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 313      |\n",
      "|    ep_rew_mean     | 0.721    |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 519      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 132         |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273072 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.046      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.0254      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 85.3        |\n",
      "|    ep_rew_mean          | 0.925       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010768481 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 0.0194      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.2        |\n",
      "|    ep_rew_mean          | 0.941       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014198671 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0208      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.0161      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 54          |\n",
      "|    ep_rew_mean          | 0.953       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013427224 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.014       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082480665 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0125      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    value_loss           | 0.00917      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.9     |\n",
      "|    ep_rew_mean     | 0.962    |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 630      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 39.3        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009152861 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00634     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    value_loss           | 0.00716     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.7        |\n",
      "|    ep_rew_mean          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007134181 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    value_loss           | 0.00516     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | 0.97         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 696          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072884676 |\n",
      "|    clip_fraction        | 0.086        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0121       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    value_loss           | 0.00388      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.3         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 717          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057167867 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00704     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 0.00313      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 28         |\n",
      "|    mean_reward          | 0.975      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 50000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00487432 |\n",
      "|    clip_fraction        | 0.05       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.445     |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00218    |\n",
      "|    n_updates            | 240        |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    value_loss           | 0.00253    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.3     |\n",
      "|    ep_rew_mean     | 0.973    |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 740      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 51.2       |\n",
      "|    ep_rew_mean          | 0.953      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 69         |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 762        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.72022086 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.45      |\n",
      "|    explained_variance   | 0.617      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0134    |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | 0.0419     |\n",
      "|    value_loss           | 0.00304    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71          |\n",
      "|    ep_rew_mean          | 0.934       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 785         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017108433 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | -2.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00156     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | 0.00357     |\n",
      "|    value_loss           | 0.00203     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 91          |\n",
      "|    ep_rew_mean          | 0.914       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042781435 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | -1.21       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0533     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.000816    |\n",
      "|    value_loss           | 0.000705    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 111        |\n",
      "|    ep_rew_mean          | 0.895      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 71         |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 831        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10450481 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.604     |\n",
      "|    explained_variance   | -2.4       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0605    |\n",
      "|    n_updates            | 280        |\n",
      "|    policy_gradient_loss | -0.0226    |\n",
      "|    value_loss           | 0.000627   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.02e+03  |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 60000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1037759 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.721    |\n",
      "|    explained_variance   | -3.44     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0629   |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -0.00979  |\n",
      "|    value_loss           | 0.00049   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 127      |\n",
      "|    ep_rew_mean     | 0.885    |\n",
      "| time/              |          |\n",
      "|    fps             | 67       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 916      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 147        |\n",
      "|    ep_rew_mean          | 0.866      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 67         |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 938        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01046698 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.891     |\n",
      "|    explained_variance   | -0.731     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0174    |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00148   |\n",
      "|    value_loss           | 0.000224   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 167         |\n",
      "|    ep_rew_mean          | 0.846       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010517446 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.944      |\n",
      "|    explained_variance   | -0.413      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 0.827       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 981         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015393111 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.965      |\n",
      "|    explained_variance   | -0.801      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 9.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 206         |\n",
      "|    ep_rew_mean          | 0.807       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024466768 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.659      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    value_loss           | 0.000101    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010418069 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -2.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 0.000175    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 224      |\n",
      "|    ep_rew_mean     | 0.797    |\n",
      "| time/              |          |\n",
      "|    fps             | 66       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1079     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | 0.778       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1098        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017332308 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -1.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    value_loss           | 7.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 264         |\n",
      "|    ep_rew_mean          | 0.759       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1119        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025590315 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -1.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000675   |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 7.15e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 284         |\n",
      "|    ep_rew_mean          | 0.739       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009926498 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | -1.55       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0387     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 7.7e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 304        |\n",
      "|    ep_rew_mean          | 0.72       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 68         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1162       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04058244 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | -2.57      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0273    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00885   |\n",
      "|    value_loss           | 4.46e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050674558 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -8.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0622     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 9.1e-05     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 0.71     |\n",
      "| time/              |          |\n",
      "|    fps             | 66       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1233     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 0.691       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1255        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024732176 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -3.15       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0259      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000153    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 361         |\n",
      "|    ep_rew_mean          | 0.671       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1276        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011825547 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -2.33       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    value_loss           | 2.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 381         |\n",
      "|    ep_rew_mean          | 0.652       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1295        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025790028 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -3.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.69e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021262806 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -4.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00797    |\n",
      "|    value_loss           | 0.0002      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 401      |\n",
      "|    ep_rew_mean     | 0.632    |\n",
      "| time/              |          |\n",
      "|    fps             | 65       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1365     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 428         |\n",
      "|    ep_rew_mean          | 0.613       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1382        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010613704 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -2.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0418     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 448         |\n",
      "|    ep_rew_mean          | 0.593       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1399        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009347767 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 3.64e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 468          |\n",
      "|    ep_rew_mean          | 0.574        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 1416         |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128165465 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | -1.25        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0942       |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    value_loss           | 2.6e-05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | 0.554       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1432        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018440332 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -1.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 2.02e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016261587 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | -8.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00669     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 1.74e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 498      |\n",
      "|    ep_rew_mean     | 0.545    |\n",
      "| time/              |          |\n",
      "|    fps             | 67       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1495     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e817de40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e817e410>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 158      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.02e+03   |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 135        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00808287 |\n",
      "|    clip_fraction        | 0.0402     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | -6.77      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0156    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    value_loss           | 8.41e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012556462 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -4.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    value_loss           | 1.47e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010563098 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -9.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 5.34e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012635031 |\n",
      "|    clip_fraction        | 0.0524      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -6.92       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 6.35e-06    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 81       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 125      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009517632 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -5.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.034      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 1.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010169674 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -4.02       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00272     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 2.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.0242      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010971509 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -5.75       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 1.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0466      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014474659 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -0.0496     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0341     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.000676    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014024646 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0122     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00809    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 0.000798    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | 0.0719   |\n",
      "| time/              |          |\n",
      "|    fps             | 80       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0877      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012038821 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -0.0198     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00527    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 0.00141     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0801      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011321435 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0777     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00935    |\n",
      "|    value_loss           | 0.000969    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0737      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011428144 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -5          |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0388     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00967    |\n",
      "|    value_loss           | 2.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0682      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014110282 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -4.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0504     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.89e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010341829 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -7.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0105      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 1.48e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | 0.0635   |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 384      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 0.0661       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092121465 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | -7.1         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0128      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    value_loss           | 1.13e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0621      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013407309 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.00826    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    value_loss           | 0.000181    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | 0.0585       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122600915 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | -7.2         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0466      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00908     |\n",
      "|    value_loss           | 1.84e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | 0.0554      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023744091 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -7.2        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0209      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 7.53e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 40000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01225755 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | -6.63      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0285    |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.00933   |\n",
      "|    value_loss           | 2.55e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0655   |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 997          |\n",
      "|    ep_rew_mean          | 0.0914       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 80           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136238495 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | 0.0306       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00258      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    value_loss           | 0.00122      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 955        |\n",
      "|    ep_rew_mean          | 0.131      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 82         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 548        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01133058 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | 0.0323     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0178    |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.00726   |\n",
      "|    value_loss           | 0.00266    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 898         |\n",
      "|    ep_rew_mean          | 0.184       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013623208 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00834    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    value_loss           | 0.00526     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 780         |\n",
      "|    ep_rew_mean          | 0.292       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764871 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    value_loss           | 0.00829     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011466859 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.0966      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0369     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.0227      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 749      |\n",
      "|    ep_rew_mean     | 0.322    |\n",
      "| time/              |          |\n",
      "|    fps             | 77       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 664      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 604         |\n",
      "|    ep_rew_mean          | 0.454       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015525246 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.00841     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 0.641       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010945106 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00512    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0307      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | 0.898       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 730         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009036511 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 0.0264      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.6        |\n",
      "|    ep_rew_mean          | 0.948       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 752         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015426228 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0229     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0183      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009511929 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00105     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    value_loss           | 0.0154      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.7     |\n",
      "|    ep_rew_mean     | 0.958    |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 775      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.1        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023075428 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.6        |\n",
      "|    ep_rew_mean          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 818         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012703784 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.958      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.00818     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.5        |\n",
      "|    ep_rew_mean          | 0.966       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 840         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009918137 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.00631     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 34.8       |\n",
      "|    ep_rew_mean          | 0.969      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 81         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 857        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02371819 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.568      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00567    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    value_loss           | 0.00471    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067544365 |\n",
      "|    clip_fraction        | 0.0794       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.629       |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0195      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 0.00392      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.9     |\n",
      "|    ep_rew_mean     | 0.971    |\n",
      "| time/              |          |\n",
      "|    fps             | 81       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 875      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.8         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 82           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 891          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050643994 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0066       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 0.0037       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 908         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012245164 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00511    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 0.00362     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 925         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003715491 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    value_loss           | 0.00329     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.5         |\n",
      "|    ep_rew_mean          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 942          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010976975 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.359       |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00195     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 0.00268      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041638953 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.297       |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000967     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 0.00264      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.974    |\n",
      "| time/              |          |\n",
      "|    fps             | 85       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 960      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 29            |\n",
      "|    ep_rew_mean          | 0.975         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 85            |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 977           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084984605 |\n",
      "|    clip_fraction        | 0.0118        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.266        |\n",
      "|    explained_variance   | 0.597         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00184       |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    value_loss           | 0.00234       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.6         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 994          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017044699 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.234       |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00302     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 0.0021       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47.1        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1011        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013687355 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0119     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 0.00219     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026367158 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | -1.81       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | 0.00661     |\n",
      "|    value_loss           | 0.00236     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 61.8     |\n",
      "|    ep_rew_mean     | 0.945    |\n",
      "| time/              |          |\n",
      "|    fps             | 83       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1075     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.4        |\n",
      "|    ep_rew_mean          | 0.934       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1092        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014189154 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.0794      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00406     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    value_loss           | 0.00543     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 62.9        |\n",
      "|    ep_rew_mean          | 0.946       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1108        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012130755 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.9       |\n",
      "|    ep_rew_mean          | 0.975      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 1125       |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01349796 |\n",
      "|    clip_fraction        | 0.0715     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.288     |\n",
      "|    explained_variance   | 0.429      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.012     |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.00749   |\n",
      "|    value_loss           | 0.011      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.7        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1142        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010565631 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.19       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00877    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 0.005       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017560031 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00166      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    value_loss           | 0.00368      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.8     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 86       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1160     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e817f820> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e817f2e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 151      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.02e+03   |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 134        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01283457 |\n",
      "|    clip_fraction        | 0.0512     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | -2.97      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0235    |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00651   |\n",
      "|    value_loss           | 3.63e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 128         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014484197 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -3.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    value_loss           | 3.58e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 118          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082828235 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | -5.58        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0138      |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    value_loss           | 1.56e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008651869 |\n",
      "|    clip_fraction        | 0.0789      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -4.91       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 1.06e-05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014241513 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -4.66       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016330129 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -4.46       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0665     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 9.68e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 77         |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 211        |\n",
      "|    total_timesteps      | 16384      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01201714 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | -10.6      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.029     |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00781   |\n",
      "|    value_loss           | 3.54e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013155613 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -7.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0518     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 2.34e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012465205 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -5.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 65       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 312      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 333         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011653734 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -3.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00873     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 0.000269    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006573561 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -4.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.021      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 2e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010664976 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | -1.28       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0333     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 2.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012569662 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -2.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 3.03e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010965147 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -5.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0044      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000179    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.08e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 477      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0211      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015333503 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -7.47       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 2.38e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.0533      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014723258 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -0.0136     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0101      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 0.00203     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 986         |\n",
      "|    ep_rew_mean          | 0.108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011728895 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.0152     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.00281     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 947         |\n",
      "|    ep_rew_mean          | 0.143       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397255 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.0698      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0262     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013570875 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 0.0042      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 848      |\n",
      "|    ep_rew_mean     | 0.235    |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 644      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 727         |\n",
      "|    ep_rew_mean          | 0.345       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 665         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015130658 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.0123      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 599         |\n",
      "|    ep_rew_mean          | 0.461       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 687         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010993176 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0296     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0202      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 490         |\n",
      "|    ep_rew_mean          | 0.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012509645 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0245      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 260         |\n",
      "|    ep_rew_mean          | 0.769       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010160634 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00572    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844232 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000157   |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0208      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | 0.911    |\n",
      "| time/              |          |\n",
      "|    fps             | 67       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 753      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.8        |\n",
      "|    ep_rew_mean          | 0.939       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 774         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019755265 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0203     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0205      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.1        |\n",
      "|    ep_rew_mean          | 0.954       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015394827 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0521     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.0158      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.9        |\n",
      "|    ep_rew_mean          | 0.954       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 817         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029903851 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.00484     |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 47.4        |\n",
      "|    ep_rew_mean          | 0.958       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 839         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018584725 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0115      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.974      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02435271 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.793     |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0119    |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    value_loss           | 0.00728    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.9     |\n",
      "|    ep_rew_mean     | 0.965    |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 862      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.1        |\n",
      "|    ep_rew_mean          | 0.963       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016852507 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000105    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | 0.00974     |\n",
      "|    value_loss           | 0.00551     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.8        |\n",
      "|    ep_rew_mean          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 905         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006550748 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.00709     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.5        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 927         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014146516 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.0049      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.6        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003202097 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00358    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 0.0037      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022496756 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 0.00322     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | 0.971    |\n",
      "| time/              |          |\n",
      "|    fps             | 73       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 972      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 993          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018230968 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.338       |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00368     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 0.00299      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.4        |\n",
      "|    ep_rew_mean          | 0.972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1015        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003643189 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00491    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 0.00284     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | 0.971        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1036         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054517146 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.315       |\n",
      "|    explained_variance   | 0.62         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000605     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 0.00236      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 1057         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015155151 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.26        |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00271      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    value_loss           | 0.00227      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 30            |\n",
      "|    mean_reward          | 0.974         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 80000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092893856 |\n",
      "|    clip_fraction        | 0.0159        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.246        |\n",
      "|    explained_variance   | 0.631         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000387      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    value_loss           | 0.00236       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.8     |\n",
      "|    ep_rew_mean     | 0.972    |\n",
      "| time/              |          |\n",
      "|    fps             | 75       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1080     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.4         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 76           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 1102         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007007909 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0085      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000747    |\n",
      "|    value_loss           | 0.00258      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | 0.973        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 76           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 1124         |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014146802 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.212       |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00158     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    value_loss           | 0.00246      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.2         |\n",
      "|    ep_rew_mean          | 0.973        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 76           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 1145         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007536347 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.189       |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00901      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00076     |\n",
      "|    value_loss           | 0.00245      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006959414 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.2        |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00424    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    value_loss           | 0.00227     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | 0.972    |\n",
      "| time/              |          |\n",
      "|    fps             | 77       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1168     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 1189         |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033768923 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.016       |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 0.00248      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1210        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015344714 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.143      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00819    |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 0.00217     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.4        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1231        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002483889 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.138      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000317   |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    value_loss           | 0.00216     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.9         |\n",
      "|    ep_rew_mean          | 0.973        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 78           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1254         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060916375 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.164       |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000138    |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    value_loss           | 0.00229      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 30           |\n",
      "|    mean_reward          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023158446 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.185       |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.011       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 0.00232      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.9     |\n",
      "|    ep_rew_mean     | 0.973    |\n",
      "| time/              |          |\n",
      "|    fps             | 78       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1276     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e817dff0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e817dc30>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 931      |\n",
      "|    ep_rew_mean     | 0.132    |\n",
      "| time/              |          |\n",
      "|    fps             | 157      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 978          |\n",
      "|    ep_rew_mean          | 0.0659       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 136          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068719746 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.152       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0412       |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 0.000277     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 939         |\n",
      "|    ep_rew_mean          | 0.108       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008247503 |\n",
      "|    clip_fraction        | 0.0785      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -3.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    value_loss           | 3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 960         |\n",
      "|    ep_rew_mean          | 0.0811      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012565087 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0687      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00366    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00902    |\n",
      "|    value_loss           | 0.000629    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059087076 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | -5.24        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -3.29e-05    |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    value_loss           | 3.57e-05     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 967      |\n",
      "|    ep_rew_mean     | 0.0797   |\n",
      "| time/              |          |\n",
      "|    fps             | 82       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 124      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 0.0665      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010116305 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00447     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    value_loss           | 0.00015     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 948         |\n",
      "|    ep_rew_mean          | 0.126       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010767311 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -1.76       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0326     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | 0.154       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012138331 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.0847      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0212     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 0.00201     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 836        |\n",
      "|    ep_rew_mean          | 0.237      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 95         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 193        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01585083 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.73      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0363    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.00626   |\n",
      "|    value_loss           | 0.00101    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009295386 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 0.00493     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 682      |\n",
      "|    ep_rew_mean     | 0.38     |\n",
      "| time/              |          |\n",
      "|    fps             | 79       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 256      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 560         |\n",
      "|    ep_rew_mean          | 0.493       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010890238 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0429     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 0.0113      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 463         |\n",
      "|    ep_rew_mean          | 0.582       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 292         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019259935 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000319    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.00969     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | 0.668       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010777156 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00769    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.0167      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 0.737       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014461785 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0155      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0244      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 27         |\n",
      "|    mean_reward          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01797846 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.032     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 0.0259     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 99.8     |\n",
      "|    ep_rew_mean     | 0.913    |\n",
      "| time/              |          |\n",
      "|    fps             | 88       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 347      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.8        |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012292607 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0254      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.2        |\n",
      "|    ep_rew_mean          | 0.955       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014178092 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0207      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 43.8         |\n",
      "|    ep_rew_mean          | 0.962        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 91           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060729566 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00765     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 0.0119       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 41         |\n",
      "|    ep_rew_mean          | 0.964      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 92         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 419        |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01059261 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 0.574      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0244    |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    value_loss           | 0.00784    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156825 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00335    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.00492     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.3     |\n",
      "|    ep_rew_mean     | 0.966    |\n",
      "| time/              |          |\n",
      "|    fps             | 93       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 438      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.9         |\n",
      "|    ep_rew_mean          | 0.968        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 94           |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 456          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076224087 |\n",
      "|    clip_fraction        | 0.0656       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.74        |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000568    |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    value_loss           | 0.00442      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.5        |\n",
      "|    ep_rew_mean          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 473         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007998172 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.00339     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 95           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 491          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045568063 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00758     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 0.00291      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 96           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 509          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034336522 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0207      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 0.00298      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006086809 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0196     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00839    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.974    |\n",
      "| time/              |          |\n",
      "|    fps             | 96       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 528      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.3        |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002845167 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.346      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00435    |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 0.00233     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 563          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023328091 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.295       |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00681     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 0.00235      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.7         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 98           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 581          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017958544 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.249       |\n",
      "|    explained_variance   | 0.619        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0101      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 0.00219      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.4         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 99           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012631137 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.23        |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0142       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 0.00225      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012805234 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.196       |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00742      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 0.00205      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28       |\n",
      "|    ep_rew_mean     | 0.975    |\n",
      "| time/              |          |\n",
      "|    fps             | 99       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 617      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.1        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054469537 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.198      |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00857     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 0.00219     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28           |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 651          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011028943 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.172       |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000379     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    value_loss           | 0.00242      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.9         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008048925 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.162       |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00414     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 0.00231      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.7          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 101           |\n",
      "|    iterations           | 34            |\n",
      "|    time_elapsed         | 685           |\n",
      "|    total_timesteps      | 69632         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093712716 |\n",
      "|    clip_fraction        | 0.0119        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.149        |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00409       |\n",
      "|    n_updates            | 330           |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    value_loss           | 0.00232       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 27         |\n",
      "|    mean_reward          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01150753 |\n",
      "|    clip_fraction        | 0.0545     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.174     |\n",
      "|    explained_variance   | 0.62       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00517   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | 0.00572    |\n",
      "|    value_loss           | 0.00237    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | 0.973    |\n",
      "| time/              |          |\n",
      "|    fps             | 101      |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 703      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 31         |\n",
      "|    ep_rew_mean          | 0.973      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 102        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 721        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19312961 |\n",
      "|    clip_fraction        | 0.0736     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.179     |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0119    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00971   |\n",
      "|    value_loss           | 0.00403    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.6         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 737          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026583395 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.123       |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00212     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    value_loss           | 0.00231      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.6         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 103          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 754          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005982178 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00497     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.00226      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.4          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 771           |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044897088 |\n",
      "|    clip_fraction        | 0.00864       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0995       |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000799     |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.000913     |\n",
      "|    value_loss           | 0.00216       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 27            |\n",
      "|    mean_reward          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 80000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032248543 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.1          |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00352       |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.000216     |\n",
      "|    value_loss           | 0.00199       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 103      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 789      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.4          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 41            |\n",
      "|    time_elapsed         | 807           |\n",
      "|    total_timesteps      | 83968         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028034742 |\n",
      "|    clip_fraction        | 0.00601       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0858       |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.0011        |\n",
      "|    n_updates            | 400           |\n",
      "|    policy_gradient_loss | -0.000753     |\n",
      "|    value_loss           | 0.00201       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.5          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 104           |\n",
      "|    iterations           | 42            |\n",
      "|    time_elapsed         | 825           |\n",
      "|    total_timesteps      | 86016         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037272676 |\n",
      "|    clip_fraction        | 0.0085        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0823       |\n",
      "|    explained_variance   | 0.612         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00106       |\n",
      "|    n_updates            | 410           |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    value_loss           | 0.00217       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.2          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 847           |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026796313 |\n",
      "|    clip_fraction        | 0.00337       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0724       |\n",
      "|    explained_variance   | 0.613         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00726       |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -6.61e-05     |\n",
      "|    value_loss           | 0.00194       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 27            |\n",
      "|    mean_reward          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 90000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013149873 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0685       |\n",
      "|    explained_variance   | 0.611         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000683      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000136     |\n",
      "|    value_loss           | 0.00202       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 103      |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 871      |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.4          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 45            |\n",
      "|    time_elapsed         | 892           |\n",
      "|    total_timesteps      | 92160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048070733 |\n",
      "|    clip_fraction        | 0.00596       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0661       |\n",
      "|    explained_variance   | 0.611         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000716      |\n",
      "|    n_updates            | 440           |\n",
      "|    policy_gradient_loss | -0.00069      |\n",
      "|    value_loss           | 0.00204       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.4          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 103           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 913           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031952755 |\n",
      "|    clip_fraction        | 0.00303       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0619       |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000686      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000466     |\n",
      "|    value_loss           | 0.00203       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.2         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 102          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 935          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003924716 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0699      |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000509     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.000375    |\n",
      "|    value_loss           | 0.00199      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.2          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 102           |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 956           |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015414678 |\n",
      "|    clip_fraction        | 0.00337       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0589       |\n",
      "|    explained_variance   | 0.602         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.000342     |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000603     |\n",
      "|    value_loss           | 0.00195       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 27            |\n",
      "|    mean_reward          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 100000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017418741 |\n",
      "|    clip_fraction        | 0.00273       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0613       |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000798      |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000316     |\n",
      "|    value_loss           | 0.00198       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 102      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 979      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e8290850> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e82918d0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 121      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 104         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005816588 |\n",
      "|    clip_fraction        | 0.0433      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -2.8        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0447     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 1e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009993872 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -3.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00569     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 2.22e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 99          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013195322 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -3.04       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 2.72e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010109415 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.42       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0052     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 1.3e-05     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 63       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008645443 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    value_loss           | 8.16e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127925575 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | -2.64        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0177      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00869     |\n",
      "|    value_loss           | 2.44e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 226         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010235595 |\n",
      "|    clip_fraction        | 0.0953      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -2.5        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00912    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 3.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015499161 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -11.2       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00305     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    value_loss           | 0.000299    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007185477 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -6.48       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00428     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 2.27e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 327      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 349        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02005804 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | -15.6      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0425    |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.00899   |\n",
      "|    value_loss           | 9.85e-06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 370        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00951886 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.85      |\n",
      "|    explained_variance   | -3.69      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.016     |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00717   |\n",
      "|    value_loss           | 1.53e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013936534 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -6.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.027      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 8.56e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 413          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074190293 |\n",
      "|    clip_fraction        | 0.0956       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.84        |\n",
      "|    explained_variance   | -20          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00254     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 3.81e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012044882 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -5.86       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00958    |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 7.07e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.08e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 493      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010520939 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -1.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0105      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 2.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009123836 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -4.63       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0511     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    value_loss           | 1.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 557         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014600646 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -6.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    value_loss           | 3.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 578         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018391898 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -4.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0609     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009845836 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -6.98       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0437     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 9.69e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 657      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008111252 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -1.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0229     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 3.17e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020672537 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -4.39       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00487     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    value_loss           | 2.25e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011019321 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -1.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00888    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 6.61e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 743        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01587925 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.74      |\n",
      "|    explained_variance   | -0.907     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0532    |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.00877   |\n",
      "|    value_loss           | 1.83e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010269137 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -2.67       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 1.86e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 822      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115062725 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | -3.7         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0369      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00931     |\n",
      "|    value_loss           | 0.000223     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 864          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066620116 |\n",
      "|    clip_fraction        | 0.0889       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | -9.21        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00163     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 2.06e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.1e+03   |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 64        |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 886       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0104922 |\n",
      "|    clip_fraction        | 0.079     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.6      |\n",
      "|    explained_variance   | -1.63     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0456   |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0114   |\n",
      "|    value_loss           | 3.43e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 907         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011345494 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -3.69       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 8.93e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014389148 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -1.98       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0041     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 1.62e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 987      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 1008         |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106446985 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -1.53        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 0.00027      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027919058 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.544      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 2.93e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006132151 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -0.0526     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00398     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 4.75e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 64         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 1073       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01222408 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | -0.706     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0326    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.00662   |\n",
      "|    value_loss           | 1.24e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072438684 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0295      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    value_loss           | 1.5e-05      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1153     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1174        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014686767 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.0686     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    value_loss           | 3.2e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1196        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010996044 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -2.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 6.07e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0          |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1218       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00788652 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | -3.1       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00297   |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 6.3e-06    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1239        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013253125 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -7.82       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00142     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    value_loss           | 2.28e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015095919 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | -1.88       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00227     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 4.58e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 62       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1320     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1341        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021712638 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -7.46       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0658      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.000118    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.00225     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013246445 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | -9.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00444    |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 6.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.00928     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1383        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010255726 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0199     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.000196    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006626646 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.053      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    value_loss           | 0.00101     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.00905  |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1462     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.0108      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1484        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019500066 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.894      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00836    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000146    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.09e+03  |\n",
      "|    ep_rew_mean          | 0.0141    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 62        |\n",
      "|    iterations           | 46        |\n",
      "|    time_elapsed         | 1505      |\n",
      "|    total_timesteps      | 94208     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0246556 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.53     |\n",
      "|    explained_variance   | -0.0897   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0331   |\n",
      "|    n_updates            | 450       |\n",
      "|    policy_gradient_loss | -0.0153   |\n",
      "|    value_loss           | 0.000153  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.09e+03   |\n",
      "|    ep_rew_mean          | 0.0138     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 1529       |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01066306 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.51      |\n",
      "|    explained_variance   | -0.00136   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0394    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.000468   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.09e+03   |\n",
      "|    ep_rew_mean          | 0.0135     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 1550       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01577527 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | -4.12      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0412    |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 3.14e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049530953 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | -2.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 2.04e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.0132   |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1628     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "simple_ppo_reward = {}\n",
    "\n",
    "for run in range(5):\n",
    "    eval_callback = Eval_Callback(eval_env=env, eval_freq=10000, n_eval_episodes=10)\n",
    "\n",
    "    policy = PPO(policy=\"CnnPolicy\", env=env, verbose=1, policy_kwargs=get_policy_kwargs(),  ent_coef=0.005)\n",
    "\n",
    "    policy.learn(total_timesteps=100000, callback=eval_callback)\n",
    "\n",
    "    simple_ppo_reward[f\"run_{run}\"] = eval_callback.record_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.save(\"pretrained_models/simple_ppo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Test PPO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can uncomment this section to test our pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = PPO.load(\"pretrained_models/simple_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average reward for 50 runs are: 0.0\n"
     ]
    }
   ],
   "source": [
    "# # Reset the environment to its initial state\n",
    "# obs, _ = env.reset()\n",
    "# count = 1\n",
    "# reward_list = []\n",
    "# # Perform some actions in the environment\n",
    "# while count <= 50:\n",
    "#     action, _ = policy.predict(obs) # Sample an action using the trained policy\n",
    "    \n",
    "#     # print(observation, action)\n",
    "\n",
    "#     obs, reward, done, truncated, info = env.step(action)  # Take a step in the environment\n",
    "\n",
    "\n",
    "#     # If the episode is finish either done or truncated, record reward & reset the environment\n",
    "#     if done or truncated:\n",
    "#         reward_list.append(reward)\n",
    "#         observation = env.reset()\n",
    "#         count += 1\n",
    "\n",
    "# print(f\"The average reward for 50 runs are: {np.mean(reward_list)}\")\n",
    "# env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Count-Based Observation Bonus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we will present our implementation of the count-based bonus intrinsic reward. \n",
    "- Here, we implement it as a wrapper to the Minigrid environment -> modifying the .step() function, so as to include the bonus reward. 🔄\n",
    "- The result of this algorithm will be presented at the end of the notebook. 📊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.1 Key Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The idea behind count-based observation is to use a memory to record the number the number of time a state has been visited. Subsequently, higher rewards are given to states or states-actions that are less visited. \n",
    "- The intrinsic reward, in counting method based on states-actions, is denoted as $r^{+}(s,a)$ is calculated using the formula: $r^{+}(s,a)=\\beta/\\sqrt{(n(\\phi(s,a)))}$ where $\\beta$ is a hyperparameter and $\\phi$ is a hashing function.\n",
    "- A simple and efficient choice for $\\phi$ is a SimHash function, converting high dimensional data into hash codes: $$\\phi(s) = sgn(Ag(s)) \\in \\{-1,1\\}^k$$ where $g$ is an optional processing function and $A$ is a matrix drawn from standard Gaussian distribution $N(0,1)$.\n",
    "- An advanced method is to use Autoencoder to learn the lower dimension vector representation. This autoencoder has a sigmoid activation function $b(s)$ that constraint the representation vector to range $\\{0,1\\}$\n",
    "\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./image/AutoEncoder_for_Count_Based_Exploration.png\" alt=\"AutoEncoder forr Count Based Exploration\" width=\"1000\" height=\"300\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class SimHash(object) :\n",
    "  def __init__(self, state_emb, k) :\n",
    "    self.A = np.random.normal(0, 1, (k, state_emb))\n",
    "\n",
    "  def hash(self, state) :\n",
    "    hash_key = str(np.sign(self.A @ np.array(state)).tolist())                          # -> the matrix A\n",
    "    return hash_key\n",
    "\n",
    "\n",
    "class CountBasedBonusWrapepr(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.M = {}                                                                     # -> Memory counting M                                                                         \n",
    "        self.hash = SimHash(147, 56) \n",
    "        self.beta = 0.001                                                               # -> hyperparameter beta                                                 \n",
    "    \n",
    "    def _update_count_dict_(self, hash):\n",
    "        \"\"\"Function to update the counting library M, if hash is in count then + 1 otherwise create a new entry of value 0.\"\"\"\n",
    "        pre_count = 0\n",
    "\n",
    "        if hash in self.M:\n",
    "            pre_count = self.M[hash]\n",
    "        new_count = pre_count + 1\n",
    "        self.M[hash] = new_count\n",
    "\n",
    "    def get_count(self, hash):\n",
    "        return self.M[hash]\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        obs_flatten = obs.flatten()\n",
    "\n",
    "        hash =  self.hash.hash(obs_flatten)\n",
    "\n",
    "        self._update_count_dict_(hash)\n",
    "\n",
    "        new_count = self.get_count(hash)                                                   # Get the count value after update the library. \n",
    "\n",
    "        bonus = self.beta / math.sqrt(new_count)                                           # Calculate the intrinsic reward.\n",
    "\n",
    "        reward += bonus\n",
    "\n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MiniGrid-Empty-16x16-v0\", render_mode=\"rgb_array\")\n",
    "env = ImgObsWrapper(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.1 Train PPO with Count Based Bonus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5fa1b40> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5fa2bf0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.23     |\n",
      "| time/              |          |\n",
      "|    fps             | 116      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.177       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010095287 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.775      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 1.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.149       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010649834 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -2.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 1.23e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 939         |\n",
      "|    ep_rew_mean          | 0.22        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012580957 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 2.11e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010104943 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    value_loss           | 0.00199     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 928      |\n",
      "|    ep_rew_mean     | 0.225    |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 168      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 979         |\n",
      "|    ep_rew_mean          | 0.232       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008116355 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.105      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00792    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 0.000485    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 896         |\n",
      "|    ep_rew_mean          | 0.287       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014300028 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00931    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000518    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 813         |\n",
      "|    ep_rew_mean          | 0.351       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 69          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010008613 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -0.0209     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 0.00385     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 779         |\n",
      "|    ep_rew_mean          | 0.375       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013382845 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.0527      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0338     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.00485     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 1.02e+03 |\n",
      "|    mean_reward          | 0        |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 20000    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.015216 |\n",
      "|    clip_fraction        | 0.134    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.82    |\n",
      "|    explained_variance   | 0.0233   |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0121   |\n",
      "|    n_updates            | 90       |\n",
      "|    policy_gradient_loss | -0.00691 |\n",
      "|    value_loss           | 0.00282  |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 769      |\n",
      "|    ep_rew_mean     | 0.381    |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 691         |\n",
      "|    ep_rew_mean          | 0.442       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015499583 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.00212     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 545         |\n",
      "|    ep_rew_mean          | 0.558       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012448411 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0165     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.0107      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | 0.657       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013283078 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00568    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.02        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 311          |\n",
      "|    ep_rew_mean          | 0.746        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 433          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151504455 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0205      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0153      |\n",
      "|    value_loss           | 0.0268       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012654008 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 132      |\n",
      "|    ep_rew_mean     | 0.89     |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 516      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60.5         |\n",
      "|    ep_rew_mean          | 0.95         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 538          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077627823 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00223      |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00978     |\n",
      "|    value_loss           | 0.0222       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.9        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008483492 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00286     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00934    |\n",
      "|    value_loss           | 0.0188      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 44.5         |\n",
      "|    ep_rew_mean          | 0.962        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 584          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053945724 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.983       |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00887     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 0.0129       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.6        |\n",
      "|    ep_rew_mean          | 0.965       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 606         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008420381 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    value_loss           | 0.00987     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006582759 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00137    |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    value_loss           | 0.00665     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.2     |\n",
      "|    ep_rew_mean     | 0.968    |\n",
      "| time/              |          |\n",
      "|    fps             | 64       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 630      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.6        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 65          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006929921 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.732      |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0061      |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    value_loss           | 0.00507     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.2         |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 66           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056433985 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0221      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    value_loss           | 0.00458      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004423663 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00388    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 0.00365     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30           |\n",
      "|    ep_rew_mean          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 68           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 721          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040254313 |\n",
      "|    clip_fraction        | 0.0683       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00169     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 0.00302      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004830861 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.366      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00864    |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.2     |\n",
      "|    ep_rew_mean     | 0.975    |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 745      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.7         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 69           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 768          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016541111 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.288       |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00175     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 0.0024       |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.8          |\n",
      "|    ep_rew_mean          | 0.975         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 69            |\n",
      "|    iterations           | 27            |\n",
      "|    time_elapsed         | 790           |\n",
      "|    total_timesteps      | 55296         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00088783324 |\n",
      "|    clip_fraction        | 0.00923       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.286        |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00751      |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.000608     |\n",
      "|    value_loss           | 0.00237       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 70           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 812          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031261472 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.26        |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00331     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 0.00243      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.8        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011455918 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 0.00242     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004152567 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.196      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00928    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 0.00229     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.2     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 859      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.1         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 882          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007753248 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.175       |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00166     |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000593    |\n",
      "|    value_loss           | 0.00233      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 27.8       |\n",
      "|    ep_rew_mean          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 72         |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 904        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00631339 |\n",
      "|    clip_fraction        | 0.0261     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.147     |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00654   |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.00327   |\n",
      "|    value_loss           | 0.0024     |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.6          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 72            |\n",
      "|    iterations           | 33            |\n",
      "|    time_elapsed         | 927           |\n",
      "|    total_timesteps      | 67584         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033481262 |\n",
      "|    clip_fraction        | 0.00747       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.136        |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00157      |\n",
      "|    n_updates            | 320           |\n",
      "|    policy_gradient_loss | -0.000317     |\n",
      "|    value_loss           | 0.00228       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.7         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 949          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004892368 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.122       |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000763     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.000785    |\n",
      "|    value_loss           | 0.00212      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 27         |\n",
      "|    mean_reward          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 70000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01931103 |\n",
      "|    clip_fraction        | 0.055      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.153     |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00962   |\n",
      "|    n_updates            | 340        |\n",
      "|    policy_gradient_loss | -0.00306   |\n",
      "|    value_loss           | 0.00232    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.3     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 73       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 974      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.6        |\n",
      "|    ep_rew_mean          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022536997 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.136      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00177    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 0.00246     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.4         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 74           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1019         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008272609 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.106       |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00104      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000621    |\n",
      "|    value_loss           | 0.00229      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.4        |\n",
      "|    ep_rew_mean          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002013256 |\n",
      "|    clip_fraction        | 0.00762     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0999     |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000736   |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.000747   |\n",
      "|    value_loss           | 0.00201     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.5          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 74            |\n",
      "|    iterations           | 39            |\n",
      "|    time_elapsed         | 1065          |\n",
      "|    total_timesteps      | 79872         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030759323 |\n",
      "|    clip_fraction        | 0.00542       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.104        |\n",
      "|    explained_variance   | 0.614         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00305      |\n",
      "|    n_updates            | 380           |\n",
      "|    policy_gradient_loss | -0.00042      |\n",
      "|    value_loss           | 0.00205       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008601737 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.113       |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.002       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00078     |\n",
      "|    value_loss           | 0.00212      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.7     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 75       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1089     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.4         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 1111         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014360952 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0992      |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00497      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.000361    |\n",
      "|    value_loss           | 0.00223      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 47.4       |\n",
      "|    ep_rew_mean          | 0.958      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 75         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1134       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17230427 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.183     |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0141    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00331   |\n",
      "|    value_loss           | 0.00247    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.9        |\n",
      "|    ep_rew_mean          | 0.942       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044032373 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.329      |\n",
      "|    explained_variance   | -5.1        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0682     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.00111     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16628167 |\n",
      "|    clip_fraction        | 0.411      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.669     |\n",
      "|    explained_variance   | -0.582     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.7        |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | 0.0225     |\n",
      "|    value_loss           | 0.000942   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 79.2     |\n",
      "|    ep_rew_mean     | 0.93     |\n",
      "| time/              |          |\n",
      "|    fps             | 72       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1240     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | 0.918       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1262        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017306462 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 122          |\n",
      "|    ep_rew_mean          | 0.9          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 73           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 1285         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0096286815 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.632       |\n",
      "|    explained_variance   | 0.00849      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00648     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    value_loss           | 0.00671      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 138         |\n",
      "|    ep_rew_mean          | 0.886       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1308        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008116715 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00766    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 0.00946     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 153         |\n",
      "|    ep_rew_mean          | 0.873       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010440994 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0132     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.0162      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015452359 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.263       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    value_loss           | 0.0178      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 130      |\n",
      "|    ep_rew_mean     | 0.895    |\n",
      "| time/              |          |\n",
      "|    fps             | 74       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1355     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5f65ba0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5f67220>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0339   |\n",
      "| time/              |          |\n",
      "|    fps             | 114      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0361      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 100         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013050657 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -1.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0507     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 3.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0335      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 96          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014551139 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -4.66       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0239     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00764    |\n",
      "|    value_loss           | 0.000136    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0316      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014819937 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -3.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    value_loss           | 1.33e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008168964 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -8.75       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 7.34e-06    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0307   |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.0304       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 192          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102491025 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -4.52        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0205      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 4.88e-05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | 0.0282     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 66         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 215        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03595434 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.86      |\n",
      "|    explained_variance   | -1.58      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.066     |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    value_loss           | 9.53e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0267      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009579728 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -0.336      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00179     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 9.72e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0257      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012881415 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -5.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 3.41e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069558695 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | -10.9        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0423      |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 4.25e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0.025    |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 342      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.0247       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104793515 |\n",
      "|    clip_fraction        | 0.0995       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.85        |\n",
      "|    explained_variance   | -3.95        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0511      |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    value_loss           | 1.05e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.024        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115717705 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | -3.23        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0268      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    value_loss           | 8.72e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.0234      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 410         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011422892 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -1.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0227      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 66          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012598189 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -1.93       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 1.91e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01187202 |\n",
      "|    clip_fraction        | 0.0954     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | -2.04      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.00616   |\n",
      "|    value_loss           | 1.66e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.08e+03 |\n",
      "|    ep_rew_mean     | 0.0222   |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 514      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | 0.0218     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 61         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 536        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01338885 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | -0.311     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0499    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 1.69e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0215      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013580388 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -1.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0503     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 5.07e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.021        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 63           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 581          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155555885 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | -7.83        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0288      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 7.41e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | 0.0206       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 64           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 604          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081657395 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.76        |\n",
      "|    explained_variance   | -2.43        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0279      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    value_loss           | 3.01e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018304996 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -6.04       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0485     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 1.31e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.0203   |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 686      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0204      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 708         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013649324 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -7.81       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    value_loss           | 3.23e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0201      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023135912 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -5.88       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 3.14e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0196      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 753         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026947703 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -9.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0383     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 1.49e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0192      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 776         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010893829 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -2.99       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 2.55e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009971868 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -9.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    value_loss           | 9.69e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0192   |\n",
      "| time/              |          |\n",
      "|    fps             | 59       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 857      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 0.0191       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 60           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 879          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115029905 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.71        |\n",
      "|    explained_variance   | -6.92        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00813     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00909     |\n",
      "|    value_loss           | 0.000112     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0191      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014596941 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -4.48       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0608     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    value_loss           | 1.32e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.019        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 921          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114800185 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -3.98        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0389      |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 1.46e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.019       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 939         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009065365 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -4.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00382    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    value_loss           | 3.76e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014767151 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -2.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 3.34e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0193   |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1000     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0193      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010271506 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -5.21       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0294     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 5.7e-05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.0194       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1043         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127592925 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | -8.68        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0142      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.0109      |\n",
      "|    value_loss           | 2.3e-05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0197      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1066        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015603516 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -7.04       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0217      |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    value_loss           | 4.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0197      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1087        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017461076 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -8.14       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00825    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 5.99e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140559785 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.72        |\n",
      "|    explained_variance   | -2.94        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0395      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 2.98e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0198   |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1157     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0199      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1179        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017317722 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -1.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00701    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 1.53e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.02        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 63          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016314834 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -6.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 2.32e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.0201     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1223       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01878881 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.81      |\n",
      "|    explained_variance   | -6.47      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00527   |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    value_loss           | 3.41e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0203      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1245        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017581237 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -6.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0465     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.63e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016136568 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -3.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0417     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 2.32e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0207   |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1327     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0207      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016156618 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -5.49       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.000112    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0208      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1373        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018641572 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -5.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00374     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 2.49e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.021      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 63         |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 1395       |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01379875 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.75      |\n",
      "|    explained_variance   | -3.78      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.028     |\n",
      "|    n_updates            | 420        |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    value_loss           | 2.97e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 90000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153176915 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | -5           |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0196      |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 2.81e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | 0.0212   |\n",
      "| time/              |          |\n",
      "|    fps             | 61       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1476     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0216      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1498        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017192308 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -5.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0615     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 4.27e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0219      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016771432 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -5.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0464     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 4.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.022       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1544        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015414548 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -6.33       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.000199    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0223      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 62          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1566        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017215762 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -4.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00345    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 3.73e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016593624 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | -4.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.05       |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 3.3e-05     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | 0.0224   |\n",
      "| time/              |          |\n",
      "|    fps             | 60       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1648     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5f65720> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5f64d30>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0193   |\n",
      "| time/              |          |\n",
      "|    fps             | 115      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | 0.0186       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 101          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062198336 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | -0.917       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0231      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 5.82e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0172      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027775772 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0111     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0084     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.000103    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009785568 |\n",
      "|    clip_fraction        | 0.0501      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -3.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 1.96e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011674203 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -5.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000178    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0163   |\n",
      "| time/              |          |\n",
      "|    fps             | 66       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 154      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.016        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 71           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129863005 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | -2.28        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0436      |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    value_loss           | 6.58e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.015       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020883523 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -4.9        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00318    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0145      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012647992 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -7.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00541    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 2.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0141      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010313984 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -2.62       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 1.49e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009331532 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 1.58e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0.0139   |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0142      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016780723 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -0.777      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00493     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 1.84e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.014      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 72         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 336        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01659092 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.73      |\n",
      "|    explained_variance   | -8.46      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0325    |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00991   |\n",
      "|    value_loss           | 8.73e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.0138      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015522431 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | -6.39       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 3.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0135      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015966907 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -7.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0356     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 3.2e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031855628 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -10.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0534     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 2.94e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.08e+03 |\n",
      "|    ep_rew_mean     | 0.0134   |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 443      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | 0.0133     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 70         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 462        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01541801 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -5.22      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00818   |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.000239   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0132      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010880331 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -8.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 1.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0129      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025651544 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -6.45       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0431     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 9.33e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.0127      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010471516 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -2.55       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00844     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 5.41e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027272068 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -2.82       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0622     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 2.17e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.0126   |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 578      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0126      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014516145 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -1.92       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00637    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 2e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.013       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011356574 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.55       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0489     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 0.000147    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0131      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008923998 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -4.07       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0026     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    value_loss           | 6.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0135      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026311405 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -2.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 1.99e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015100191 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -5.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 8.12e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0145   |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 724      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0148      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 743         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015490479 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -2.73       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0304     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 2.21e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0151      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017682351 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -2.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 5.01e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.0154     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 782        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01586079 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.63      |\n",
      "|    explained_variance   | -4.32      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0387    |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0138    |\n",
      "|    value_loss           | 7.11e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0155      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 801         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016631491 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -1.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 4.34e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018425979 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -5.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0431     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 3.07e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.016    |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 870      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0162      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 890         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010501387 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -2.04       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.037      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00801    |\n",
      "|    value_loss           | 0.000136    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 909         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026053566 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | -1.44       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 4.23e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.0163     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 72         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 929        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01596993 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | -1.51      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 2.74e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0163      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 948         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017893044 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -1.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0645     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 4.04e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018298296 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -6.47       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 4.63e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1015     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | 0.0166     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 71         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 1032       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01885454 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | -3.59      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0578    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00874   |\n",
      "|    value_loss           | 1.3e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0166      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1049        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017606068 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -4.23       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0543      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 5.18e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.0165     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 72         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1067       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01531638 |\n",
      "|    clip_fraction        | 0.0852     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.57      |\n",
      "|    explained_variance   | -6.75      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0294    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | -0.00897   |\n",
      "|    value_loss           | 3.13e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.1e+03    |\n",
      "|    ep_rew_mean          | 0.0165     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 73         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 1084       |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02000101 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.56      |\n",
      "|    explained_variance   | -6.04      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0575    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 4.74e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014024299 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -17         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00808    |\n",
      "|    value_loss           | 7.45e-06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 0.0166   |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1150     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0165      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1169        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015763558 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -8.15       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0511     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 2.05e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0165      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013230213 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 4.99e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0165      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1208        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010338297 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | -0.176      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0595     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 6.36e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017497301 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -1.81       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0116      |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000359    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | 0.0165   |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1279     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0167      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1298        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016620468 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0549     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 4.65e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0167      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1317        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016538056 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.568      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0436     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 5.46e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | 0.0168      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1336        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012887435 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.925      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 2.08e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.017       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 72          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1355        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011515072 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -1.63       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 5.26e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018382158 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -3.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0466     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 4.71e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | 0.0171   |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1422     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e8292500> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f7708f8bd00>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0124   |\n",
      "| time/              |          |\n",
      "|    fps             | 135      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 958         |\n",
      "|    ep_rew_mean          | 0.0968      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 118         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005869706 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.266      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00426    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 8.72e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 980          |\n",
      "|    ep_rew_mean          | 0.069        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 114          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077155964 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | 0.0119       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00803     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 0.00058      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 991         |\n",
      "|    ep_rew_mean          | 0.0549      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 111         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014683297 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.965      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0362     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 4.49e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.02e+03  |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 10000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0222167 |\n",
      "|    clip_fraction        | 0.219     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.87     |\n",
      "|    explained_variance   | -2.64     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0642   |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -0.0155   |\n",
      "|    value_loss           | 3.56e-05  |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 926      |\n",
      "|    ep_rew_mean     | 0.128    |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 143      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 940         |\n",
      "|    ep_rew_mean          | 0.183       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010141788 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -0.0141     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 0.00172     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 839        |\n",
      "|    ep_rew_mean          | 0.271      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 78         |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 181        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01113816 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.81      |\n",
      "|    explained_variance   | 0.105      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0227    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    value_loss           | 0.00269    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 675         |\n",
      "|    ep_rew_mean          | 0.414       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012258077 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 0.00465     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 541         |\n",
      "|    ep_rew_mean          | 0.53        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 219         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009021136 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014282281 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00308     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0168      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 409      |\n",
      "|    ep_rew_mean     | 0.647    |\n",
      "| time/              |          |\n",
      "|    fps             | 70       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 308         |\n",
      "|    ep_rew_mean          | 0.733       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017004602 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0163     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0209      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 186          |\n",
      "|    ep_rew_mean          | 0.844        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 75           |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 327          |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152958855 |\n",
      "|    clip_fraction        | 0.176        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0239      |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.0248       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.3        |\n",
      "|    ep_rew_mean          | 0.941       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743281 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0259     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.0294      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.4        |\n",
      "|    ep_rew_mean          | 0.951       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011707837 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00397    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.0193      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016070452 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.0143      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47       |\n",
      "|    ep_rew_mean     | 0.959    |\n",
      "| time/              |          |\n",
      "|    fps             | 71       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 427      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.2        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 73          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186141 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0062     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.00981     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.2        |\n",
      "|    ep_rew_mean          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007801008 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.015       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    value_loss           | 0.00744     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011894463 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    value_loss           | 0.00628     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | 0.972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004817617 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.006      |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 0.00521     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018857814 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.571      |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    value_loss           | 0.00402     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.7     |\n",
      "|    ep_rew_mean     | 0.962    |\n",
      "| time/              |          |\n",
      "|    fps             | 78       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 521      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.6        |\n",
      "|    ep_rew_mean          | 0.959       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023030942 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.000283   |\n",
      "|    value_loss           | 0.00612     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 34.2       |\n",
      "|    ep_rew_mean          | 0.97       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 80         |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 560        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01395064 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.598     |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00874    |\n",
      "|    n_updates            | 210        |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 0.00808    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025731917 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 0.00543     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001931406 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00069     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 0.00352     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049584205 |\n",
      "|    clip_fraction        | 0.0283       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.262       |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0176      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 0.0028       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.5     |\n",
      "|    ep_rew_mean     | 0.975    |\n",
      "| time/              |          |\n",
      "|    fps             | 82       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 619      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.4          |\n",
      "|    ep_rew_mean          | 0.975         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 83            |\n",
      "|    iterations           | 26            |\n",
      "|    time_elapsed         | 638           |\n",
      "|    total_timesteps      | 53248         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083356013 |\n",
      "|    clip_fraction        | 0.0213        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.219        |\n",
      "|    explained_variance   | 0.589         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00367      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | -0.00254      |\n",
      "|    value_loss           | 0.00236       |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.4        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 657         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001360454 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.21       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000106   |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    value_loss           | 0.00228     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.2         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012901429 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.219       |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00809     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00144     |\n",
      "|    value_loss           | 0.00234      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.3        |\n",
      "|    ep_rew_mean          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 695         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014751531 |\n",
      "|    clip_fraction        | 0.0223      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00146    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 0.00204     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008985551 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0272     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.0043      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 37.5     |\n",
      "|    ep_rew_mean     | 0.968    |\n",
      "| time/              |          |\n",
      "|    fps             | 80       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 767      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.3        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013483424 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00756    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.00381     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 81          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016383909 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.315      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000702   |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.00349     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028918583 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.227      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00814    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    value_loss           | 0.0031      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.9        |\n",
      "|    ep_rew_mean          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 842         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011246104 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.186      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00133    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.0053      |\n",
      "|    value_loss           | 0.00324     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021720642 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.232      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0082     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    value_loss           | 0.00686     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 36.7     |\n",
      "|    ep_rew_mean     | 0.968    |\n",
      "| time/              |          |\n",
      "|    fps             | 83       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 858      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 28.9       |\n",
      "|    ep_rew_mean          | 0.975      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 84         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 876        |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06602513 |\n",
      "|    clip_fraction        | 0.0273     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.191     |\n",
      "|    explained_variance   | 0.575      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00317   |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.00158   |\n",
      "|    value_loss           | 0.00398    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.6         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 894          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017580274 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.149       |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00313     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    value_loss           | 0.00289      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.3         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 912          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009819887 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.125       |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00271     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    value_loss           | 0.00238      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.4         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 930          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018638705 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.126       |\n",
      "|    explained_variance   | 0.53         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 0.00263      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036817265 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.118       |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00321     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    value_loss           | 0.00214      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.7     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 86       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 951      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.5         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 970          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036437223 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0946      |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000972     |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 0.00211      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.3         |\n",
      "|    ep_rew_mean          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 989          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053562215 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0753      |\n",
      "|    explained_variance   | 0.603        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00896     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    value_loss           | 0.00201      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 27.3          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 87            |\n",
      "|    iterations           | 43            |\n",
      "|    time_elapsed         | 1008          |\n",
      "|    total_timesteps      | 88064         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019957215 |\n",
      "|    clip_fraction        | 0.00259       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0657       |\n",
      "|    explained_variance   | 0.616         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00119      |\n",
      "|    n_updates            | 420           |\n",
      "|    policy_gradient_loss | -0.00023      |\n",
      "|    value_loss           | 0.00201       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 27            |\n",
      "|    mean_reward          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 90000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029329132 |\n",
      "|    clip_fraction        | 0.00366       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0605       |\n",
      "|    explained_variance   | 0.613         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000697      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000405     |\n",
      "|    value_loss           | 0.00201       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.2     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 87       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1029     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.3        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 87          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1048        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010527987 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0823     |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00256    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.000222   |\n",
      "|    value_loss           | 0.002       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.8        |\n",
      "|    ep_rew_mean          | 0.962       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016495578 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00422     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    value_loss           | 0.00553     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30          |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1085        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010785675 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0254     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.00615     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27.7        |\n",
      "|    ep_rew_mean          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1103        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016981741 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.112      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00092    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    value_loss           | 0.00314     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045153038 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0822      |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00121     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    value_loss           | 0.00238      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 89       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1123     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e82912a0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e82928c0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.018    |\n",
      "| time/              |          |\n",
      "|    fps             | 173      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.015       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 138         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010911626 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -2.02       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.04       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 3.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.0156      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 130         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009213674 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.43       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 1.85e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0.016       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 126         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010186462 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -2.45       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0529     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 3.05e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010695953 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -6.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0218     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 8.67e-06    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.016    |\n",
      "| time/              |          |\n",
      "|    fps             | 77       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 132      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | 0.0159       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0108848885 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | -4.44        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00955     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 2.83e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | 0.0155       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068126745 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | -2.86        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0106      |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 7.69e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0152      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009271136 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -3.5        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00362     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    value_loss           | 1.08e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0152      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009134373 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -5.73       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0459     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    value_loss           | 2.05e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011426315 |\n",
      "|    clip_fraction        | 0.0848      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -5.39       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0406     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.64e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0.0154   |\n",
      "| time/              |          |\n",
      "|    fps             | 77       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 265      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0156      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010009991 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -5.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    value_loss           | 2.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0153      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010251261 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -5.76       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    value_loss           | 1.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.0712      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013086781 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -3.96       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    value_loss           | 3.55e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.0672      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012684986 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.0148      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0137      |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    value_loss           | 0.00324     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013711259 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -1.81       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0099     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 6.96e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | 0.0682   |\n",
      "| time/              |          |\n",
      "|    fps             | 74       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 412      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | 0.109       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014375278 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.00655    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.000108    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | 0.199       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011392048 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    value_loss           | 0.00422     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 734         |\n",
      "|    ep_rew_mean          | 0.342       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010812309 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.0992      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 607          |\n",
      "|    ep_rew_mean          | 0.457        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 79           |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 490          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140610505 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0313      |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 0.0224       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 40000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01413349 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 0.243      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0292    |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.0222     |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 465      |\n",
      "|    ep_rew_mean     | 0.585    |\n",
      "| time/              |          |\n",
      "|    fps             | 73       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 560      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 238         |\n",
      "|    ep_rew_mean          | 0.794       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 579         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009692983 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00719    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0247      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 80.9        |\n",
      "|    ep_rew_mean          | 0.93        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014002698 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00521    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.027       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.1        |\n",
      "|    ep_rew_mean          | 0.949       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011332434 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0219      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 49.7         |\n",
      "|    ep_rew_mean          | 0.957        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 77           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 635          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072935326 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00596     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00894     |\n",
      "|    value_loss           | 0.0147       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072079874 |\n",
      "|    clip_fraction        | 0.0988       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0154      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00989     |\n",
      "|    value_loss           | 0.00982      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.2     |\n",
      "|    ep_rew_mean     | 0.963    |\n",
      "| time/              |          |\n",
      "|    fps             | 78       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 654      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.6        |\n",
      "|    ep_rew_mean          | 0.967       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014235662 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.00666     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.9        |\n",
      "|    ep_rew_mean          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006734257 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.00513     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.8        |\n",
      "|    ep_rew_mean          | 0.971       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 710         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005537164 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00521    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 0.00518     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32           |\n",
      "|    ep_rew_mean          | 0.972        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 81           |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 729          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058092778 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    value_loss           | 0.00404      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032572686 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00927     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    value_loss           | 0.00341      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.1     |\n",
      "|    ep_rew_mean     | 0.973    |\n",
      "| time/              |          |\n",
      "|    fps             | 82       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 748      |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.8        |\n",
      "|    ep_rew_mean          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 767         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005327213 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.42       |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    value_loss           | 0.00294     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.974        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 785          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022486267 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0071      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    value_loss           | 0.0027       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29           |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 84           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 804          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018044565 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.338       |\n",
      "|    explained_variance   | 0.538        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00237     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 0.00316      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29          |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 822         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003223544 |\n",
      "|    clip_fraction        | 0.0285      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00654    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 0.00236     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 27            |\n",
      "|    mean_reward          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 70000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076272653 |\n",
      "|    clip_fraction        | 0.0167        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.281        |\n",
      "|    explained_variance   | 0.606         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.00199      |\n",
      "|    n_updates            | 340           |\n",
      "|    policy_gradient_loss | -0.000821     |\n",
      "|    value_loss           | 0.00244       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.3     |\n",
      "|    ep_rew_mean     | 0.975    |\n",
      "| time/              |          |\n",
      "|    fps             | 85       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 842      |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.4         |\n",
      "|    ep_rew_mean          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 85           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 861          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010775533 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.255       |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0032      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    value_loss           | 0.00322      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.2        |\n",
      "|    ep_rew_mean          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 880         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000996046 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000826   |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 0.0022      |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.1          |\n",
      "|    ep_rew_mean          | 0.976         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 86            |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 899           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080149097 |\n",
      "|    clip_fraction        | 0.00723       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.227        |\n",
      "|    explained_variance   | 0.613         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00431       |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | 0.000194      |\n",
      "|    value_loss           | 0.00241       |\n",
      "-------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 48         |\n",
      "|    ep_rew_mean          | 0.956      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 86         |\n",
      "|    iterations           | 39         |\n",
      "|    time_elapsed         | 918        |\n",
      "|    total_timesteps      | 79872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37829286 |\n",
      "|    clip_fraction        | 0.082      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.24      |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0201    |\n",
      "|    n_updates            | 380        |\n",
      "|    policy_gradient_loss | -0.00438   |\n",
      "|    value_loss           | 0.00257    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04567437 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.957     |\n",
      "|    explained_variance   | -5.9       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0302    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    value_loss           | 0.00115    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 59.5     |\n",
      "|    ep_rew_mean     | 0.947    |\n",
      "| time/              |          |\n",
      "|    fps             | 82       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 988      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 79.4        |\n",
      "|    ep_rew_mean          | 0.927       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1006        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.096402675 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | -2.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 0.000641    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 99.3       |\n",
      "|    ep_rew_mean          | 0.908      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 83         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 1024       |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06732419 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.46      |\n",
      "|    explained_variance   | -0.555     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.058     |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.00398   |\n",
      "|    value_loss           | 0.00027    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 120         |\n",
      "|    ep_rew_mean          | 0.888       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1041        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024689361 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -0.874      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0595     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.000168    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022623565 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.00819     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 0.00223     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 139      |\n",
      "|    ep_rew_mean     | 0.871    |\n",
      "| time/              |          |\n",
      "|    fps             | 81       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 1103     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 164         |\n",
      "|    ep_rew_mean          | 0.855       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1122        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019132443 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.0678      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.00451     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 179         |\n",
      "|    ep_rew_mean          | 0.843       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1141        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020015614 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00404     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.00943     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 191         |\n",
      "|    ep_rew_mean          | 0.832       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1161        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027775427 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.0217      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 66.2         |\n",
      "|    ep_rew_mean          | 0.942        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 83           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 1180         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124979075 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.88        |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00117     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 0.0258       |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013079662 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00783    |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0174      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.2     |\n",
      "|    ep_rew_mean     | 0.962    |\n",
      "| time/              |          |\n",
      "|    fps             | 83       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 1200     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "count_base_reward = {}\n",
    "\n",
    "for run in range(5):\n",
    "    train_env = CountBasedBonusWrapepr(env)\n",
    "    \n",
    "    test_env = env\n",
    "\n",
    "    eval_callback = Eval_Callback(eval_env=env, eval_freq=10000, n_eval_episodes=10)\n",
    "\n",
    "    policy = PPO(policy=\"CnnPolicy\", env=train_env, verbose=1, policy_kwargs=get_policy_kwargs(),  ent_coef=0.005)\n",
    "\n",
    "    policy.learn(total_timesteps=100000, callback=eval_callback)\n",
    "\n",
    "    count_base_reward[f\"run_{run}\"] = eval_callback.record_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy.save(\"pretrained_models/ppo_observation_count_bonus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4.2.2 Test PPO Agent with Count Based Bonus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = PPO.load(\"pretrained_models/ppo_observation_count_bonus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average reward for 50 runs are: 0.9642109375\n"
     ]
    }
   ],
   "source": [
    "# # Reset the environment to its initial state\n",
    "# obs, _ = test_env.reset()\n",
    "# count = 1\n",
    "# reward_list = []\n",
    "# # Perform some actions in the environment\n",
    "# while count <= 50:\n",
    "#     action, _ = policy.predict(obs) # Sample an action using the trained policy\n",
    "    \n",
    "\n",
    "#     obs, reward, done, truncated, info = test_env.step(action)  # Take a step in the environment\n",
    "\n",
    "#     # If the episode is finish either done or truncated, record reward & reset the environment\n",
    "#     if done or truncated:\n",
    "#         reward_list.append(reward)\n",
    "#         observation = test_env.reset()\n",
    "#         count += 1\n",
    "\n",
    "# print(f\"The average reward for 50 runs are: {np.mean(reward_list)}\")\n",
    "# test_env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Episodic Curiousity through Reachability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we will present our implementation of the reachability bonus. 🚀\n",
    "- Here, we will also implement it as a wrapper to the Minigrid environment. \n",
    "- This implementation is a simplified version of the implementation in the original paper, wherein the author uses a pretrained ResNet model to learn the feature vector from image input. 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.1 Key Points**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The main idea behind this method is to give reward to observations depending on how far it is to the observations recorded in the agent's memory.\n",
    "- A neural network is created, with the task, to determine whether one observation can be reached from another labelled as 0 for unreachable and 1 for reachable. The network can be summarized as $C(E(o_i),E(o_j))$, where $E(o_i)$ and $E(o_j)$ is the feature embeddinng of observations $o_i$ and $o_j$, and $C\\rightarrow [0,1]$ is a function that determinned reachability.\n",
    "- A memory $M$ is used to record the embedding $e$ of visited observations. When a new observation is met, we will calculate the reachability to this obsevation from every observations stored in $M$ denoted as $C(M,e)=F(c_1,...,c_{|M|})$, where $F$ is a hyperparameter method, for instance, $F=max$. \n",
    "- The bonus denoted as $\\beta$ is calculated as $\\alpha*(\\beta-C(M,e))$ where $\\alpha$ and $\\beta$ are hyperparameters.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./image/Episodic_Reachability_Architecture.png\" alt=\"Episodic Curiosity through Reachability\" width=\"1000\" height=\"450\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R_Model, self).__init__()\n",
    "        \n",
    "        # Define the number of output features after convolutional layers\n",
    "        feature_output = 64\n",
    "\n",
    "        # Embedding network -> In original implementation, the author used pretrained ResNet.\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,  # Adjusted to match the number of input channels\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(feature_output, 512)\n",
    "        )\n",
    "\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 256),  # Combine the embeddings of two observations\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 2),  \n",
    "            nn.Softmax(dim=1)  \n",
    "        )\n",
    "\n",
    "    def get_embedding(self, ob):\n",
    "        ob = torch.tensor(ob.reshape(1,3,7,7), dtype=torch.float32).to(device)\n",
    "        ob_emb = self.embedding(ob)\n",
    "        return ob_emb\n",
    "    \n",
    "    def get_label(self, ob_1, ob_2):\n",
    "        ob_1_emb = self.get_embedding(ob_1)\n",
    "        ob_2_emb = self.get_embedding(ob_2)\n",
    "        combined_embedding = torch.cat((ob_1_emb, ob_2_emb), dim=1).to(device)\n",
    "        prob = self.classification(combined_embedding)\n",
    "        return prob\n",
    "        \n",
    "    def get_reward(self, ob, M):\n",
    "        max_reward = 0\n",
    "        for ob_2 in M:\n",
    "            with torch.no_grad():\n",
    "                prob = self.get_label(ob, ob_2)\n",
    "            prob = prob.to(\"cpu\")\n",
    "            value = prob[0][1]\n",
    "            if value > max_reward:\n",
    "                max_reward = value\n",
    "        return max_reward.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodicCuriousityBonusWrapepr(Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.based_bonus = 0.001\n",
    "        self.M = []                                  # Memory \n",
    "        self.eps = []\n",
    "        self.max_length = 10\n",
    "\n",
    "        self.step_retrained_model = 0                                    \n",
    "        self.r_model = R_Model().to(device)\n",
    "        self.optimizer = optim.Adam(self.r_model.parameters(), lr=1e-4)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.model_trained = False\n",
    "        self.beta = 1\n",
    "        self.alpha = 0.001\n",
    "\n",
    "        self.history = deque(maxlen=10)\n",
    "        self.k = 5                                  # Gap\n",
    "        self.gamma = 1.2\n",
    "\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.eps.append(obs[0])\n",
    "        self.M.append(obs[0])\n",
    "        return obs\n",
    "        \n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        self.eps.append(obs)\n",
    "        if len(self.M) > self.max_length:\n",
    "            if not any(np.array_equal(obs, array) for array in self.M):\n",
    "                self.M.pop(random.randint(0, len(self.M) - 1))\n",
    "                self.M.append(obs)\n",
    "        else:\n",
    "            if not any(np.array_equal(obs, array) for array in self.M):\n",
    "                self.M.append(obs)\n",
    " \n",
    "        if terminated or truncated: \n",
    "            self.history.append(self.eps.copy())\n",
    "            self.eps = []\n",
    "            self.M = []\n",
    "\n",
    "        # Train r_model\n",
    "        self.step_retrained_model += 1\n",
    "        if self.step_retrained_model == 30000 and len(self.history) != 0:\n",
    "            X, y = self.create_training_data()                                                      # -> labelling the training data\n",
    "            self.train_r_model(X, y)\n",
    "            self.step_retrained_model = 0\n",
    "            self.model_trained = True\n",
    "\n",
    "        if len(self.M) >= 2 and self.model_trained:                                                 # -> If network R is trained then start getting the reward\n",
    "            bonus = self.r_model.get_reward(obs, self.M)\n",
    "            bonus = self.alpha*(self.beta-bonus)\n",
    "            reward += bonus\n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n",
    "    \n",
    "    def create_training_data(self):\n",
    "        \"\"\"Function to create the training dataset of neural network R\"\"\"\n",
    "        X = []\n",
    "        y = []\n",
    "        for episode in self.history:\n",
    "            for _ in range(30):\n",
    "                episode_with_indices = list(enumerate(episode))\n",
    "                index, _ = random.choice(episode_with_indices)\n",
    "\n",
    "                # Get random positive (reachable) example -> reachable 1\n",
    "                # Calculate the maximum allowable value for 'step' to stay within the range of indices\n",
    "                max_step = min(self.k, len(episode) - 1 - index)\n",
    "                if max_step == 1:\n",
    "                    step = 1\n",
    "                elif max_step == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    step = random.randint(1, max_step)\n",
    "                X.append([episode[index], episode[index+step]])\n",
    "                y.append(1)\n",
    "\n",
    "                # Get random negative (unreachable) example -> non-reachable 0\n",
    "                # If last few index then skip\n",
    "                if self.k*self.gamma > len(episode) - 1 - index:\n",
    "                    continue\n",
    "                else:\n",
    "                    step = random.randint(self.k*self.gamma, len(episode) - 1 - index)\n",
    "                    X.append([episode[index], episode[index+step]])\n",
    "                    y.append(0)\n",
    "        return X, y\n",
    " \n",
    "\n",
    "    def train_r_model(self, X, y):\n",
    "        for _ in range(5):\n",
    "            indices = list(range(len(X)))\n",
    "\n",
    "            # Shuffle the indices\n",
    "            random.shuffle(indices)\n",
    "\n",
    "            # Reorder both X and y using the shuffled indices\n",
    "            X_shuffled = [X[i] for i in indices]\n",
    "            y_shuffled = [y[i] for i in indices]\n",
    "         \n",
    "            prob_stack = []\n",
    "            for i in range(len(X)):\n",
    "                prob = self.r_model.get_label(X_shuffled[i][0], X_shuffled[i][1])\n",
    "                prob_stack.append(prob)\n",
    "            prob_stack = torch.cat(prob_stack, dim=0)\n",
    "            loss = self.criterion(prob_stack[:,1], torch.tensor(y_shuffled).float().to(device))\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MiniGrid-Empty-16x16-v0\", render_mode=\"rgb_array\")\n",
    "env = ImgObsWrapper(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.1 Train PPO with Episodic Curiousity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e598bfd0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e598bee0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 219      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 194         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010137494 |\n",
      "|    clip_fraction        | 0.0517      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -1.15       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00689    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 1.28e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | 0            |\n",
      "| time/                   |              |\n",
      "|    fps                  | 182          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042131636 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | -0.395       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0108      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.57e-05     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.02e+03  |\n",
      "|    ep_rew_mean          | 0         |\n",
      "| time/                   |           |\n",
      "|    fps                  | 166       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 49        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0145624 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.89     |\n",
      "|    explained_variance   | -4.74     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0043    |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -0.00766  |\n",
      "|    value_loss           | 2.41e-05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071883537 |\n",
      "|    clip_fraction        | 0.0619       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.88        |\n",
      "|    explained_variance   | -2.74        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00728     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 4.36e-05     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 107      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 94       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273525 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -4.74       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00891    |\n",
      "|    value_loss           | 2.84e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0183      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 120         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016080637 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -5.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 2.49e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0159      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008575911 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.0457     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    value_loss           | 0.00027     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011354523 |\n",
      "|    clip_fraction        | 0.0592      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -4.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    value_loss           | 4.18e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009645967 |\n",
      "|    clip_fraction        | 0.0617      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -7.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00829    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    value_loss           | 2.81e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0.0483   |\n",
      "| time/              |          |\n",
      "|    fps             | 105      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0437      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 105         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012686144 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00555     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    value_loss           | 0.00187     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 944         |\n",
      "|    ep_rew_mean          | 0.139       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 107         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014144152 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -2.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00896    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    value_loss           | 0.000289    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | 0.197       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012094663 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.0586      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0291     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.00707     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 697          |\n",
      "|    ep_rew_mean          | 0.368        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 108          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 264          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111333225 |\n",
      "|    clip_fraction        | 0.181        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.78        |\n",
      "|    explained_variance   | -0.0246      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0112      |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.00621      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014658837 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.104       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0273     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 557      |\n",
      "|    ep_rew_mean     | 0.504    |\n",
      "| time/              |          |\n",
      "|    fps             | 85       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 437         |\n",
      "|    ep_rew_mean          | 0.625       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016222248 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00913    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0235      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 0.708       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014663597 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00555    |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0255      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.6         |\n",
      "|    ep_rew_mean          | 0.953        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 67           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 545          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143751055 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0243      |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 0.0239       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.6        |\n",
      "|    ep_rew_mean          | 0.977       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 600         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013920658 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006759368 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00138     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 0.0142      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 48.2     |\n",
      "|    ep_rew_mean     | 0.981    |\n",
      "| time/              |          |\n",
      "|    fps             | 58       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 704      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.4        |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 762         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012320456 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    value_loss           | 0.0102      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 39.9         |\n",
      "|    ep_rew_mean          | 0.984        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067188367 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0463      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 0.00725      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 37.4         |\n",
      "|    ep_rew_mean          | 0.985        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 53           |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 883          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066936444 |\n",
      "|    clip_fraction        | 0.0858       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.844       |\n",
      "|    explained_variance   | 0.521        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0197      |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00792     |\n",
      "|    value_loss           | 0.00464      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.4        |\n",
      "|    ep_rew_mean          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 933         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004642874 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    value_loss           | 0.00355     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065495255 |\n",
      "|    clip_fraction        | 0.0913       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.589        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0197      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00821     |\n",
      "|    value_loss           | 0.00362      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34       |\n",
      "|    ep_rew_mean     | 0.987    |\n",
      "| time/              |          |\n",
      "|    fps             | 51       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 990      |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | 0.987        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1045         |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033793696 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0067      |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    value_loss           | 0.00305      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 31.3        |\n",
      "|    ep_rew_mean          | 0.988       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1095        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003520432 |\n",
      "|    clip_fraction        | 0.0564      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000927   |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.00256     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.9        |\n",
      "|    ep_rew_mean          | 0.982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 49          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1166        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007566431 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.36       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    value_loss           | 0.00238     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 56.2        |\n",
      "|    ep_rew_mean          | 0.978       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 48          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014836866 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    value_loss           | 0.00758     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015598495 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00494    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.00948     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 54.7     |\n",
      "|    ep_rew_mean     | 0.978    |\n",
      "| time/              |          |\n",
      "|    fps             | 47       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1299     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.7        |\n",
      "|    ep_rew_mean          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006070706 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 0.00635     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.7         |\n",
      "|    ep_rew_mean          | 0.987        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1400         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023483178 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.331       |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00962     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 0.00432      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 46.5       |\n",
      "|    ep_rew_mean          | 0.98       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 46         |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 1461       |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17596082 |\n",
      "|    clip_fraction        | 0.0453     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00381   |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    value_loss           | 0.00301    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 54.7       |\n",
      "|    ep_rew_mean          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 1529       |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18801546 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.536     |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0446    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 0.00126    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.02e+03  |\n",
      "|    mean_reward          | 0         |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 70000     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2289092 |\n",
      "|    clip_fraction        | 0.0633    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.245    |\n",
      "|    explained_variance   | 0.423     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0225   |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -0.00922  |\n",
      "|    value_loss           | 0.00693   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.8     |\n",
      "|    ep_rew_mean     | 0.985    |\n",
      "| time/              |          |\n",
      "|    fps             | 44       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1626     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.5         |\n",
      "|    ep_rew_mean          | 0.987        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1676         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019724227 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.195       |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00485      |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 0.00404      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.6        |\n",
      "|    ep_rew_mean          | 0.982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1744        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008278035 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.194      |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00277    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    value_loss           | 0.00324     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 58.2       |\n",
      "|    ep_rew_mean          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 42         |\n",
      "|    iterations           | 38         |\n",
      "|    time_elapsed         | 1812       |\n",
      "|    total_timesteps      | 77824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07708743 |\n",
      "|    clip_fraction        | 0.0836     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.391     |\n",
      "|    explained_variance   | 0.118      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0138    |\n",
      "|    n_updates            | 370        |\n",
      "|    policy_gradient_loss | 0.00114    |\n",
      "|    value_loss           | 0.00599    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 65.5        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1871        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017753389 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00885    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.00498     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011486255 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    value_loss           | 0.00796     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 52.5     |\n",
      "|    ep_rew_mean     | 0.978    |\n",
      "| time/              |          |\n",
      "|    fps             | 41       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 1971     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 43.3         |\n",
      "|    ep_rew_mean          | 0.982        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 2031         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044457167 |\n",
      "|    clip_fraction        | 0.0792       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.401       |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00416      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    value_loss           | 0.00778      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.8        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2083        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003928828 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.335      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 0.0075      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.2        |\n",
      "|    ep_rew_mean          | 0.987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2134        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004394019 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.28       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00777    |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 0.00411     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04248108 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0241    |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    value_loss           | 0.00387    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.4     |\n",
      "|    ep_rew_mean     | 0.981    |\n",
      "| time/              |          |\n",
      "|    fps             | 39       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2270     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 71.2       |\n",
      "|    ep_rew_mean          | 0.974      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 39         |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 2345       |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10193035 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.41      |\n",
      "|    explained_variance   | -2.81      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00945    |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.008     |\n",
      "|    value_loss           | 0.0021     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.9        |\n",
      "|    ep_rew_mean          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2423        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035255227 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | -4.97       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 0.000705    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 110         |\n",
      "|    ep_rew_mean          | 0.956       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 2499        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016626108 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0165     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.000631   |\n",
      "|    value_loss           | 0.000321    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 123         |\n",
      "|    ep_rew_mean          | 0.95        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 2574        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021626614 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | -0.25       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    value_loss           | 0.000595    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.02e+03     |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098457225 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.805       |\n",
      "|    explained_variance   | 0.00868      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00799     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    value_loss           | 0.00273      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 149      |\n",
      "|    ep_rew_mean     | 0.941    |\n",
      "| time/              |          |\n",
      "|    fps             | 37       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 2691     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5dd4a00> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5dd5d80>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 162      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 996         |\n",
      "|    ep_rew_mean          | 0.0496      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 140         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023861913 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -2.98       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 3.22e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0331      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 133         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014475049 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.000313    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 0.000245    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0248      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 129         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006861387 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -5.55       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0347     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 2.31e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 10000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01138145 |\n",
      "|    clip_fraction        | 0.0946     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.79      |\n",
      "|    explained_variance   | -6.71      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00825   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.00956   |\n",
      "|    value_loss           | 0.000536   |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | 0.022    |\n",
      "| time/              |          |\n",
      "|    fps             | 103      |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.018       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010006091 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -5.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0087      |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 1.95e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | 0.0153     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 122        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03488122 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.87      |\n",
      "|    explained_variance   | -2.82      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0276    |\n",
      "|    n_updates            | 60         |\n",
      "|    policy_gradient_loss | -0.0222    |\n",
      "|    value_loss           | 1.77e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0132      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012637403 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -3.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.045      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 5.24e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0117      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663542 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -3.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00557    |\n",
      "|    value_loss           | 2.29e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022524344 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -1.54       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 2.14e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0.011    |\n",
      "| time/              |          |\n",
      "|    fps             | 91       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.00992     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 245         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019248879 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -4.82       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000358    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.0459      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455957 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -2.21       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 1.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0525      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011186596 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    value_loss           | 0.00241     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.05e+03   |\n",
      "|    ep_rew_mean          | 0.0486     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 91         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00941535 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.81      |\n",
      "|    explained_variance   | -0.0559    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0159     |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    value_loss           | 0.000329   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02025232 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.77      |\n",
      "|    explained_variance   | -1.54      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0284    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 4.45e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | 0.0469   |\n",
      "| time/              |          |\n",
      "|    fps             | 68       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 446      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.0773      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011483623 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -0.213      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.022      |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 2.52e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.104       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012750391 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -5.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0262     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.127       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 733         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014521542 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -4.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0195     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 1.21e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.148       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015125011 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -2.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0426     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 1.38e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339761 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -3.69       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00986    |\n",
      "|    value_loss           | 1.94e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.06e+03 |\n",
      "|    ep_rew_mean     | 0.161    |\n",
      "| time/              |          |\n",
      "|    fps             | 42       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 974      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.189       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1049        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016409585 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -0.173      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.204       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1120        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009057328 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -5.56       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    value_loss           | 1.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.231       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023244837 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -2.18       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 9.34e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.248       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1278        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013102079 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.00371     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00217    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.00118     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017723173 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.0693     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0435     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.000764    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.06e+03 |\n",
      "|    ep_rew_mean     | 0.268    |\n",
      "| time/              |          |\n",
      "|    fps             | 36       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1406     |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.278       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1483        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012583848 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -1.5        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0357     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    value_loss           | 3.38e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.06e+03   |\n",
      "|    ep_rew_mean          | 0.286      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 35         |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 1564       |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01168851 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.78      |\n",
      "|    explained_variance   | -4.07      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00704    |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 7.57e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.294       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1646        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014120114 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -4.72       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0119      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    value_loss           | 2.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.301       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 34          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1723        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014845343 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -4.26       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00216     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 1.73e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012579996 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -5.24       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 6.78e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | 0.312    |\n",
      "| time/              |          |\n",
      "|    fps             | 33       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1861     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.322       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1939        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020640949 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | -3.19       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0225     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 1.52e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.336       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 2017        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016171368 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.00799     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0263     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.000482    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.374       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 2087        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019649755 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -0.125      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.00039     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 935         |\n",
      "|    ep_rew_mean          | 0.424       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 2159        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012488401 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.00697     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013432894 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.0845      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00533    |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0125      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 891      |\n",
      "|    ep_rew_mean     | 0.458    |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 2279     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 792        |\n",
      "|    ep_rew_mean          | 0.524      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 31         |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 2347       |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01665774 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.67      |\n",
      "|    explained_variance   | 0.0897     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0103    |\n",
      "|    n_updates            | 350        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    value_loss           | 0.00949    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 637         |\n",
      "|    ep_rew_mean          | 0.657       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 2413        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012490718 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0195      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 417          |\n",
      "|    ep_rew_mean          | 0.837        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 2477         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101964325 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000854    |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    value_loss           | 0.0216       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 0.944       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2540        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014610076 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.023       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 30         |\n",
      "|    mean_reward          | 0.974      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 80000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01107595 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.428      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0128    |\n",
      "|    value_loss           | 0.0236     |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 78.5     |\n",
      "|    ep_rew_mean     | 0.969    |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 2602     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.9        |\n",
      "|    ep_rew_mean          | 0.977       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010812508 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.0155      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.4        |\n",
      "|    ep_rew_mean          | 0.981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2721        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008627874 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0162     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.00985     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42          |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2780        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007888474 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.00655     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04593774 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.842     |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0108    |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    value_loss           | 0.00525    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 58.7     |\n",
      "|    ep_rew_mean     | 0.976    |\n",
      "| time/              |          |\n",
      "|    fps             | 30       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2926     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 76.5        |\n",
      "|    ep_rew_mean          | 0.969       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 3007        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025703333 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -10.3       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0469     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 0.00145     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 96.2        |\n",
      "|    ep_rew_mean          | 0.961       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028407212 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -2.9        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0478     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.000393    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 113         |\n",
      "|    ep_rew_mean          | 0.954       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 3164        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011660775 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.0043      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 128         |\n",
      "|    ep_rew_mean          | 0.948       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 30          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 3239        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011849316 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.132       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.00619     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010999691 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00334     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0144      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 134      |\n",
      "|    ep_rew_mean     | 0.945    |\n",
      "| time/              |          |\n",
      "|    fps             | 30       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 3306     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5dd4880> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5dd57e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 151      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008538345 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -3.5        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    value_loss           | 2.71e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 972        |\n",
      "|    ep_rew_mean          | 0.0628     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 126        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02139515 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.89      |\n",
      "|    explained_variance   | -4.91      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0103    |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 6.09e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 985         |\n",
      "|    ep_rew_mean          | 0.0471      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 124         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011642788 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -0.0387     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0198     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    value_loss           | 0.000637    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018081332 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -4.8        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00644    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 2.21e-05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 992      |\n",
      "|    ep_rew_mean     | 0.0377   |\n",
      "| time/              |          |\n",
      "|    fps             | 78       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 0.0314      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009054834 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -6.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 2.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0269      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 86          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 166         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012446489 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -3.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    value_loss           | 2.47e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0236      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360401 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -7.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 1.7e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0209      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010158475 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -2.83       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 0.000125    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010502253 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -5.6        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    value_loss           | 3.47e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | 0.0198   |\n",
      "| time/              |          |\n",
      "|    fps             | 76       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0179      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013580611 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -5.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0317     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 3.16e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0164      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 304         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011627333 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -5.85       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00769    |\n",
      "|    value_loss           | 2.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0151      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010810775 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -7.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0407     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    value_loss           | 2.92e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.014       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012774501 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | -6.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.000142    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018728238 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -1.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0096     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 6.44e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | 0.0135   |\n",
      "| time/              |          |\n",
      "|    fps             | 69       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 444      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.07e+03   |\n",
      "|    ep_rew_mean          | 0.0461     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 62         |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 525        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01101893 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | -0.543     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0153    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    value_loss           | 6.46e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.07e+03  |\n",
      "|    ep_rew_mean          | 0.0745    |\n",
      "| time/                   |           |\n",
      "|    fps                  | 57        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 604       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0128211 |\n",
      "|    clip_fraction        | 0.132     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.81     |\n",
      "|    explained_variance   | -1.4      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.013    |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -0.0124   |\n",
      "|    value_loss           | 4.07e-05  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.06e+03   |\n",
      "|    ep_rew_mean          | 0.0997     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 53         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 685        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02430449 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | -2.56      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0312    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.000128   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.122       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 765         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012010497 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -4.28       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    value_loss           | 0.000344    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033565566 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -4.65       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 5.63e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.06e+03 |\n",
      "|    ep_rew_mean     | 0.132    |\n",
      "| time/              |          |\n",
      "|    fps             | 45       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 892      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | 0.161      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 44         |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 972        |\n",
      "|    total_timesteps      | 43008      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02454996 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | -3.24      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0338    |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 2.66e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.178       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1052        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017214473 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -6.33       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 3.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.193       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1132        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011904985 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | -3.61       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 6.99e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.207       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1212        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012599626 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -6.7        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0027      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000119    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009384094 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -4.47       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 3.76e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.228    |\n",
      "| time/              |          |\n",
      "|    fps             | 38       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1336     |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.239       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 37          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1416        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014501904 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -5.33       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 2.97e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1495        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011761224 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -4.58       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 2.93e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.259       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 36          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1575        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016200315 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -4.34       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0513     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 4.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.268       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 35          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1654        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014746785 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -4.36       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0496     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 4.38e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 60000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01334064 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.8       |\n",
      "|    explained_variance   | -9.83      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0567    |\n",
      "|    n_updates            | 290        |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    value_loss           | 4.7e-05    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.09e+03 |\n",
      "|    ep_rew_mean     | 0.279    |\n",
      "| time/              |          |\n",
      "|    fps             | 34       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1799     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | 0.286       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1875        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022339331 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -5.75       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0492     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000172    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | 0.305       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1954        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029865056 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -1.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0606     |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0376     |\n",
      "|    value_loss           | 4.58e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.314       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 33          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 2033        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014949057 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.418      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00557    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    value_loss           | 0.00166     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.323       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 32          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 2112        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021370351 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.451      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0522      |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00762    |\n",
      "|    value_loss           | 0.0008      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018526116 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.219      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000414    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | 0.342    |\n",
      "| time/              |          |\n",
      "|    fps             | 32       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 2234     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 994         |\n",
      "|    ep_rew_mean          | 0.382       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 2309        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013130343 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.0831      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.00193     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 924         |\n",
      "|    ep_rew_mean          | 0.432       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 2384        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016764738 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00371    |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.00729     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 845         |\n",
      "|    ep_rew_mean          | 0.485       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 2458        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012242114 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.011       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | 0.614       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2526        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011056267 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014530955 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.028      |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0201      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 498      |\n",
      "|    ep_rew_mean     | 0.796    |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 2595     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 219         |\n",
      "|    ep_rew_mean          | 0.91        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2660        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013579142 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00442    |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0235      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 88.4        |\n",
      "|    ep_rew_mean          | 0.964       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2724        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014730711 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00697     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0174      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 69.2        |\n",
      "|    ep_rew_mean          | 0.972       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2787        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014336137 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.0169      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012649247 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0126      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 55.4     |\n",
      "|    ep_rew_mean     | 0.977    |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2867     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.8        |\n",
      "|    ep_rew_mean          | 0.981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2926        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011965413 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.009       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.7        |\n",
      "|    ep_rew_mean          | 0.982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 2985        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009661529 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0411     |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00574     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 37.2        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 31          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 3045        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007901064 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 35.1         |\n",
      "|    ep_rew_mean          | 0.985        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 31           |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 3103         |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063410467 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0207      |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 0.00343      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.97 +/- 0.00\n",
      "Episode length: 30.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 30          |\n",
      "|    mean_reward          | 0.974       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005692524 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00797     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.00325     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.7     |\n",
      "|    ep_rew_mean     | 0.986    |\n",
      "| time/              |          |\n",
      "|    fps             | 31       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 3160     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5dd78b0> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5dd72b0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 150      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 132         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013339898 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -10.5       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00985     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 1.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | 0.0378      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 127         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008112207 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -5.24       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0533     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    value_loss           | 1.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | 0.0283      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 125         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009921052 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.0167      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00773    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 0.000255    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010801156 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -2.94       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000798   |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00802    |\n",
      "|    value_loss           | 9.6e-06     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | 0.0252   |\n",
      "| time/              |          |\n",
      "|    fps             | 80       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | 0.0206      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 145         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009811849 |\n",
      "|    clip_fraction        | 0.0669      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -7.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00838    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    value_loss           | 1.3e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0174      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843817 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -5.86       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 1.34e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | 0.0151      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011688802 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | -4.15       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00597     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00865    |\n",
      "|    value_loss           | 3.6e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.0264      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 94          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011877483 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -5.02       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0268     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 2.04e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008640532 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -0.0102     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00573    |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.000276    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | 0.0404   |\n",
      "| time/              |          |\n",
      "|    fps             | 83       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | 0.0366       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 86           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0122348135 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.023       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 0.000526     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 896         |\n",
      "|    ep_rew_mean          | 0.181       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017918378 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | -4.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00497    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 3.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 826         |\n",
      "|    ep_rew_mean          | 0.244       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016651567 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.00139     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0257     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.0106      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 750       |\n",
      "|    ep_rew_mean          | 0.316     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 94        |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 303       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0180659 |\n",
      "|    clip_fraction        | 0.226     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.74     |\n",
      "|    explained_variance   | 0.192     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00011   |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -0.0111   |\n",
      "|    value_loss           | 0.00646   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018370954 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.0874      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0105      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 635      |\n",
      "|    ep_rew_mean     | 0.432    |\n",
      "| time/              |          |\n",
      "|    fps             | 76       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 402      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 510         |\n",
      "|    ep_rew_mean          | 0.561       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 71          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 455         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011530676 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.0882      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00826    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.0175      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 409         |\n",
      "|    ep_rew_mean          | 0.659       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 68          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010224495 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00184     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.0201      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 207         |\n",
      "|    ep_rew_mean          | 0.85        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 64          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016531479 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00106    |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.0231      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.6        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 61          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 632         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019011546 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0214      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011897935 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.016       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 57.4     |\n",
      "|    ep_rew_mean     | 0.977    |\n",
      "| time/              |          |\n",
      "|    fps             | 55       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 740      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48          |\n",
      "|    ep_rew_mean          | 0.981       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006658136 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000426    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.0145      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.5        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010657991 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0136     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00844    |\n",
      "|    value_loss           | 0.00825     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 38.3        |\n",
      "|    ep_rew_mean          | 0.985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 52          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 905         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007897034 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000749    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 0.00592     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 36.8        |\n",
      "|    ep_rew_mean          | 0.985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 51          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008256825 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 0.00719     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009588355 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00863    |\n",
      "|    value_loss           | 0.00428     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34       |\n",
      "|    ep_rew_mean     | 0.986    |\n",
      "| time/              |          |\n",
      "|    fps             | 50       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1021     |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.5         |\n",
      "|    ep_rew_mean          | 0.987        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 1079         |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039179455 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00134     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    value_loss           | 0.00325      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.8        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1160        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021968428 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00305    |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 0.0025      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.5        |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1229        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020823887 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | -0.583      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0307     |\n",
      "|    value_loss           | 0.00486     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35          |\n",
      "|    ep_rew_mean          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1302        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008930426 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.329       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.00345     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075746216 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0179      |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0119      |\n",
      "|    value_loss           | 0.00356      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.4     |\n",
      "|    ep_rew_mean     | 0.987    |\n",
      "| time/              |          |\n",
      "|    fps             | 43       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1396     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.9        |\n",
      "|    ep_rew_mean          | 0.987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1461        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005614184 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00911    |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 0.00286     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.9        |\n",
      "|    ep_rew_mean          | 0.987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 1529        |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017274337 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00612    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 0.00279     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.6        |\n",
      "|    ep_rew_mean          | 0.985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 1609        |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042653166 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.296      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00145    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 0.0025      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.1        |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 41          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1685        |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021144152 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00288     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016931897 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.00327     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.7     |\n",
      "|    ep_rew_mean     | 0.985    |\n",
      "| time/              |          |\n",
      "|    fps             | 40       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1752     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.8        |\n",
      "|    ep_rew_mean          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1810        |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004505884 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.323      |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00208    |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 0.00322     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.7        |\n",
      "|    ep_rew_mean          | 0.987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 1869        |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316629 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    value_loss           | 0.00281     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.2        |\n",
      "|    ep_rew_mean          | 0.988       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012077162 |\n",
      "|    clip_fraction        | 0.0277      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.179      |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00437    |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.0024      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.988        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 1985         |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007901414 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.133       |\n",
      "|    explained_variance   | 0.631        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00066     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    value_loss           | 0.00199      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 28            |\n",
      "|    mean_reward          | 0.975         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 80000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00057336036 |\n",
      "|    clip_fraction        | 0.0113        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.113        |\n",
      "|    explained_variance   | 0.633         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.000538      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    value_loss           | 0.00206       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.9     |\n",
      "|    ep_rew_mean     | 0.988    |\n",
      "| time/              |          |\n",
      "|    fps             | 40       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 2045     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.5        |\n",
      "|    ep_rew_mean          | 0.986       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 2109        |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025917934 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.127      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00116    |\n",
      "|    value_loss           | 0.00212     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.7        |\n",
      "|    ep_rew_mean          | 0.985       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2173        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015715953 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.365      |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.032      |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.00472     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 31.9         |\n",
      "|    ep_rew_mean          | 0.987        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 2238         |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064907162 |\n",
      "|    clip_fraction        | 0.0779       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.258       |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0273      |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 0.00314      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 28          |\n",
      "|    mean_reward          | 0.975       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015782706 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00864    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.00252     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.2     |\n",
      "|    ep_rew_mean     | 0.987    |\n",
      "| time/              |          |\n",
      "|    fps             | 38       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2326     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.987       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2391        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016167551 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.00247     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.6          |\n",
      "|    ep_rew_mean          | 0.987         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 38            |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 2454          |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00085967244 |\n",
      "|    clip_fraction        | 0.00796       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.108        |\n",
      "|    explained_variance   | 0.64          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -3.93e-06     |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.000895     |\n",
      "|    value_loss           | 0.00224       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.4          |\n",
      "|    ep_rew_mean          | 0.987         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 38            |\n",
      "|    iterations           | 47            |\n",
      "|    time_elapsed         | 2511          |\n",
      "|    total_timesteps      | 96256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043877074 |\n",
      "|    clip_fraction        | 0.00889       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0924       |\n",
      "|    explained_variance   | 0.636         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | -0.0036       |\n",
      "|    n_updates            | 460           |\n",
      "|    policy_gradient_loss | -0.00124      |\n",
      "|    value_loss           | 0.00207       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 28.3          |\n",
      "|    ep_rew_mean          | 0.987         |\n",
      "| time/                   |               |\n",
      "|    fps                  | 38            |\n",
      "|    iterations           | 48            |\n",
      "|    time_elapsed         | 2566          |\n",
      "|    total_timesteps      | 98304         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022160506 |\n",
      "|    clip_fraction        | 0.00415       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0796       |\n",
      "|    explained_variance   | 0.641         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 0.00124       |\n",
      "|    n_updates            | 470           |\n",
      "|    policy_gradient_loss | -0.000857     |\n",
      "|    value_loss           | 0.00209       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 28.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 28           |\n",
      "|    mean_reward          | 0.975        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063549196 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.086       |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00285     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 0.00192      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30       |\n",
      "|    ep_rew_mean     | 0.987    |\n",
      "| time/              |          |\n",
      "|    fps             | 38       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 2627     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s223669184/AAMAS_Tutorial_2024/callbacks/Eval_Callback.py:91: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7f76e5dd5690> != <stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7f76e5dd72e0>\n",
      "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 139      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 123         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014258437 |\n",
      "|    clip_fraction        | 0.067       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -2.22       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0159      |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 1.42e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 119         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015552941 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.502      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00916    |\n",
      "|    value_loss           | 1.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | 0           |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011017281 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -1.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000161    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012307612 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | -8.18       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.02e+03 |\n",
      "|    ep_rew_mean     | 0        |\n",
      "| time/              |          |\n",
      "|    fps             | 75       |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | 0.043       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010733877 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -7.2        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0328     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    value_loss           | 2.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0364      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 172         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010702867 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | -0.00578    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000844    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 0.000956    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0315      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 85          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019256156 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | -1.97       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0848     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 2.68e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.05e+03   |\n",
      "|    ep_rew_mean          | 0.0278     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 87         |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 209        |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01923814 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.91      |\n",
      "|    explained_variance   | -0.884     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00882   |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 1.6e-05    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013638269 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -4.67       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 6.73e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | 0.0249   |\n",
      "| time/              |          |\n",
      "|    fps             | 74       |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 275      |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0225      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014818093 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -6.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0487     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 3.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0206      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011454228 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | -5.72       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    value_loss           | 1.47e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | 0.0189      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025669677 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -4.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | 0.0175      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017234579 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -6.61       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 2.16e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 30000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02039447 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.84      |\n",
      "|    explained_variance   | -6.65      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00133    |\n",
      "|    n_updates            | 140        |\n",
      "|    policy_gradient_loss | -0.00924   |\n",
      "|    value_loss           | 2.91e-05   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03e+03 |\n",
      "|    ep_rew_mean     | 0.033    |\n",
      "| time/              |          |\n",
      "|    fps             | 66       |\n",
      "|    iterations      | 15       |\n",
      "|    time_elapsed    | 459      |\n",
      "|    total_timesteps | 30720    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | 0.113       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 60          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 539         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012512908 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0438     |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 967         |\n",
      "|    ep_rew_mean          | 0.16        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013819107 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00587     |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    value_loss           | 0.00436     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 911        |\n",
      "|    ep_rew_mean          | 0.229      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 52         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 696        |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01517181 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.79      |\n",
      "|    explained_variance   | 0.0829     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0303    |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 0.00197    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 878         |\n",
      "|    ep_rew_mean          | 0.279       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 50          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 770         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011487847 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 0.00602     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016758753 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.137       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 0.00311     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 803      |\n",
      "|    ep_rew_mean     | 0.363    |\n",
      "| time/              |          |\n",
      "|    fps             | 45       |\n",
      "|    iterations      | 20       |\n",
      "|    time_elapsed    | 894      |\n",
      "|    total_timesteps | 40960    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 740         |\n",
      "|    ep_rew_mean          | 0.427       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 966         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010494299 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.73       |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00638    |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 0.0117      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 616         |\n",
      "|    ep_rew_mean          | 0.533       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 43          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013190409 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00581    |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 512         |\n",
      "|    ep_rew_mean          | 0.619       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1096        |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010561703 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00777    |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0218      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | 0.806       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 42          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010466834 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00398     |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 0.0203      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013607197 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0171     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.0222      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 104      |\n",
      "|    ep_rew_mean     | 0.955    |\n",
      "| time/              |          |\n",
      "|    fps             | 40       |\n",
      "|    iterations      | 25       |\n",
      "|    time_elapsed    | 1262     |\n",
      "|    total_timesteps | 51200    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 68.7        |\n",
      "|    ep_rew_mean          | 0.968       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013979457 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.0192      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.4        |\n",
      "|    ep_rew_mean          | 0.973       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493987 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.0139      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.7        |\n",
      "|    ep_rew_mean          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 1430        |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013096668 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.00989     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.7        |\n",
      "|    ep_rew_mean          | 0.978       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 40          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 1482        |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010422146 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.00671     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009748355 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 0.0057      |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.1     |\n",
      "|    ep_rew_mean     | 0.98     |\n",
      "| time/              |          |\n",
      "|    fps             | 39       |\n",
      "|    iterations      | 30       |\n",
      "|    time_elapsed    | 1552     |\n",
      "|    total_timesteps | 61440    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 35.6        |\n",
      "|    ep_rew_mean          | 0.982       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 1603        |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013962703 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00175     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    value_loss           | 0.00586     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 34.1         |\n",
      "|    ep_rew_mean          | 0.982        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 1653         |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070510656 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.699       |\n",
      "|    explained_variance   | 0.566        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00012      |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 0.00472      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.5         |\n",
      "|    ep_rew_mean          | 0.982        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 1704         |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060949167 |\n",
      "|    clip_fraction        | 0.0771       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.728       |\n",
      "|    explained_variance   | 0.496        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0115      |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 0.00391      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 32.4         |\n",
      "|    ep_rew_mean          | 0.983        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 1755         |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070523256 |\n",
      "|    clip_fraction        | 0.0894       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.592        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0143      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 0.00306      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008158982 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000987   |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 0.00305     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | 0.984    |\n",
      "| time/              |          |\n",
      "|    fps             | 39       |\n",
      "|    iterations      | 35       |\n",
      "|    time_elapsed    | 1805     |\n",
      "|    total_timesteps | 71680    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 30.1         |\n",
      "|    ep_rew_mean          | 0.984        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 1855         |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034960161 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00182     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 0.00293      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.7         |\n",
      "|    ep_rew_mean          | 0.984        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 1905         |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026152558 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00558      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 0.00287      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 28.9         |\n",
      "|    ep_rew_mean          | 0.984        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 1954         |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025661313 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.327       |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0107      |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 0.00245      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 28.6        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 2003        |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002522056 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00661    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    value_loss           | 0.00228     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 27           |\n",
      "|    mean_reward          | 0.976        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009977596 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.235       |\n",
      "|    explained_variance   | 0.533        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00105      |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 0.00228      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.4     |\n",
      "|    ep_rew_mean     | 0.985    |\n",
      "| time/              |          |\n",
      "|    fps             | 39       |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 2053     |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 33.8         |\n",
      "|    ep_rew_mean          | 0.982        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 2112         |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016455757 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.215       |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -8.72e-05    |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    value_loss           | 0.00231      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.1        |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 2163        |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015144283 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    value_loss           | 0.0043      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 32.6        |\n",
      "|    ep_rew_mean          | 0.983       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 2218        |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010123786 |\n",
      "|    clip_fraction        | 0.0684      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.269      |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0833      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    value_loss           | 0.00329     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=0.98 +/- 0.00\n",
      "Episode length: 27.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 27          |\n",
      "|    mean_reward          | 0.976       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005134104 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.316      |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00119    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.000495   |\n",
      "|    value_loss           | 0.00404     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | 0.984    |\n",
      "| time/              |          |\n",
      "|    fps             | 39       |\n",
      "|    iterations      | 44       |\n",
      "|    time_elapsed    | 2289     |\n",
      "|    total_timesteps | 90112    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.1        |\n",
      "|    ep_rew_mean          | 0.984       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 39          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 2340        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010655254 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00498    |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 0.00277     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 27.8         |\n",
      "|    ep_rew_mean          | 0.985        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 2389         |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085666785 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.207       |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0189      |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 0.00259      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 45.8       |\n",
      "|    ep_rew_mean          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 38         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 2472       |\n",
      "|    total_timesteps      | 96256      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27817285 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.299     |\n",
      "|    explained_variance   | 0.572      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0193    |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.274      |\n",
      "|    value_loss           | 0.00231    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 61.5        |\n",
      "|    ep_rew_mean          | 0.97        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 38          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 2551        |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029668065 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.997      |\n",
      "|    explained_variance   | -2.08       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 0.00189     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 1024.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016640272 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.158       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000727   |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.004       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.4     |\n",
      "|    ep_rew_mean     | 0.965    |\n",
      "| time/              |          |\n",
      "|    fps             | 37       |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 2675     |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "episodic_curiousity = {}\n",
    "\n",
    "for run in range(5):\n",
    "    train_env = EpisodicCuriousityBonusWrapepr(env)\n",
    "    \n",
    "    test_env = env  \n",
    "\n",
    "    eval_callback = Eval_Callback(eval_env=env, eval_freq=10000, n_eval_episodes=10)\n",
    "\n",
    "    policy = PPO(policy=\"CnnPolicy\", env=train_env, verbose=1, policy_kwargs=get_policy_kwargs(),  ent_coef=0.005)\n",
    "\n",
    "    policy.learn(total_timesteps=100000, callback=eval_callback)\n",
    "\n",
    "    episodic_curiousity[f\"run_{run}\"] = eval_callback.record_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.save(\"pretrained_models/ppo_observation_episodic_curiousity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5.2.2 Test PPO Agent with Episodic Curiousity Bonus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy = PPO.load(\"pretrained_models/ppo_observation_episodic_curiousity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset the environment to its initial state\n",
    "# obs, _ = test_env.reset()\n",
    "# count = 1\n",
    "# reward_list = []\n",
    "# # Perform some actions in the environment\n",
    "# while count <= 50:\n",
    "#     action, _ = policy.predict(obs) # Sample an action using the trained policy\n",
    "    \n",
    "#     # print(observation, action)\n",
    "\n",
    "#     obs, reward, done, truncated, info = test_env.step(action)  # Take a step in the environment\n",
    "\n",
    "\n",
    "#     # If the episode is finish either done or truncated, record reward & reset the environment\n",
    "#     if done or truncated:\n",
    "#         reward_list.append(reward)\n",
    "#         observation = test_env.reset()\n",
    "#         count += 1\n",
    "\n",
    "# print(f\"The average reward for 50 runs are: {np.mean(reward_list)}\")\n",
    "# test_env.close()  # Close the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Results Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.1 Saving Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_freq = 10000\n",
    "total_timesteps = 100000\n",
    "\n",
    "row_idx = [i for i in range(0, total_timesteps, eval_freq)]\n",
    "\n",
    "df_simple_PPO = pd.DataFrame.from_dict(simple_ppo_reward, orient='index').T\n",
    "\n",
    "df_simple_PPO.index = row_idx\n",
    "\n",
    "df_count_base = pd.DataFrame.from_dict(count_base_reward, orient='index').T\n",
    "\n",
    "df_count_base.index = row_idx\n",
    "\n",
    "df_episodic_curiousity = pd.DataFrame.from_dict(episodic_curiousity, orient='index').T\n",
    "\n",
    "df_episodic_curiousity.index = row_idx\n",
    "\n",
    "\n",
    "# Save DataFrames to CSV files\n",
    "df_simple_PPO.to_csv('data/simple_ppo_rewards.csv')\n",
    "df_count_base.to_csv('data/count_base_rewards.csv')\n",
    "df_episodic_curiousity.to_csv('data/episodic_curiousity.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.2 Load Data & Visualizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_PPO = pd.read_csv('data/simple_ppo_rewards.csv')\n",
    "df_count_base = pd.read_csv('data/count_base_rewards.csv')\n",
    "df_episodic_curiousity = pd.read_csv('data/episodic_curiousity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_simple_PPO, df_count_base, df_episodic_curiousity]\n",
    "\n",
    "for df in dfs:\n",
    "    df[\"mean\"] = df.iloc[:,1:].mean(axis=1)\n",
    "    df[\"mean_smoothed\"] = df[\"mean\"].ewm(alpha=1-0.9).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot simple_ppo_reward\n",
    "plt.plot(df_simple_PPO.index, df_simple_PPO['mean_smoothed'], label='Simple PPO')\n",
    "\n",
    "# Plot count_base_reward\n",
    "plt.plot(df_count_base.index, df_count_base['mean_smoothed'], label='Count-Based')\n",
    "\n",
    "# Plot episodic_curiousity\n",
    "plt.plot(df_episodic_curiousity.index, df_episodic_curiousity['mean_smoothed'], label='Episodic-Curiousity')\n",
    "\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Average return over 5 runs (Evaluate over 10 episodes)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
